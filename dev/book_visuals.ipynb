{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing context extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define embeddings - remember to change the embeddings file to 1000, 2000 or 4000\n",
    "# Select context, context_medium or context_long depending on 1000, 2000 or 4000\n",
    "book = [2450, 'ww2'][1]\n",
    "embedding_length = [1000, 2000, 4000][2]\n",
    "print(f\"book: {book}, Embedding length: {embedding_length}\")\n",
    "ctx_length_to_name = {1000: 'context', 2000: 'context_medium', 4000: 'context_long'}\n",
    "\n",
    "# use cuda\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(652, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get data\n",
    "with open(f'./data/{book}.pkl', 'rb') as f:\n",
    "    df_data = pickle.load(f)\n",
    "df_data.reset_index(inplace=True)\n",
    "with open(f'./Embeddings/{book}_context_embeddings_{embedding_length}.pkl', 'rb') as f:\n",
    "    context_embeddings = pickle.loads(f.read())\n",
    "with open(f'./Embeddings/{book}_question_embeddings.pkl', 'rb') as f:\n",
    "    question_embeddings = pickle.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_ctx_short = df_data['context'].unique()\n",
    "\n",
    "ctx_mapping_short_to_medium = {}\n",
    "\n",
    "for i in range(len(u_ctx_short)-1):\n",
    "    if i % 2 == 0:\n",
    "        ctx_mapping_short_to_medium[u_ctx_short[i]] = u_ctx_short[i]+u_ctx_short[i+1]\n",
    "    else:\n",
    "        ctx_mapping_short_to_medium[u_ctx_short[i]] = u_ctx_short[i-1]+u_ctx_short[i]\n",
    "\n",
    "data = []\n",
    "for ctx in df_data['context']:\n",
    "    val = ctx_mapping_short_to_medium.get(ctx)\n",
    "    if val:\n",
    "        data.append(val)\n",
    "    else:\n",
    "        data.append(ctx)\n",
    "\n",
    "df_data['context_medium'] = data\n",
    "\n",
    "u_ctx_medium = df_data['context_medium'].unique()\n",
    "\n",
    "ctx_mapping_medium_to_long = {}\n",
    "\n",
    "n = len(u_ctx_medium)\n",
    "for i in range(n-1,0,-1):\n",
    "    if i % 2 == n % 2:\n",
    "        ctx_mapping_medium_to_long[u_ctx_medium[i]] = u_ctx_medium[i]+u_ctx_medium[i+1]\n",
    "    else:\n",
    "        ctx_mapping_medium_to_long[u_ctx_medium[i]] = u_ctx_medium[i-1]+u_ctx_medium[i]\n",
    "\n",
    "data = []\n",
    "for ctx in df_data['context_medium']:\n",
    "    val = ctx_mapping_medium_to_long.get(ctx)\n",
    "    if val:\n",
    "        data.append(val)\n",
    "    else:\n",
    "        data.append(ctx)\n",
    "\n",
    "df_data['context_long'] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make combinations\n",
    "from collections import defaultdict\n",
    "\n",
    "is_added = defaultdict(lambda: 0)\n",
    "\n",
    "contexts = df_data[ctx_length_to_name[embedding_length]].unique()\n",
    "data = []\n",
    "\n",
    "for i,row in df_data.iterrows():\n",
    "    if is_added[row['question']]:\n",
    "        continue\n",
    "\n",
    "    dft = pd.DataFrame(columns=['context', 'question', 'label'])\n",
    "    dft['context'] = contexts\n",
    "    dft['question'] = row['question']\n",
    "    dft['label'] = 0\n",
    "\n",
    "    for ctx in df_data.loc[df_data['question'] == row['question'], ctx_length_to_name[embedding_length]]:\n",
    "        dft.loc[dft['context']==ctx,'label'] = 1\n",
    "\n",
    "    data.append(dft)\n",
    "\n",
    "    is_added[row['question']] = 1\n",
    "df = pd.concat(data, ignore_index=True)\n",
    "sum(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select for train and test\n",
    "n_test_q = int(0.2*len(df['question'].unique()))\n",
    "test_q = np.random.choice(df['question'].unique(), n_test_q, replace=False)\n",
    "\n",
    "# # Make dataframes for repeated contexts\n",
    "# df_test_all_ctx = df.loc[df['question'].isin(test_q)]\n",
    "# df_test_all_ctx.reset_index(inplace=True, drop=True)\n",
    "df_par_all_ctx =  df.loc[~df['question'].isin(test_q)]\n",
    "df_par_all_ctx.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# # Select validation questions\n",
    "n_val_q = int(0.1*len(df_par_all_ctx['question'].unique()))\n",
    "val_q = np.random.choice(df_par_all_ctx['question'].unique(), n_val_q, replace=False)\n",
    "\n",
    "# # Make dataframes for train and validation\n",
    "# df_val_all_ctx =  df_par_all_ctx.loc[df_par_all_ctx['question'].isin(val_q)]\n",
    "# df_val_all_ctx.reset_index(inplace=True, drop=True)\n",
    "df_train_all_ctx =  df_par_all_ctx.loc[~df_par_all_ctx['question'].isin(val_q)]\n",
    "# df_train_all_ctx.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Make train and test data - Context and question are concatenated together\n",
    "X_train_all_ctx = np.array([np.concatenate((context_embeddings[ctx],question_embeddings[q])) for ctx,q in zip(df_train_all_ctx['context'].values, df_train_all_ctx['question'].values)])\n",
    "y_train_all_ctx = np.array([i for i in df_train_all_ctx['label'].values])\n",
    "\n",
    "# X_val_all_ctx = np.array([np.concatenate((context_embeddings[ctx],question_embeddings[q])) for ctx,q in zip(df_val_all_ctx['context'].values, df_val_all_ctx['question'].values)])\n",
    "# y_val_all_ctx = np.array([i for i in df_val_all_ctx['label'].values])\n",
    "\n",
    "# X_test_all_ctx = np.array([np.concatenate((context_embeddings[ctx],question_embeddings[q])) for ctx,q in zip(df_test_all_ctx['context'].values, df_test_all_ctx['question'].values)])\n",
    "# y_test_all_ctx = np.array([i for i in df_test_all_ctx['label'].values])\n",
    "\n",
    "# # Shuffle\n",
    "# idx_train_all_ctx = np.random.permutation(len(X_train_all_ctx))\n",
    "# X_train_all_ctx = X_train_all_ctx[idx_train_all_ctx]\n",
    "# y_train_all_ctx = y_train_all_ctx[idx_train_all_ctx]\n",
    "\n",
    "# idx_val_all_ctx = np.random.permutation(len(X_val_all_ctx))\n",
    "# X_val_all_ctx = X_val_all_ctx[idx_val_all_ctx]\n",
    "# y_val_all_ctx = y_val_all_ctx[idx_val_all_ctx]\n",
    "\n",
    "# idx_test_all_ctx = np.random.permutation(len(X_test_all_ctx))\n",
    "# X_test_all_ctx = X_test_all_ctx[idx_test_all_ctx]\n",
    "# y_test_all_ctx = y_test_all_ctx[idx_test_all_ctx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get top param: n contexts,\n",
    "# increase color intensity for higher values (dot product normalized)\n",
    "# How to normalize? Standardize entire output?\n",
    "def show_book_contexts(num_segments: int, context_indx: set, title=\"\", linewidth=2):\n",
    "    fig, ax = plt.subplots(figsize=(14, 1))\n",
    "    for x in range(num_segments):\n",
    "        color = 'red' if x in context_indx else '#1f77b4'\n",
    "        ax.axvline(x, color=color, linewidth=linewidth) \n",
    "        # ax.axvline(x, color='black', linewidth=1) \n",
    "\n",
    "    if title:\n",
    "        plt.title(title, fontsize=15)\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "_num_segments = 720\n",
    "_context_indx = set(np.random.randint(0, _num_segments, 10)) # top 10\n",
    "show_book_contexts(_num_segments, _context_indx, title='Contexts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a random question from the training data\n",
    "random_idx = np.random.randint(0, len(X_train_all_ctx))\n",
    "random_question = X_train_all_ctx[random_idx]\n",
    "query = random_question[:len(random_question)//2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First half is context, second half is question\n",
    "query_book = np.array([np.concatenate((ctx, query)) for ctx in context_embeddings.values()])\n",
    "# query_book = np.array([np.concatenate((x[len(x)//2:], query)) for x in X_train_all_ctx]) \n",
    "query_book.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "from keras.models import load_model\n",
    "neural_net_b = load_model(f'./Results/{embedding_length}/hist_nn_{book}')\n",
    "output = neural_net_b.predict(query_book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def main(values, title=\"\", size=(14, 1), linewidth=2):\n",
    "    values = (values - values.min())/(values.max() - values.min())\n",
    "\n",
    "    # fig, ax = plt.subplots()\n",
    "    fig, ax = plt.subplots(figsize=size)\n",
    "    # for i, v in enumerate(values):\n",
    "    #     ax.axvline(i, color=colorFader('#1f77b4', 'red', v), linewidth=1) \n",
    "    # plt.plot(values)\n",
    "    # values = np.array(values).flatten()\n",
    "    # plt.bar(range(len(values)), values)\n",
    "    if title:\n",
    "        plt.title(title, fontsize=15)\n",
    "    # ax.set_yticklabels([])\n",
    "    # ax.set_xticklabels([])\n",
    "    # ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def colorFader(c1,c2,mix=0): #fade (linear interpolate) from color c1 (at mix=0) to c2 (mix=1)\n",
    "    c1=np.array(mpl.colors.to_rgb(c1))\n",
    "    c2=np.array(mpl.colors.to_rgb(c2))\n",
    "    return mpl.colors.to_hex((1-mix)*c1 + mix*c2)\n",
    "\n",
    "# main(output, \"len = 1\", 1)\n",
    "# main(output, \"len = 2\", 2)\n",
    "main(output, \"\", (10,1), 2)\n",
    "# main(output, \"\", (28,1), 2, True)\n",
    "\n",
    "# Atomic contexts: Nice to do? - More clear distinction between contexts (too many contexts!), it will give more information of the width of the context. \n",
    "# - try with a height instead?\n",
    "# - try with a binary color?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Embeddings and save\n",
    "2) Load embedding for a model and train it indpendent\n",
    "3) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
