{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sections from dev\\al_experiment\\df_pickle\\sections.pkl\n",
    "import pickle\n",
    "import torch\n",
    "with open('section_embeddings.pkl', 'rb') as f:\n",
    "    embeddings = pickle.load(f)\n",
    "with open('sections.pkl', 'rb') as f:\n",
    "    sections = pickle.load(f)\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('msmarco-distilbert-base-tas-b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tue Herlau, Mikkel N. Schmidt and Morten Mørup\\nIntroduction to Machine Learning\\nand Data Mining\\nLecture notes, Fall 2019, version 1.4b\\nThis document may not be redistributed. All rights belongs to\\nthe authors and DTU.\\nDecember 13, 2019\\nTechnical University of DenmarkNotation cheat sheet\\nMatlab var. Type Size Description\\nX Numeric N × M Data matrix: The rows correspond to N\\ndata objects, each of which contains M at\\ufffetributes.\\nattributeNames Cell array M × 1 Attribute names: Name (string) for each of\\nthe M attributes.\\nN Numeric Scalar Number of data objects.\\nM Numeric Scalar Number of attributes.\\nRegression\\ny Numeric N × 1 Dependent variable (output): For each\\ndata object, y contains an output value\\nthat we wish to predict.\\nClassification\\ny Numeric N × 1 Class index: For each data object, y con\\ufffetains a class index, yn ∈ {0, 1, . . . , C − 1},\\nwhere C is the total number of classes.\\nclassNames Cell array C × 1 Class names: Name (string) for each of the\\nC classes.\\nC Numeric Scalar Number of classes.\\nCross-validation\\nAll variables mentioned above appended\\nwith train or test represent the corre\\ufffesponding variable for the training or test\\nset.\\n? train — — Training data.\\n? test — — Test data.\\nThis book attempts to give a concise introduction to machine-learning concepts. We believe\\nthis is best accomplished by clearly stating what a given method actually does as a sequence of\\nmathematical operations, and use illustrations and text to provide an intuition. We will therefore\\nmake use of tools from linear algebra, probability theory and analysis to describe the methods,\\nfocusing on using as small a set of concepts as possible and strive towards maximal consistency.VI\\nIn the following, vectors will be denoted by lower-case roman letters x, y, . . . and matrices by\\nbolder, upper case roman letters A, B, . . . . A superscript T denote the transpose. For instance\\nA =\\n\\x14\\n−1 0 2\\n1 1 −2\\n\\x15\\nand if x =\\n\\uf8ee\\n\\uf8f0\\n−1\\n4\\n1\\n\\uf8f9\\n\\uf8fb then x\\nT =\\n\\n−1 4 1\\n.\\nThe ith element of a vector is written as xi and the i, j’th element of a matrix as Aij (and sometimes\\nAi,j to avoid ambiguity). In the preceding example, x2 = 4 and A2,3 = −2. During this course the\\nobserved data set, which we feed into our machine learning methods, will consist of N observations\\nwhere each observation consist of a M dimensional vector. For instance if we have N observations\\nx1, · · · , xN then any given observation will consist of M numbers:\\nx =\\n\\nx1 . . . , xM\\nT\\n.\\nFor convenience, we will often combine the observations into an N × M data matrix X\\nX =\\n\\uf8ee\\n\\uf8ef\\n\\uf8f0\\nx\\nT\\n1\\n.\\n.\\n.\\nx\\nT\\nN\\n\\uf8f9\\n\\uf8fa\\n\\uf8fb\\nin which the ith row of X corresponds to the row vector x\\nT\\ni\\n. We will use this notation for our\\ndata matrix and the rows of X will correspond to N observations and the M columns of X will\\ncorrespond to M attributes. Often each of the observations xi will come with a label or target yi\\ncorresponding to a feature of xi which we are interested in predicting. In this case we will collect\\nthe labels in a N-dimensional vector y and the pair (X, y) will be all the data available for the\\nmachine learning method. A more comprehensive translation of the notation as used in this book\\nand in the exercises can be found in the table on the previous page. Finally, the reader should be\\nfamiliar with the big-sigma notation which allows us to conveniently write sums and products of\\nmultiple terms:\\nXn\\ni=1\\nf(i) = f(1) + f(2) + · · · + f(n − 1) + f(n)\\nYn\\ni=1\\nf(i) = f(1) × f(2) × · · · × f(n − 1) × f(n).\\nAs an example, if f(i) = i\\n2 and n = 4 we have\\nX\\n4\\ni=1\\nf(i) = 12 + 22 + 32 + 42 = 30,\\nY\\n4\\ni=1\\nf(i) = 12 × 2\\n2 × 3\\n2 × 4\\n2 = 576.\\x00\\x00\\x00\\x00Course Reading Guide\\nIt is our experience that when students have difficulties understanding a topic of this course, most\\noften probability theory is the culprit. A reason for this is probability theory can be notationally\\nchallenging. For instance:\\nP(X = x|Y = y) (0.1)\\nis, all being equal, a fairly unusual way to use an equality sign. Another reason is many students\\nlast encountered probability theory in conjunction with an introductory statistics course, where\\nthe main theorems are presented using the notation of stochastic variables and measure spaces.\\nEspecially when such a course has an applied focus, there is a tendency terms such as stochastic\\nvariables end up playing a mnemonic role; i.e. as a shorthand for which theorems or rules are\\nsupposed to be used in a given situation. This makes it difficult for students to map their notation\\nonto probabilistic primitives such as events, in particular for multivariate distributions.\\nTo overcome these problems, both chapter 5 and chapter 6 will be concerned with probability\\ntheory. The idea is to provide a ground-up introduction to probability theory with a focus on\\ndistributions that can be represented using well-behaved density functions. We advice a reader to\\nmake absolutely sure he or she understands the definitions in the green boxes in these chapters.\\nThe disadvantage of this approach is the amount of reading material for the first weeks may\\nseem excessively long, and we will therefore use stars, i.e. F, to signify a particular section (including\\nsubsections) is of less significance, perhaps because it recaps material from other courses (such as\\nthe introduction to linear algebra), or because it is technical in nature and is supposed to give a\\nmore in-depth idea of what is going on (c.f. section 5.5 and section 5.4.6).\\nWe obviously advice a reader to do the assigned homework problems (see course website), but\\nfailing that, we strongly encourage a reader to read the homework problems to get an idea about\\nwhat parts of the material is more likely to occur at the exam. The focus in the exam is to either\\nbe able to understand the material well enough to make common-sense inferences about how they\\napply in particular situations, or to concretely apply the methods/definitions to concrete situations.\\nNote solutions to the homework problems are included at the end of this book.\\nBased on feedback in previous semesters, we have begun implementing colored boxes as an aid\\nfor the reader. These boxes are used as follows:VIII\\nMethod: Key definitions or summaries\\nSummarizing a method or particular relevant result. Should be fairly self-contained and\\nrelevant as a how-to resource. Make sure you understand the content.\\nExample: Illustration of how to do something\\nA small (concrete) example of how to calculate something, either because it is exam relevant,\\nor to test how certain definitions are used in practice.\\nTechnical note: A warning or derivation\\nUsed to provide additional details which may be technical, confusing or simply a lot of work.\\nEasily (and sometimes best) skipped.\\nNote the use of boxes is still work in progress and, as with all other aspects of this note, we will\\nbe very happy to get feedback on how to best make use of them.\\nUpdates in version 1.1\\n• Added section 3.4.1 on interpretation of PCA components which will be useful for project 1.\\n• Added section 6.3.4 about the cumulative density function and it’s inverse. This material should\\nbe familiar from a statistics/probability class.\\nUpdates in version 1.2\\n• Added chapter 11 on statistical evaluation and comparison of machine learning models\\n• Renamed chapter 16 to avoid confusion with chapter 11 (no other changes)\\n• Bayesian networks (section 13.3) is now optional reading and will not be part of the exam\\nUpdates in version 1.3\\n• Equation (11.35) for McNemars confidence interval was expressed for the wrong coordinates\\nand have been updated. A small comment was added to the text as an explanation.\\n• Added section 11.2.1 to provide a brief explanation of baseline models (useful for project 2)\\n• Aligned notation in eq. (11.40) with the subsequent notation (ˆs → σ˜)\\nUpdates in 1.4\\n• Fixed typo in eq. (8.16)\\n• Fixed error in definition of n in eq. (18.8) (see discussion on Piazza). Also fixed typo in\\neq. (18.13)Contents\\nNotation cheat sheet . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . V\\nCourse reading guide . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . VI\\nPart I Data: Types, Features and Visualization\\n1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\\n1.1 What is machine learning and data mining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\\n1.1.1 Machine Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\\n1.1.2 Data mining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\n1.1.3 Relationship to artificial intelligence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\n1.1.4 Relationship to other disciplines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\n1.1.5 Why should I care about machine learning. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\n1.2 Machine learning tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n1.2.1 Supervised learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n1.2.2 Unsupervised learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n1.2.3 Reinforcement learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n1.2.4 The machine-learning toolbox . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\n1.3 Basic terminology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\n1.3.1 Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\\n1.3.2 A closer look at what a model doesF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\\n1.4 The machine learning workflow . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\n2 Data and attribute types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\\n2.1 What is a dataset? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\\n2.1.1 Attributes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\n2.1.2 Attribute types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\n2.2 Data issues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\\n2.3 The standard data format . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n2.4 Feature transformations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\\n2.4.1 One-out-of-K coding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25X Contents\\n2.4.2 Binarizing/thresholding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\n3 Principal Component Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\n3.1 Projections and subspacesF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\n3.1.1 Subspaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\\n3.1.2 Projection onto a subspace . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\\n3.2 Principal Component Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\\n3.3 Singular Value Decomposition and PCA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\\n3.3.1 The PCA algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\\n3.3.2 Variance explained by the PCA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\\n3.4 Applications of principal component analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\\n3.4.1 Example 1: Interpreting PCA components . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\\n3.4.2 Example 2: A high-dimensional example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\\n3.4.3 Uses of PCA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\\n4 Summary statistics and measures of similarity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\\n4.1 Attribute statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\\n4.1.1 Covariance and Correlation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\\n4.2 Term-document matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\\n4.3 Measures of distance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\\n4.3.1 The Mahalanobis Distance. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\\n4.4 Measures of similarity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\\n5 Discrete probabilities and information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\\n5.1 Probability basics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\\n5.1.1 A primer on binary propositionsF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65\\n5.1.2 Probabilities and plausibility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65\\n5.1.3 Basic rules of probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\\n5.1.4 Marginalization and Bayes’ theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\\n5.1.5 Mutually exclusive events . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69\\n5.1.6 Equally likely events . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70\\n5.2 Discrete data and stochastic variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74\\n5.2.1 Example: Bayes theorem and the cars dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\\n5.2.2 Generating random numbersF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\n5.2.3 Expectations, mean and variance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78\\n5.3 Independence and conditional independence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79\\n5.4 The Bernoulli, categorical and binomial distributions. . . . . . . . . . . . . . . . . . . . . . . . . . . 80\\n5.4.1 The Bernoulli distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80\\n5.4.2 The categorical distribution. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81\\n5.4.3 Parameter transformations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82\\n5.4.4 Repeated events . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82\\n5.4.5 A learning principle: Maximum likelihood . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83\\n5.4.6 The binomial distributionF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85\\n5.5 Information TheoryF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85Contents XI\\n5.5.1 Measuring information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\\n5.5.2 Entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88\\n5.5.3 Mutual information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89\\n5.5.4 Normalized mutual information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92\\n6 Densities and models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93\\n6.1 Probability densities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93\\n6.1.1 Multiple continuous parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94\\n6.2 Expectations, mean and variance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97\\n6.3 Examples of densities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98\\n6.3.1 The normal and multivariate normal distribution . . . . . . . . . . . . . . . . . . . . . . . . 99\\n6.3.2 Diagonal covariance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\\n6.3.3 The Beta distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102\\n6.3.4 The cumulative density function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103\\n6.3.5 The central limit theoremF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104\\n6.4 Bayesian probabilities and machine learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107\\n6.4.1 Choosing the prior . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109\\n6.5 Bayesian learning in general . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113\\n7 Data Visualization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115\\n7.1 Basic plotting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115\\n7.2 What sets apart a good plot? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121\\n7.3 Visualizing the machine-learning workflowF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123\\n7.3.1 Visualizations to understand loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123\\n7.3.2 Use visualizations to understand mistakes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124\\n7.3.3 Visualization to debug methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125\\n7.3.4 Use visualization for an overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126\\n7.3.5 Illustration of baseline and ceiling performance . . . . . . . . . . . . . . . . . . . . . . . . . . 129\\n7.3.6 Visualizing learning curves . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132XII Contents\\nPart II Supervised learning\\n8 Introduction to classification and regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137\\n8.1 Linear models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137\\n8.1.1 Training the linear regression model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139\\n8.2 Logistic Regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143\\n8.2.1 The confusion matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145\\n8.3 The general linear modelF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149\\n9 Tree-based methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153\\n9.1 Classification trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154\\n9.1.1 Impurity measures and purity gains . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154\\n9.1.2 Controlling tree complexity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158\\n9.2 Regression trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163\\n10 Overfitting and cross-validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165\\n10.1 Cross-validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165\\n10.1.1 A simple example, linear regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165\\n10.1.2 The basic setup for cross-validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167\\n10.1.3 Cross-validation for quantifying generalization . . . . . . . . . . . . . . . . . . . . . . . . . . 170\\n10.1.4 Cross-validation for model selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172\\n10.1.5 Two-layer cross-validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172\\n10.2 Sequential feature selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175\\n10.2.1 Forward Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177\\n10.2.2 Backward Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179\\n10.3 Cross validation of time-series dataF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179\\n10.3.1 The setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179\\n10.3.2 Cross-validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183\\n10.3.3 Two-layer cross-validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184\\n10.4 Visualizing learning curvesF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184\\n10.4.1 The setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187\\n11 Performance evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191\\n11.1 Statistical testing for machine learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191\\n11.2 Statistical primerF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193\\n11.2.1 Baselines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197\\n11.3 Setup I: the training set is fixed . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198\\n11.3.1 Translating to a statistical test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198\\n11.3.2 First task: Evaluation of a single classifier . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 199\\n11.3.3 Comparing two classifiers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202\\n11.3.4 Estimating the generalization error of a regression model . . . . . . . . . . . . . . . . . 205\\n11.3.5 Comparing two regression models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 208Contents XIII\\n11.4 Setup II: The training set is randomF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210\\n11.4.1 A problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211\\n11.4.2 The correlation heuristic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 214\\n12 Nearest neighbor methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215\\n12.1 K-nearest neighbour classification. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215\\n12.1.1 A Bayesian view of the KNN classifierF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216\\n12.2 K-nearest neighbour regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 219\\n12.2.1 Higher-order KNN regressionF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220\\n12.3 Cross-validation and nearest-neighbour methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 223\\n13 Bayesian methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225\\n13.1 Discriminative and generative modeling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225\\n13.1.1 Bayes classifier . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 226\\n13.2 Na¨ıve-Bayes classifier . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227\\n13.2.1 Na¨ıve-Bayes for non-binary data and robust estimation. . . . . . . . . . . . . . . . . . . 229\\n13.3 Bayesian networksF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\n13.3.1 A brief comment on causality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 236\\n14 Regularization and the bias-variance decomposition . . . . . . . . . . . . . . . . . . . . . . . . . 239\\n14.1 Least squares regularization. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239\\n14.1.1 The effect of regularization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241\\n14.2 Bias-variance decomposition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 244\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 249\\n15 Neural Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 251\\n15.1 The feedforward neural network . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 251\\n15.1.1 Artificial neural networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 251\\n15.1.2 The forward pass in details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 252\\n15.2 Training neural networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255\\n15.2.1 Gradient DescentF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 256\\n15.3 Neural networks for classification . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259\\n15.3.1 Neural networks for binary classification . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259\\n15.3.2 Neural networks for multi-class classification . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260\\n15.3.3 Multinomial regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261\\n15.3.4 Flexibility and cross-validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262\\n15.4 Advanced topicsF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262\\n15.4.1 Mini-batching . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262\\n15.4.2 Convolutional neural networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263\\n15.4.3 Autoencoders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 264\\n15.4.4 Recurrent neural networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 264\\n15.4.5 Serious neural network modelling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 265\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 266XIV Contents\\n16 Class imbalance. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269\\n16.1 Dealing with class imbalance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269\\n16.1.1 Resampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270\\n16.1.2 Penalization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270\\n16.2 Area-under-curve (AUC) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 272\\n16.2.1 The confusion matrix and thresholding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 273\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 277\\n17 Ensemble methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279\\n17.1 Introduction to ensemble methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279\\n17.2 Bagging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281\\n17.3 Random Forests . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 284\\n17.4 Boosting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 285\\n17.4.1 AdaBoost . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 285\\n17.4.2 Properties of the AdaBoost algorithmF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 288\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290Contents XV\\nPart III Unsupervised learning\\n18 Distance-based clustering techniques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 293\\n18.1 Types of clusters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 293\\n18.1.1 The distance-based cluster types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 293\\n18.1.2 More elaborate cluster types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 294\\n18.2 K-means clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 294\\n18.2.1 A closer look at the K-means algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 297\\n18.2.2 Practical issues with the K-means algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . 298\\n18.3 Hierarchical agglomerative clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 299\\n18.3.1 Selecting linkage function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 301\\n18.4 Comparing partitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 304\\n18.4.1 Rand index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 308\\n18.4.2 Jaccard similarity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 310\\n18.4.3 Comparing partitions using normalized mutual information . . . . . . . . . . . . . . . 311\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 314\\n19 Mixture models for unsupervised clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 317\\n19.1 The Gaussian mixture model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 317\\n19.2 The EM algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 320\\n19.2.1 Why the EM algorithm worksF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 323\\n19.2.2 Some problems with the EM algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 325\\n19.2.3 Selecting K for the GMM using Cross-validation . . . . . . . . . . . . . . . . . . . . . . . . 326\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 328\\n20 Density estimation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 331\\n20.1 The kernel density estimator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 331\\n20.1.1 Selecting the kernel width λ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 332\\n20.2 Average relative density . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 334\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 338\\n21 Association rule learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 341\\n21.1 Basic concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 341\\n21.1.1 Itemsets and association rules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 342\\n21.1.2 Support . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\n21.1.3 Confidence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\n21.2 The Apriori algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 344\\n21.2.1 An example of the Apriori algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 345\\n21.3 Using the Apriori algorithm to find itemsets with high confidence . . . . . . . . . . . . . . . . 347\\n21.4 Some limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 348\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 349\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 351XVI Contents\\nA Mathematical Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 369\\nElementary notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 370\\nLinear Algebra . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 370\\nAnalysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 371\\nProbability Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 373\\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 375Part I\\nData: Types, Features and Visualization1\\nIntroduction\\nIn this chapter, we will try to define machine learning and data mining, as well as give a high-level\\ngrouping of the various machine-learning methods. Understanding the different machine learning\\ntasks is essential in order to determine which method is suitable in a given situation.\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sections[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: What is class-imbalance\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "============\n",
      "\n",
      "\n",
      "As the example with the Ebola test illustrates class imbalance can make ordinary measures of\n",
      "performance such as accuracy highly misleading because if we just put everything in the largest\n",
      "class our method will seem to have a high accuracy. Furthermore, in many situations class imbalance\n",
      "is not just common but expected, for instance if we are trying to detect fraud in a set of credit card\n",
      "transactions or build a system to recognize obstacles on the road. In this chapter, we will consider\n",
      "a few ways to combat class imbalance in increasing degree of sophistication:\n",
      "Resampling: where the dataset is changed.270 16 Class imbalance\n",
      "Positive class\n",
      "Negative class\n",
      "0 0.2 0.4 0.6\n",
      "0.1\n",
      "0.2\n",
      "0.3\n",
      "TP = 5\n",
      "TN = 2\n",
      "FN = 1\n",
      "FP = 2\n",
      "N = 10\n",
      "Actually\n",
      "Positive\n",
      "Actually\n",
      "Negative\n",
      "Predicted\n",
      "Positive Negative\n",
      "Predicted\n",
      "(False Positive) (True Negative)\n",
      "N\n",
      "+ = 6 (True Positive) (False Negative)\n",
      "N\n",
      "− = 4\n",
      "Fig. 16.1. (Left:) A small N = 10 observation binary classification problem and the classification boundary.\n",
      "(Right:) The confusion matrix of the classifier in the left-hand pane. The inserts (ticks on background)\n",
      "indicate which observations counts towards which numbers in the confusion matrix.\n",
      "Penalization: where the relative importance of the classes are changed.\n",
      "Change performance measure: where we use a performance measure such as area-under-curve\n",
      "(AUC) of the receiver operating characteristic (ROC) which is invariant to class imbalance.\n",
      " (Score: 0.8269)\n",
      "============\n",
      "\n",
      "\n",
      "The simplest way to handle class imbalance is to change the dataset. There are two variants: If\n",
      "the dataset is very large, we can consider under-sampling where we simply remove (by random)\n",
      "observations of the over-represented class until the two classes have the same size. Alternatively, we\n",
      "can try over-sampling where we add copies from the under-sampled class until the two classes have\n",
      "the same size. These approaches are very simple to implement and therefore provide an excellent\n",
      "starting point, however, they also have obvious drawbacks: In the first case we loose information,\n",
      "in the second case we must take into account some methods can be very influenced by duplicated\n",
      "observations.\n",
      " (Score: 0.8250)\n",
      "============\n",
      "\n",
      "\n",
      "Penalization works by scaling the relative importance of the two classes. Recall the definition of the\n",
      "confusion matrix which is reproduced for convenience in fig. 16.1 and which we encountered earlier\n",
      "in section 8.2.1 of chapter 8. In the notation of the confusion matrix the accuracy of the classifier\n",
      "can be written as:\n",
      "Accuracy = TP + TN\n",
      "N\n",
      ".\n",
      "Let’s assume that it is the positive class which is over-represented. We can then consider a “scaled”\n",
      "accuracy measure of the form:\n",
      "Accuracy-scaled = TP\n",
      "2N +\n",
      "+\n",
      "TN\n",
      "2N −\n",
      ".16.1 Dealing with class imbalance 271\n",
      "Let’s assume we are in the imbalanced setting where N + = 1000 and N − = 10. A classifier that\n",
      "puts everything in the positive class would have an accuracy of 1000\n",
      "1010 ≈ 99%, but a scaled accuracy\n",
      "of only 1000\n",
      "2×1000 +\n",
      "0\n",
      "2×10 = 50% corresponding to random guessing (also notice the scaled and true\n",
      "accuracy are both 1 if the classifier is perfect). A disadvantage of the scaled accuracy is that it is also\n",
      "50% if everything is classified as belonging to the negative class which might seem counterintuitive\n",
      "because all but 10 observations are then classified incorrectly!\n",
      "In general, the errors of the classifier are not equally important. Suppose we have credit-card\n",
      "transaction system where the positive class corresponds to a fraudulent transaction and the negative\n",
      "to a non-fraudulent (normal) transaction. In this case labelling a few good transactions as fraud￾ulent, FP, (transactions that are actually negative labelled positive) is not so bad, but labelling\n",
      "fraudulent transactions as good, FN, correspond to a loss of money. We can therefore consider a\n",
      "general measure of the quality of the classifier of the form\n",
      "w1TP + w2FN + w3FP + w4TN, (16.3)\n",
      "where w1, · · · , w4 are constants. As a crude example, in the credit-card system we could choose\n",
      "w1 = 2, w2 = −1000, w3 = −1 and w4 = 0.01 to signify that classifying non-fraudulent transactions\n",
      "as non-fraudulent (which happen very often) is good (weight 0.01), labelling fraudulent transactions\n",
      "as fraudulent is even better (weight 2; keep in mind this happens rarely) but incorrectly labelling a\n",
      "fraudulent transaction as non-fraudulent is very bad (weight −1000). The drawback of this method\n",
      "is that the user has to specify w1, w2, w3 and w4.\n",
      "If we consider the credit card transaction problem, we should ask ourselves why it is so bad to\n",
      "classify all transactions as being without fraud. The obvious answer is that it is bad because we\n",
      "loose customers and, ultimately, money. A way around the problem could therefore be to figure out\n",
      "the expected loss of money for each classification outcome: How much do we expect to loose by\n",
      "(incorrectly) closing a credit card and annoy a customer and how much do we expect to loose by\n",
      "not closing a credit card in time? This information could in turn be used to select w1, . . . , w4 in\n",
      "the penalization scheme eq. (16.3). Keep in mind that especially in medical applications this may\n",
      "lead to fairly uninviting utilitarianism when bad medical decisions are balanced against monetary\n",
      "concerns.\n",
      "Precision and recall\n",
      "Two terms relating to the performance of a classifier which roughly falls within the above category\n",
      "is the precision and recall. They are simply defined as:\n",
      "Recall: TP\n",
      "TP + FN\n",
      "=\n",
      "TP\n",
      "#{Observations in the positive class}\n",
      ",\n",
      "Precision: TP\n",
      "TP + FP\n",
      "=\n",
      "TP\n",
      "#{Observations predicted as positive}\n",
      ".\n",
      "The recall is also known as the true positive rate which we will see again in a moment. The recall\n",
      "can trivially be improved by labelling all observations as positive, however the precision will suffer\n",
      "if all observations are labelled positive. Both of these measures are different from for instance the\n",
      "accuracy in that they place more emphasis on the positive class. For instance in a credit-card fraud\n",
      "detection system, where fraud corresponds to the positive class, high recall is the measure of how\n",
      "many actually cases of fraud are caught. Meanwhile precision might be appropriate in a case where\n",
      "false positive comes at a significant cost, for instance medical screening.272 16 Class imbalance\n",
      "Negative, yi = 0\n",
      "Positive, yi = 1\n",
      "yˆi = f(x, w)\n",
      "−5 0 5 10\n",
      "0\n",
      "0.05\n",
      "0.1\n",
      "0.15\n",
      "0.2\n",
      "0.25\n",
      "0.3\n",
      "Negative, yi = 0\n",
      "Positive, yi = 1\n",
      "yˆi = f(x, w)\n",
      "Density of observations\n",
      "−5 0 5 10\n",
      "0\n",
      "0.05\n",
      "0.1\n",
      "0.15\n",
      "0.2\n",
      "0.25\n",
      "0.3\n",
      "Fig. 16.2. A dataset consisting of a positive yi = 1 class and a negative yi = 0 class. The x-position indicates\n",
      "the predicted y-value by a classification model. In the right plane we have plotted the same dataset but\n",
      "with the density of each class which is easier to visualize and which will be used in the following.\n",
      "16.2 Area-under-curve (AUC)\n",
      "The final strategy we will consider for the class-imbalance problem is to change the performance\n",
      "measure to implicitly take class imbalance into account. In order to do so we need to take a step back\n",
      "and consider what a classifier actually does. Consider therefore a standard two-class classification\n",
      "problem with observations xi and output yi where yi = 0 means observations i belongs to the\n",
      "negative class and yi = 1 means observations i belongs to the positive class. Suppose we build a\n",
      "classifier that assigns to each observation i a number ˆyi\n",
      "yˆi = f(xi\n",
      ", w).\n",
      "In many practical situations, the number ˆyi will be continuous and only indicate a relative “propen￾sity” for i to belong to a given class according to the classifier, see fig. 16.2. For instance in logistic\n",
      "regression, ˆyi\n",
      "is a (continuous) probability in the interval [0, 1] such that the higher ˆyi\n",
      "is the more\n",
      "likely it is to belong to the positive class.\n",
      "How do we evaluate such a classifier? The first step is to translate the continuous numbers ˆyi\n",
      "into binary class-predictions. The simplest way is to introduce a parameter θ and simply assign all\n",
      "i where ˆyi > θ to the positive class and all i where ˆyi ≤ θ to the negative class. In fig. 16.3 is shown\n",
      "two different thresholds. Notice, the different thresholds have a large influence on the behaviour of\n",
      "the classifier: If we use the high (shown in the left plot) threshold, it is very unlikely to ever say\n",
      "an observation that in fact is negative (yi = 0) belongs to the positive class, whereas it will be\n",
      "slightly prone to falsely saying an observation which is in fact positive (yi = 1) is negative. The\n",
      "other threshold has the opposing effect. Since the threshold is chosen arbitrarily, when we wish to\n",
      "discuss the performance of a classifier f, we must take into account the different threshold values.\n",
      "This requires some terminology.16.2 Area-under-curve (AUC) 273\n",
      "Negative, yi = 0\n",
      "Positive, yi = 1\n",
      "Labelled as positive\n",
      "Labelled as Negative\n",
      "← θ\n",
      "yˆi = f(x, w)\n",
      "Density of observations\n",
      "−5 0 5 10\n",
      "0\n",
      "0.05\n",
      "0.1\n",
      "0.15\n",
      "0.2\n",
      "0.25\n",
      "0.3\n",
      "Negative, yi = 0\n",
      "Positive, yi = 1\n",
      "Labelled as positive\n",
      "Labelled as Negative\n",
      "← θ\n",
      "yˆi = f(x, w)\n",
      "Density of observations\n",
      "−5 0 5 10\n",
      "0\n",
      "0.05\n",
      "0.1\n",
      "0.15\n",
      "0.2\n",
      "0.25\n",
      "0.3\n",
      "Fig. 16.3. The dataset considered in fig. 16.2 with a positive yi = 1 class and a negative yi = 0 class and\n",
      "where the x-position indicates the predicted y-value by a classification model. If we threshold the classifier\n",
      "at the value θ the choice of this threshold value has a large influence on what will be labelled as positive\n",
      "and negative.\n",
      " (Score: 0.7630)\n",
      "============\n",
      "\n",
      "\n",
      "Some machine-learning terminology such as supervised or unsupervised learning is not fully settled\n",
      "in the literature and specific definitions often become overly technical. We will therefore first provide\n",
      "some examples of various tasks and types of learning before stating more exact definitions.\n",
      " (Score: 0.7301)\n",
      "============\n",
      "\n",
      "\n",
      "The generalization error is such an important quantity it can be used as a qualitative pointer to\n",
      "model problems, here illustrated using learning curves. A learning curve refers to how the perfor￾mance of a given method change as a function of a key quantity or parameter. We have already\n",
      "encountered examples of learning curves, for instance in fig. 7.15 we considered a schematic illus￾tration of learning as a function of computation time and in fig. 1.11 we considered performance as\n",
      "a function of training set size.\n",
      "In this chapter, we will try to provide an intuitive feeling for how different shapes of learning\n",
      "curves may point to different problems (or lack therefore) with a given method. A word of warning:\n",
      "This discussion should not be taken too literal, and a reader should not expect their curves to\n",
      "re-produce those in this section exactly, as they will depend quite strongly on the specifics of the\n",
      "chosen method, evaluation metric and data set. For this reason the section is marked with a F.\n",
      " (Score: 0.7283)\n"
     ]
    }
   ],
   "source": [
    "query = 'What is class-imbalance'\n",
    "query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "# Find index in corpus with highest cosine similarity\n",
    "cos_scores = util.pytorch_cos_sim(query_embedding, embeddings)[0]\n",
    "top_results = torch.topk(cos_scores, k=5)\n",
    "print(\"\\n\\n======================\\n\\n\")\n",
    "print(\"Query:\", query)\n",
    "print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "for score, idx in zip(top_results[0], top_results[1]):\n",
    "    print(\"============\\n\")\n",
    "    print(sections[idx], \"(Score: {:.4f})\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
