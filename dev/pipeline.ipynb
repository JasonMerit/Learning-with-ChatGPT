{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypdfium2 as pdfium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pdfium.PdfDocument(\"./02450_Book.pdf\")\n",
    "\n",
    "text_all = \"\"\n",
    "for page in pdf:\n",
    "    textpage = page.get_textpage()\n",
    "    text_all += \" \".join(textpage.get_text_range().splitlines())\n",
    "\n",
    "\n",
    "text_sentences = text_all.split('. ')\n",
    "text_sentences = [seg for seg in text_sentences if len(seg)>10]\n",
    "\n",
    "text_segments = []\n",
    "seg = \"\"\n",
    "threshold = 1000 #chars\n",
    "for s in text_sentences:\n",
    "    if len(seg)+len(s)>threshold:\n",
    "        text_segments.append(seg.strip())\n",
    "        seg = \"\"\n",
    "    else:\n",
    "        seg+=f'{s} '"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic query generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5TokenizerFast, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = T5TokenizerFast.from_pretrained(\"lmsys/fastchat-t5-3b-v1.0\")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"lmsys/fastchat-t5-3b-v1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = tokenizer([f'Give a list of 2 questions that can be answered with the following context: \\'\\'\\'{seg}\\'\\'\\'' for seg in text_segments[52:53]], padding=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[f'Give a list of 2 questions that can be answered with the following context: \\'\\'\\'{seg}\\'\\'\\'' for seg in text_segments[52:53]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(**inp, do_sample=True, max_new_tokens=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(*output, skip_special_tokens=True, spaces_between_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained('BeIR/query-gen-msmarco-t5-large-v1')\n",
    "model = T5ForConditionalGeneration.from_pretrained('BeIR/query-gen-msmarco-t5-large-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for ctx in tqdm.tqdm(text_segments):\n",
    "    input_ids = tokenizer.encode(ctx, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            max_length=256,\n",
    "            do_sample=True,\n",
    "            top_p=0.95,\n",
    "            num_return_sequences=2)\n",
    "\n",
    "    for i in range(len(outputs)):\n",
    "        query = tokenizer.decode(outputs[i], skip_special_tokens=True)\n",
    "        data.append({'question':f'{query}?','context':ctx})\n",
    "\n",
    "df_questions = pd.DataFrame(columns=['question', 'context'], data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./df_questions.pkl', 'wb') as f:\n",
    "    f.write(pickle.dumps(df_questions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating vector embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Neural Search/data/2450.pkl', 'rb') as f:\n",
    "    df_questions = pickle.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_ctx_short = df_questions['context'].unique()\n",
    "\n",
    "ctx_mapping_short_to_medium = {}\n",
    "\n",
    "for i in range(len(u_ctx_short)-1):\n",
    "    if i % 2 == 0:\n",
    "        ctx_mapping_short_to_medium[u_ctx_short[i]] = u_ctx_short[i]+u_ctx_short[i+1]\n",
    "    else:\n",
    "        ctx_mapping_short_to_medium[u_ctx_short[i]] = u_ctx_short[i-1]+u_ctx_short[i]\n",
    "\n",
    "\n",
    "data = []\n",
    "for ctx in df_questions['context']:\n",
    "    val = ctx_mapping_short_to_medium.get(ctx)\n",
    "    if val:\n",
    "        data.append(val)\n",
    "    else:\n",
    "        data.append(ctx)\n",
    "\n",
    "df_questions['context_medium'] = data\n",
    "\n",
    "u_ctx_medium = df_questions['context_medium'].unique()\n",
    "\n",
    "ctx_mapping_medium_to_long = {}\n",
    "\n",
    "n = len(u_ctx_medium)\n",
    "for i in range(n-1,0,-1):\n",
    "    if i % 2 == n % 2:\n",
    "        ctx_mapping_medium_to_long[u_ctx_medium[i]] = u_ctx_medium[i]+u_ctx_medium[i+1]\n",
    "    else:\n",
    "        ctx_mapping_medium_to_long[u_ctx_medium[i]] = u_ctx_medium[i-1]+u_ctx_medium[i]\n",
    "\n",
    "data = []\n",
    "for ctx in df_questions['context_medium']:\n",
    "    val = ctx_mapping_medium_to_long.get(ctx)\n",
    "    if val:\n",
    "        data.append(val)\n",
    "    else:\n",
    "        data.append(ctx)\n",
    "\n",
    "df_questions['context_long'] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3595.962742175857"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(c) for c in df_questions['context_long'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions.drop(columns=['context','question','context_medium'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions.rename(columns={\"context_long\":\"context\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Neural Search/data/ww2_long_contexts.pkl','wb') as f:\n",
    "    f.write(pickle.dumps(df_questions['context'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "df_questions['fetched'] = False\n",
    "df_questions['fetched_time'] = 0\n",
    "df_questions['choice'] = np.nan\n",
    "with open('../web/chatta/ab_test/context_length/df_data_original.pkl','wb') as f:\n",
    "    f.write(pickle.dumps(df_questions.rename(columns={\"context\": \"short\", \"context_medium\": \"medium\",\"context_long\":\"long\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../web/chatta/ab_test/context_length/saves/20.pkl','rb') as f:\n",
    "    test = pickle.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test[\"question\"]==\"How is the mean of the silly die calculated using the given probabilities?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How is the mean of the silly die calculated using the given probabilities?\"\n",
    "context = df_questions.iloc[100]['context']\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": f'Act as a teacher. A student asks the following question: {question}. Use the following context to answer the question: {context}'}\n",
    "    ]\n",
    "    )\n",
    "\n",
    "answer_ctx = completion.choices[0].message.content\n",
    "answer_ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "embedding_model = SentenceTransformer('sentence-transformers/multi-qa-mpnet-base-dot-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_embeddings = {q: embedding_model.encode(q) for q in df_questions['question'].unique()}\n",
    "context_embeddings = {ctx: embedding_model.encode(ctx) for ctx in df_questions['context'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Neural Search/data/2450_question_embeddings.pkl', 'wb') as f:\n",
    "    f.write(pickle.dumps(question_embeddings))\n",
    "with open('./Neural Search/data/2450_context_embeddings_1000.pkl', 'wb') as f:\n",
    "    f.write(pickle.dumps(context_embeddings))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "is_added = defaultdict(lambda: 0)\n",
    "\n",
    "contexts = df_questions['context'].unique()\n",
    "data = []\n",
    "\n",
    "for i,row in df_questions.iterrows():\n",
    "    #Avoid duplicate data-points. Skip if question if it has already been matched with contexts\n",
    "    if is_added[row['question']]:\n",
    "        continue\n",
    "\n",
    "    dft = pd.DataFrame(columns=['context', 'question', 'label'])\n",
    "    dft['context'] = contexts\n",
    "    dft['question'] = row['question']\n",
    "    dft['label'] = 0\n",
    "\n",
    "    #Update label to 1 if question was generated from the context\n",
    "    for ctx in df_questions.loc[df_questions['question'] == row['question'],'context']:\n",
    "        dft.loc[dft['context']==ctx,'label'] = 1\n",
    "\n",
    "    data.append(dft)\n",
    "\n",
    "    is_added[row['question']] = 1\n",
    "df = pd.concat(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_q = int(0.25*len(df['question'].unique()))\n",
    "test_q = np.random.choice(df['question'].unique(), n_test_q, replace=False)\n",
    "\n",
    "df_test = df.loc[df['question'].isin(test_q)]\n",
    "df_test.reset_index(inplace=True, drop=True)\n",
    "df_train = df.loc[~df['question'].isin(test_q)]\n",
    "df_train.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting context question pairs to vector embeddings\n",
    "\n",
    "X_train = np.array([np.concatenate((context_embeddings[ctx],question_embeddings[q])) for ctx,q in zip(df_train['context'].values, df_train['question'].values)])\n",
    "y_train = np.array([i for i in df_train['label'].values])\n",
    "\n",
    "X_test = np.array([np.concatenate((context_embeddings[ctx],question_embeddings[q])) for ctx,q in zip(df_test['context'].values, df_test['question'].values)])\n",
    "y_test = np.array([i for i in df_test['label'].values])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training NS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "neural_net = Sequential()\n",
    "neural_net.add(Dense(768, input_dim=768*2, activation='relu'))\n",
    "neural_net.add(Dense(384, activation='relu'))\n",
    "neural_net.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "neural_net.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class BatchBalancerSequence(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x_p = x_set[y_set==1]\n",
    "        self.x_n = x_set[y_set==0]\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_size_n = batch_size//2\n",
    "\n",
    "    def __len__(self):\n",
    "        #For each n y=0 we will oversample with n y=1\n",
    "        return int(np.ceil(len(self.x_n)*2 / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        low = idx * self.batch_size_n\n",
    "        # Cap upper bound at array length; the last batch may be smaller\n",
    "        # if the total number of items is not a multiple of batch size.\n",
    "        high = min(low + self.batch_size_n, len(self.x_n))\n",
    "        batch_x = self.x_n[low:high]\n",
    "        n_neg = len(batch_x)\n",
    "        batch_y = [0]*n_neg\n",
    "        \n",
    "        x_p_idx = np.random.choice(len(self.x_p), n_neg, replace=False)\n",
    "        batch_x = np.concatenate((batch_x, self.x_p[x_p_idx]))\n",
    "        batch_y = np.append(batch_y, [1]*n_neg)\n",
    "\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = neural_net.fit(BatchBalancerSequence(X_train, y_train, 128), epochs=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc(name, labels, predictions, **kwargs):\n",
    "  fp, tp, _ = roc_curve(labels, predictions)\n",
    "\n",
    "  plt.plot(100*fp, 100*tp, label=f'{name} AUC: {roc_auc_score(labels, predictions):.3f}', linewidth=2, **kwargs)\n",
    "  plt.xlabel('False positives [%]')\n",
    "  plt.ylabel('True positives [%]')\n",
    "  plt.xlim([-0.5,100])\n",
    "  plt.ylim([0,100.5])\n",
    "  plt.grid(True)\n",
    "  ax = plt.gca()\n",
    "  ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_nn_preds = neural_net.predict(X_test)\n",
    "y_cosine_preds = [np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b)) for a,b in zip(X_test[:,:1536//2], X_test[:,1536//2:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plot_roc(\"NS\", y_test, y_nn_preds)\n",
    "plot_roc(\"Cosine\", y_test, y_cosine_preds)\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Neural Search/data/y_2450_labels.pkl', 'wb') as f:\n",
    "    f.write(pickle.dumps(y_test))\n",
    "with open('./Neural Search/data/y_2450_nn.pkl', 'wb') as f:\n",
    "    f.write(pickle.dumps(y_nn_preds))\n",
    "with open('./Neural Search/data/y_2450_cos.pkl', 'wb') as f:\n",
    "    f.write(pickle.dumps(y_cosine_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[:653, 768:][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_q1 = neural_net.predict(X_test[:652])\n",
    "with open('./Neural Search/data/q1_preds.pkl', 'wb') as f:\n",
    "    f.write(pickle.dumps(preds_q1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.iloc[650:655]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions.iloc[405]['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plot_roc(\"NS\", y_test, y_nn_preds)\n",
    "plot_roc(\"Cosine\", y_test, y_cosine_preds)\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plot_roc(\"NS\", y_test, y_nn_preds)\n",
    "plot_roc(\"Cosine\", y_test, y_cosine_preds)\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plot_roc(\"NS\", y_test, y_nn_preds)\n",
    "plot_roc(\"Cosine\", y_test, y_cosine_preds)\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plot_roc(\"NS\", y_test, y_nn_preds)\n",
    "plot_roc(\"Cosine\", y_test, y_cosine_preds)\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plot_roc(\"NS\", y_test, y_nn_preds)\n",
    "plot_roc(\"Cosine\", y_test, y_cosine_preds)\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plot_roc(\"NS\", y_test, y_nn_preds)\n",
    "plot_roc(\"Cosine\", y_test, y_cosine_preds)\n",
    "plt.legend(loc='lower right')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
