{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "stop = set(stopwords.words(\"english\"))\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1 0 0 0 1 0 1 1 0]\n",
      " [0 0 0 0 1 0 0 1 0 1 0 1]\n",
      " [1 1 0 0 0 1 1 1 1 0 0 0]] \n",
      "\n",
      "[[0 1 0 0 0 0 1 1]\n",
      " [0 0 1 0 0 0 1 0]\n",
      " [1 0 0 1 1 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "def bow(corpus):\n",
    "    filtered_corpus = [\" \".join([word.lower() for word in word_tokenize(document) if word.lower() not in stop]) for document in corpus]\n",
    "    return np.array(vectorizer.fit_transform(filtered_corpus).toarray())\n",
    "\n",
    "allsentences = [\"Joe waited for the train\", \"The train was late\", \"Mary and Samantha took the bus\"]\n",
    "filtered_allsentences = [\" \".join([word.lower() for word in word_tokenize(sentence) if word.lower() not in stop]) for sentence in allsentences]\n",
    "\n",
    "X = vectorizer.fit_transform(allsentences).toarray()\n",
    "print(X,'\\n')\n",
    "X = vectorizer.fit_transform(filtered_allsentences).toarray()\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Joe waited for the train', 'The train was late', 'Mary and Samantha took the bus']\n",
      "12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Why the len diff?\n",
    "print(allsentences)\n",
    "X = vectorizer.fit_transform(allsentences).toarray()\n",
    "print(len(X[0]))\n",
    "\n",
    "# count number of unique words\n",
    "counts = set()\n",
    "for s in allsentences:\n",
    "    counts.update(s.split())\n",
    "len(counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look up best sentence given query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 1, 1, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = bow(allsentences)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def look_up(query, corpus, top_hits=1):\n",
    "    assert top_hits <= len(corpus), \"top_hits must be less than or equal to the number of documents in the corpus\"\n",
    "    \n",
    "    # filter query\n",
    "    query = \" \".join([word.lower() for word in word_tokenize(query) if word.lower() not in stop])\n",
    "    query = vectorizer.transform([query]).toarray()\n",
    "    query = np.array(query[0])\n",
    "    product = query @ corpus.T\n",
    "    return product.argsort()[-top_hits:][::-1]\n",
    "\n",
    "look_up(\"Joe waited for the train\", corpus, top_hits=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applied to history data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get book\n",
    "book = 'ww2'\n",
    "embedding_length = 1000\n",
    "with open(f'neural_search/Embeddings/{book}_context_embeddings_{embedding_length}.pkl', 'rb') as f:\n",
    "    context_embeddings = pickle.loads(f.read())\n",
    "book = list(context_embeddings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(251, 4736)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = bow(book)\n",
    "corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([239], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "look_up(\"The Origins of the Second World War\", corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Bell’s The Origins of the Second World War in Europe (London, 1986) Slightly dated but still useful is Esmonde Robertson’s edited collection  of essays, The Origins of the Second World War (London, 1971), with contributions from  A.J.P.Taylor, Alan Bullock, Hugh Trevor-Roper and Tim Mason amongst others Clearly  students will want to see why there was so much controversy over Taylor’s interpretation  by reading A.J.P.Taylor, The Origins of the Second World War (London, 1961; second  edition, with new introduction, 1963) This should be read in conjunction with two  stimulating collections of essays edited by Gordon Martel, The Origins of the Second  World War Reconsidered: The A.J.P.Taylor Debate After Twenty-Five Years (London,  1986) and The Origins of the Second World War Reconsidered: A.J.P.Taylor and the  Historians (London, 1999)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book[239]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
