{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "stop = set(stopwords.words(\"english\"))\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1 0 0 0 1 0 1 1 0]\n",
      " [0 0 0 0 1 0 0 1 0 1 0 1]\n",
      " [1 1 0 0 0 1 1 1 1 0 0 0]] \n",
      "\n",
      "[[0 1 0 0 0 0 1 1]\n",
      " [0 0 1 0 0 0 1 0]\n",
      " [1 0 0 1 1 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "def bog(corpus):\n",
    "    filtered_corpus = [\" \".join([word.lower() for word in word_tokenize(document) if word.lower() not in stop]) for document in corpus]\n",
    "    return np.array(vectorizer.fit_transform(filtered_corpus).toarray())\n",
    "\n",
    "allsentences = [\"Joe waited for the train\", \"The train was late\", \"Mary and Samantha took the bus\"]\n",
    "filtered_allsentences = [\" \".join([word.lower() for word in word_tokenize(sentence) if word.lower() not in stop]) for sentence in allsentences]\n",
    "\n",
    "X = vectorizer.fit_transform(allsentences).toarray()\n",
    "print(X,'\\n')\n",
    "X = vectorizer.fit_transform(filtered_allsentences).toarray()\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Joe waited for the train', 'The train was late', 'Mary and Samantha took the bus']\n",
      "12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Why the len diff?\n",
    "print(allsentences)\n",
    "X = vectorizer.fit_transform(allsentences).toarray()\n",
    "print(len(X[0]))\n",
    "\n",
    "# count number of unique words\n",
    "counts = set()\n",
    "for s in allsentences:\n",
    "    counts.update(s.split())\n",
    "len(counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look up best sentence given query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1],\n",
       "       [1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "corpus = np.array(X)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "bog_corpus = bog(allsentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0]\n",
      "[0] \n",
      "\n",
      "[1 0 0]\n",
      "[2 0 1] \n",
      "\n",
      "[0 1 1]\n",
      "[1] \n",
      "\n",
      "[0 1 1]\n",
      "[2 1 0] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def look_up(query, top_hits=0):\n",
    "    assert top_hits <= len(corpus), \"top_hits must be less than or equal to the number of documents in the corpus\"\n",
    "    \n",
    "    # filter query\n",
    "    query = \" \".join([word.lower() for word in word_tokenize(query) if word.lower() not in stop])\n",
    "    query = vectorizer.transform([query]).toarray()\n",
    "    query = np.array(query[0])\n",
    "\n",
    "    product = query @ bog_corpus.T\n",
    "    # return top 5 results\n",
    "    print(product)\n",
    "    return np.argpartition(product, -top_hits)[-top_hits:][::-1] if top_hits else [product.argmax()]\n",
    "    # return product.argsort()[-top_hits:][::-1] if top_hits else [product.argmax()]\n",
    "\n",
    "    # calculate cosine similarity\n",
    "    return query @ corpus.T / (np.linalg.norm(query) * np.linalg.norm(corpus, axis=1))\n",
    "\n",
    "print(look_up(\"What is Joe waiting for?\"), '\\n')\n",
    "print(look_up(\"What is Joe waiting for?\", 3), '\\n')\n",
    "print(look_up(\"Was Mary too late for the the?\"), '\\n')\n",
    "print(look_up(\"Was Mary too late for the the?\", 3), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5 2 1 9 0 7 8 3 6]\n",
      "[4 6 7 9]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([9, 4, 4, 3, 3, 9, 0, 4, 6, 0])\n",
    "A = np.arange(10)\n",
    "# shuffle A\n",
    "np.random.shuffle(A)\n",
    "print(A)\n",
    "ind = np.argpartition(A, -4)[-4:][::-1]\n",
    "print(ind)\n",
    "# print(A[ind])\n",
    "# print(ind[np.argsort(A[ind])])\n",
    "# sort A\n",
    "# A.argsort()\n",
    "# print(A)\n",
    "# A.sort()[-5:][::-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applied to history data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The Origins of the Second World War  1933–194...</td>\n",
       "      <td>What is the focus of the book \"The Origins of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Origins of the Second World War  1933–194...</td>\n",
       "      <td>Who is Ruth Henig and what is her background i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Origins of the Second World War  1933–194...</td>\n",
       "      <td>What are some of the factors that the book ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Origins of the Second World War  1933–194...</td>\n",
       "      <td>How has the second edition of the book been up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The Origins of the Second World War  1933–194...</td>\n",
       "      <td>What is included in the Guide to Further Readi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            context  \\\n",
       "0      0   The Origins of the Second World War  1933–194...   \n",
       "1      1   The Origins of the Second World War  1933–194...   \n",
       "2      2   The Origins of the Second World War  1933–194...   \n",
       "3      3   The Origins of the Second World War  1933–194...   \n",
       "4      4   The Origins of the Second World War  1933–194...   \n",
       "\n",
       "                                            question  \n",
       "0  What is the focus of the book \"The Origins of ...  \n",
       "1  Who is Ruth Henig and what is her background i...  \n",
       "2  What are some of the factors that the book ana...  \n",
       "3  How has the second edition of the book been up...  \n",
       "4  What is included in the Guide to Further Readi...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data\n",
    "import pickle\n",
    "with open(f'Neural Search/data/ww2.pkl', 'rb') as f:\n",
    "    df_data = pickle.load(f)\n",
    "df_data.reset_index(inplace=True)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the corpus\n",
    "corpus = df_data['context'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 580)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = list(set(corpus))[0:10]\n",
    "bog_corpus = bog(corpus)\n",
    "bog_corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 580)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "look_up(\"The Origins of the Second World War\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' As the American historian Sally Marks has noted, Hitler’s aims  were more vast, his ideology very different and his methods much more confrontational  than those of any previous German leaders By the 1990s, Taylor’s interpretation of  Hitler and of the origins of the Second World War had been vigorously rejected by the  great majority of historians researching inter-war history David Kaiser’s verdict, in  Modern Germany Reconsidered, edited by Gordon Martel and published in 1992, was  that Taylor’s views that ‘Hitler did not intend war in 1939 and lacked a real plan for the  conquest of Europe and of the world, and that other governments played a crucial role in  unleashing German expansionism’ can no longer be regarded as valid  However, by this time, a new debate had been raging for some years about the extent  to which the course of Nazi foreign policy had been decisively and exclusively shaped by  Hitler'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(corpus))[7]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
