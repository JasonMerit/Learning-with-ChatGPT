{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pypdfium2 as pdfium\n",
        "import re\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import openai\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "openai.api_key = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "pdf = pdfium.PdfDocument(\"../02450_Book.pdf\")\n",
        "\n",
        "text_all = \"\"\n",
        "for page in pdf:\n",
        "    textpage = page.get_textpage()\n",
        "    text_all += \" \".join(textpage.get_text_range().splitlines())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "text_sentences = list(re.split('([\\.\\?\\!]) ', text_all))\n",
        "#text_sentences = [''.join(x) for x in zip(text_sentences[0::2], text_sentences[1::2])]\n",
        "text_sentences = [s for s in text_sentences if len(s)>10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "text_segments = []\n",
        "seg = \"\"\n",
        "threshold = 1000 #chars\n",
        "for s in text_sentences:\n",
        "    # if len(s)>threshold:\n",
        "    #     print(\"sentence too long...\")\n",
        "    if len(seg)+len(s)>threshold:\n",
        "        text_segments.append(seg.strip())\n",
        "        seg = \"\"\n",
        "    else:\n",
        "        seg+=f' {s}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Tue Herlau, Mikkel N Schmidt and Morten Mørup Introduction to Machine Learning and Data Mining Lecture notes, Spring 2022, version 1.0 Version for print This document may not be redistributed All rights belongs to the authors and DTU April 5, 2022 Technical University of DenmarkNotation cheat sheet Matlab var Type Size Description X Numeric N × M Data matrix: The rows correspond to N data objects, each of which contains M at\\ufffetributes attributeNames Cell array M × 1 Attribute names: Name (string) for each of the M attributes N Numeric Scalar Number of data objects M Numeric Scalar Number of attributes Regression y Numeric N × 1 Dependent variable (output): For each data object, y contains an output value that we wish to predict Classification y Numeric N × 1 Class index: For each data object, y con\\ufffetains a class index, yn ∈ {0, 1,  , C − 1}, where C is the total number of classes classNames Cell array C × 1 Class names: Name (string) for each of the C classes',\n",
              " 'Cross-validation All variables mentioned above appended with train or test represent the corre\\ufffesponding variable for the training or test set ⋆ train — — Training data ⋆ test — — Test data This book attempts to give a concise introduction to machine-learning concepts We believe this is best accomplished by clearly stating what a given method actually does as a sequence of mathematical operations, and use illustrations and text to provide an intuition We will therefore make use of tools from linear algebra, probability theory and analysis to describe the methods, focusing on using as small a set of concepts as possible and strive towards maximal consistency.VI In the following, vectors will be denoted by lower-case roman letters x, y,  and matrices by bolder, upper case roman letters A, B,  A superscript T denote the transpose For instance A = \\x14 −1 0 2 1 1 −2 \\x15 and if x = \\uf8ee \\uf8f0 −1 4 1 \\uf8f9 \\uf8fb then x T =  −1 4 1',\n",
              " 'In the preceding example, x2 = 4 and A2,3 = −2 During this course the observed data set, which we feed into our machine learning methods, will consist of N observations where each observation consist of a M dimensional vector For instance if we have N observations x1, · · · , xN then any given observation will consist of M numbers: x =  x1  For convenience, we will often combine the observations into an N × M data matrix X X = \\uf8ee \\uf8ef \\uf8f0 x T 1  x T N \\uf8f9 \\uf8fa \\uf8fb in which the ith row of X corresponds to the row vector x T i  We will use this notation for our data matrix and the rows of X will correspond to N observations and the M columns of X will correspond to M attributes Often each of the observations xi will come with a label or target yi corresponding to a feature of xi which we are interested in predicting In this case we will collect the labels in a N-dimensional vector y and the pair (X, y) will be all the data available for the machine learning method',\n",
              " 'Finally, the reader should be familiar with the big-sigma notation which allows us to conveniently write sums and products of multiple terms: Xn i=1 f(i) = f(1) + f(2) + · · · + f(n − 1) + f(n) Yn i=1 f(i) = f(1) × f(2) × · · · × f(n − 1) × f(n) As an example, if f(i) = i 2 and n = 4 we have X 4 i=1 f(i) = 12 + 22 + 32 + 42 = 30, Y 4 i=1 f(i) = 12 × 2 2 × 3 2 × 4 2 = 576.\\x00\\x00\\x00\\x00Course Reading Guide It is our experience that when students have difficulties understanding a topic of this course, most often probability theory is the culprit A reason for this is probability theory can be notationally challenging For instance: P(X = x|Y = y) (0.1) is, all being equal, a fairly unusual way to use an equality sign Another reason is many students last encountered probability theory in an introductory statistics course, where the main theorems are presented using the notation of stochastic variables and measure spaces',\n",
              " 'as a shorthand for which theorems or rules are supposed to be used in a given situation This makes it difficult for students to map their notation onto probabilistic primitives such as events, in particular for multivariate distributions To overcome these problems, both chapter 5 and chapter 6 will be concerned with probability theory The idea is to provide a ground-up introduction to probability theory with a focus on distributions that can be represented using well-behaved density functions We advice a reader to make absolutely sure he or she understands the definitions in the green boxes in these chapters The disadvantage of this approach is the amount of reading material for the first weeks may seem excessively long, and we will therefore use stars, i.e',\n",
              " 'section 5.5 and section 5.4.6) We obviously advice a reader to do the assigned homework problems (see course website), but failing that, we strongly encourage a reader to read the homework problems to get an idea about what parts of the material is more likely to occur at the exam The focus in the exam is to either be able to understand the material well enough to make common-sense inferences about how it applies in particular situations or alternatively, to apply the methods/definitions to concrete situations Note solutions to the homework problems are included at the end of this book Based on feedback in previous semesters, we have begun implementing colored boxes as an aid for the reader These boxes are used as follows:VIII Method: Key definitions or summaries Summarizing a method or particular relevant result Should be fairly self-contained and relevant as a how-to resource Make sure you understand the content',\n",
              " 'Technical note: A warning or derivation Used to provide additional details which may be technical, confusing or simply a lot of work Easily (and sometimes best) skipped Updates in version 1.1 \\x88 Added missing I in eq (5.40), expression for entropyContents Notation cheat sheet  V Course reading guide  VI Part I Data: Types, Features and Visualization 1 Introduction  3 1.1 What is machine learning and data mining  3 1.1.1 Machine Learning  3 1.1.2 Data mining  4 1.1.3 Relationship to artificial intelligence  4 1.1.4 Relationship to other disciplines  4 1.1.5 Why should I care about machine learning 4 1.2 Machine learning tasks  5 1.2.1 Supervised learning  5 1.2.2 Unsupervised learning  7 1.2.3 Reinforcement learning  11 1.2.4 The machine-learning toolbox  12 1.3 Basic terminology  13 1.3.1 Models  14 1.3.2 A closer look at what a model does⋆  14 1.4 The machine learning workflow  17 2 Data and attribute types  19 2.1 What is a dataset 19 2.1.1 Attributes  20 2.1.2 Attribute types',\n",
              " '22 2.3 The standard data format  23 2.4 Feature transformations  24 2.4.1 One-out-of-K coding  25X Contents 2.4.2 Binarizing/thresholding  26 Problems  27 3 Principal Component Analysis  29 3.1 Projections and subspaces⋆  29 3.1.1 Subspaces  30 3.1.2 Projection onto a subspace  31 3.2 Principal Component Analysis  33 3.3 Singular Value Decomposition and PCA  38 3.3.1 The PCA algorithm  39 3.3.2 Variance explained by the PCA  40 3.4 Applications of principal component analysis  41 3.4.1 Example 1: Interpreting PCA components  43 3.4.2 Example 2: A high-dimensional example  44 3.4.3 Uses of PCA  46 Problems  49 4 Summary statistics and measures of similarity  53 4.1 Attribute statistics  53 4.1.1 Covariance and Correlation  55 4.2 Term-document matrix  56 4.3 Measures of distance  57 4.3.1 The Mahalanobis Distance 58 4.4 Measures of similarity  59 Problems  62 5 Discrete probabilities and information  65 5.1 Probability basics  66 5.1.1 A primer on binary propositions⋆',\n",
              " '67 5.1.3 Basic rules of probability  69 5.1.4 Marginalization and Bayes’ theorem  69 5.1.5 Mutually exclusive events  71 5.1.6 Equally likely events  72 5.2 Discrete data and stochastic variables  76 5.2.1 Example: Bayes theorem and the cars dataset  77 5.2.2 Generating random numbers⋆  79 5.2.3 Expectations, mean and variance  80 5.3 Independence and conditional independence  81 5.4 The Bernoulli, categorical and binomial distributions 82 5.4.1 The Bernoulli distribution  82 5.4.2 The categorical distribution 83 5.4.3 Parameter transformations  84 5.4.4 Repeated events  84 5.4.5 A learning principle: Maximum likelihood  85 5.4.6 The binomial distribution⋆  87 5.5 Information Theory⋆  87Contents XI 5.5.1 Measuring information  88 5.5.2 Entropy  90 5.5.3 Mutual information  91 5.5.4 Normalized mutual information  92 Problems  94 6 Densities and models  95 6.1 Probability densities  95 6.1.1 Multiple continuous parameters  96 6.2 Expectations, mean and variance',\n",
              " '100 6.3.1 The normal and multivariate normal distribution  101 6.3.2 Diagonal covariance  103 6.3.3 The Beta distribution  104 6.3.4 The cumulative density function  105 6.3.5 The central limit theorem⋆  106 6.4 Bayesian probabilities and machine learning  109 6.4.1 Choosing the prior  111 6.5 Bayesian learning in general  111 Problems  115 7 Data Visualization  117 7.1 Basic plotting  117 7.2 What sets apart a good plot 123 7.3 Visualizing the machine-learning workflow⋆  125 7.3.1 Visualizations to understand loss  125 7.3.2 Use visualizations to understand mistakes  126 7.3.3 Visualization to debug methods  127 7.3.4 Use visualization for an overview  128 7.3.5 Illustration of baseline and ceiling performance  131 7.3.6 Visualizing learning curves  132 Problems  134XII Contents Part II Supervised learning 8 Introduction to classification and regression  139 8.1 Linear models  139 8.1.1 Training the linear regression model  141 8.2 Logistic Regression  145 8.2.1 The confusion matrix',\n",
              " '148 Problems  151 9 Tree-based methods  155 9.1 Classification trees  156 9.1.1 Impurity measures and purity gains  156 9.1.2 Controlling tree complexity  160 9.2 Regression trees  162 Problems  165 10 Overfitting and cross-validation  167 10.1 Cross-validation  167 10.1.1 A simple example, linear regression  167 10.1.2 The basic setup for cross-validation  169 10.1.3 Cross-validation for quantifying generalization  172 10.1.4 Cross-validation for model selection  174 10.1.5 Two-layer cross-validation  174 10.2 Sequential feature selection  177 10.2.1 Forward Selection  179 10.2.2 Backward Selection  181 10.3 Cross validation of time-series data⋆  181 10.3.1 The setup  181 10.3.2 Cross-validation  185 10.3.3 Two-layer cross-validation  186 10.4 Visualizing learning curves⋆  186 10.4.1 The setup  186 Problems  189 11 Performance evaluation  193 11.1 Statistical testing for machine learning  193 11.2 Statistical primer⋆  195 11.2.1 Baselines  199 11.3 Setup I: the training set is fixed',\n",
              " '200 11.3.2 First task: Evaluation of a single classifier  201 11.3.3 Comparing two classifiers  204 11.3.4 McNemars test and small datasets⋆  207 11.3.5 Estimating the generalization error of a regression model  209Contents XIII 11.3.6 Comparing two regression models  211 11.4 Setup II: The training set is random⋆  213 11.4.1 A problem  214 11.4.2 The correlation heuristic  214 Problems  217 12 Nearest neighbor methods  219 12.1 K-nearest neighbour classification 219 12.1.1 A Bayesian view of the KNN classifier⋆  220 12.2 K-nearest neighbour regression  223 12.2.1 Higher-order KNN regression⋆  224 12.3 Cross-validation and nearest-neighbour methods  224 Problems  227 13 Bayesian Classifiers and Bayesian Networks  229 13.1 Discriminative and generative modeling  229 13.1.1 Bayes classifier  230 13.2 Na¨ıve-Bayes classifier  231 13.2.1 Na¨ıve-Bayes for non-binary data and robust estimation 233 13.3 Bayesian networks⋆  235 13.3.1 A brief comment on causality  238 Problems',\n",
              " '243 14.1 Least squares regularization 243 14.1.1 The effect of regularization  245 14.2 Bias-variance decomposition  248 Problems  253 15 Neural Networks  255 15.1 The feedforward neural network  255 15.1.1 Artificial neural networks  255 15.1.2 The forward pass in details  256 15.2 Training neural networks  259 15.2.1 Gradient Descent⋆  260 15.3 Neural networks for classification  263 15.3.1 Neural networks for binary classification  263 15.3.2 Neural networks for multi-class classification  264 15.3.3 Multinomial regression  265 15.3.4 Flexibility and cross-validation  266 15.4 Advanced topics⋆  266 15.4.1 Mini-batching  266 15.4.2 Convolutional neural networks  267 15.4.3 Autoencoders  268 15.4.4 Recurrent neural networks  268 15.4.5 Serious neural network modelling  269 Problems  270XIV Contents 16 Class imbalance 273 16.1 Dealing with class imbalance  273 16.1.1 Resampling  274 16.1.2 Penalization  274 16.2 Area-under-curve (AUC)  276 16.2.1 The confusion matrix and thresholding',\n",
              " '282 17 Ensemble methods  285 17.1 Introduction to ensemble methods  285 17.2 Bagging  287 17.3 Random Forests  290 17.4 Boosting  291 17.4.1 AdaBoost  291 17.4.2 Properties of the AdaBoost algorithm⋆  294 Problems  296Contents XV Part III Unsupervised learning 18 Distance-based clustering techniques  299 18.1 Types of clusters  299 18.1.1 The distance-based cluster types  299 18.1.2 More elaborate cluster types  300 18.2 K-means clustering  300 18.2.1 A closer look at the K-means algorithm  303 18.2.2 Practical issues with the K-means algorithm  304 18.3 Hierarchical agglomerative clustering  305 18.3.1 Selecting linkage function  307 18.4 Comparing partitions  310 18.4.1 Rand index  314 18.4.2 Jaccard similarity  316 18.4.3 Comparing partitions using normalized mutual information  317 Problems  320 19 Mixture models for unsupervised clustering  323 19.1 The Gaussian mixture model 323 19.2 The EM algorithm  326 19.2.1 Why the EM algorithm works⋆',\n",
              " '331 19.2.3 Selecting K for the GMM using Cross-validation  332 Problems  334 20 Density estimation 337 20.1 The kernel density estimator  337 20.1.1 Selecting the kernel width λ  338 20.2 Average relative density  340 Problems  344 21 Association rule learning  347 21.1 Basic concepts  347 21.1.1 Itemsets and association rules  348 21.1.2 Support  349 21.1.3 Confidence  349 21.2 The Apriori algorithm  350 21.2.1 An example of the Apriori algorithm  351 21.3 Using the Apriori algorithm to find itemsets with high confidence  353 21.4 Some limitations  354 Problems  355 Solutions  357XVI Contents A Mathematical Notation  375 Elementary notation  376 Linear Algebra  376 Analysis  377 Probability Theory  379 References  381Part I Data: Types, Features and Visualization1 Introduction In this chapter, we will try to define machine learning and data mining, as well as give a high-level grouping of the various machine-learning methods',\n",
              " '1.1 What is machine learning and data mining How can we build intelligent machines More than 65 years ago Alan Turing made this question the subject of his famous essay “Computing machinery and intelligence” [Turing, 1950] Alan Turing suggested that when we phrase the question in this manner, we unavoidably get bogged down in the definition of the word “intelligence” Instead, he proposed we should rather consider a different question: Can we construct a machine that can do the same things a human can do This may ultimately be as hard to answer as the first question, but at least we don’t have to begin our efforts by defining intelligence A second part of Turing’s essay discuss how we might build such a human\\ufffeimitating machine Turing proposed that instead of writing a computer program that behaves like a human from scratch, we should build a machine which initially cannot do a great many things but which can learn from past experience',\n",
              " '1.1.1 Machine Learning Machine learning is the implementation of Turing’s idea: The study of algorithms which can learn to do interesting things The learning is based on observed data, whether from a spreadsheet, a sensor attached to a robot or human instructions The goal of machine learning is therefore to use past experience to learn how to accomplish a task in such a way this learned ability generalize to future situations of the same type, and we will simply refer to this process as learning The focus of machine learning is on automatic and general methods In other words, the goal is to learn as much as possible with as little as possible human intervention, preferably none at all.4 1 Introduction 1.1.2 Data mining Data mining refers to the discovery of patterns or relationships in data and translating these into a useful structure The datasets are usually considered to be very large, possibly undergoing change and too complicated for any human to sit down and understand them',\n",
              " 'Making predictions about future events in the customers’ life, or finding similar groups of customers, are tasks ideally suited for machine learning In the following sections we will nearly exclusively discuss “machine learning methods” and a student may wonder what happened to data mining; this is partly to simplify the vocabulary and the student should keep in mind the methods are suited for various data mining tasks 1.1.3 Relationship to artificial intelligence Artificial intelligence is the construction of intelligent, thinking machines Machine learning is an important subarea of artificial intelligence in that it is nearly unthinkable to have an intelligent system that cannot learn from past experience Furthermore, it is arguably true that machine learning is the research area where most progress towards truly intelligent artificial systems is currently being made',\n",
              " 'A basic knowledge of these subjects is required to get started, and specialization in machine learning will require good knowledge in at least one (though not nec\\ufffeessarily all) of these subjects However, this course will focus on the underlying machine-learning concepts to make the course material as accessible as possible for non-expert students It is worth mentioning that biology has an important role in machine learning and researchers are inspired both by evolution as an information-creating principle (this is known as evolutionary computing) as well as how the human brain processes and store information The latter is known as (artificial) neural computing or artificial neural networks Furthermore, machine learning is a very broad subject which caters to very different types of researchers',\n",
              " '1.1.5 Why should I care about machine learning We might not notice, but machine learning is becoming more and more pervasive in our society these years Today, a person can use automatically trained speech recognition to order a product on an online shop which he learned about in an advertisement, which was specifically tailored to him by a machine-learning recommender system, and pay with a credit card that is automatically checked for fraud All these steps involve machine learning; however it is just the tip of the iceberg Artificial intelligence systems for self-driving cars can accomplish many transportation tasks, computers can1.2 Machine learning tasks 5 learn to automatically play video games better than humans and beat the grandmaster of Jeopardy They can correctly recognize if an image contains a rock or an armadillo and learn to translate sentences from two languages with no expert input or initial knowledge of grammar',\n",
              " 'We might still think these tasks, impressive and useful as they may be, have little to do with us in our professional lives However, since the machine learning methods are general, the same algorithms that can classify observations into 20 000 categories can be used to solve much simpler data analysis problems we might encounter in our every-day life To give an example, suppose Susi is an electrical engineer who is in charge of maintaining a hundred wind turbines The wind turbines already register a lot of data (wind speed, amount of electricity generated, vibrations, etc.), and Susi notices that if the vibrations for a wind-turbine exceed a certain threshold even if the wind is not very strong, the turbine is likely to become faulty in the near future Accordingly, she writes a small program: If vibrations exceed level x on a day where the wind is no greater than y, call in a technician to check the turbine',\n",
              " 'However even in this simple case, Susi is faced with important choices: What should x and y be Are there other things that are relevant to determine if the wind turbine should be monitored If she comes up with another rule, how does she prove it is better (or worse) Will this rule be suitable for the land-based windfarm Susi can try to work out these questions on her own However there is a simpler option: She could apply standard machine-learning methods to learn x, y from the data Or even better, she could apply standard tools such as logistic regression which we learn about in chapter 8 for modelling the break-down probability given all available variables and she could use proven techniques for validating her models such as cross-validatio which we learn about in chapter 10 This will lead to better and more trustworthy predictions and, more importantly, it will save Susi a lot of time',\n",
              " 'When we as engineers consider why machine learning is important to us it is not necessarily because it will allow us to build the new self-driving car, discover the cure for cancer, or build a bridge-building robot, but because it will provide simple, off-the-shelf tools which will allow us to make efficient use of data which is already available This book will provide an introduction to these tools In the following sections, we will introduce basic terminology surrounding machine learning and data mining We will provide an overview of various forms of machine learning problems for later reference and discuss the basic machine-learning workflow 1.2 Machine learning tasks Some machine-learning terminology such as supervised or unsupervised learning is not fully settled in the literature and specific definitions often become overly technical We will therefore first provide some examples of various tasks and types of learning before stating more exact definitions',\n",
              " 'It is useful to distinguish between classification and regression:6 1 Introduction Setosa Versicolor Virginica Petal Length Petal Width 1 2 3 4 5 6 7 0 0.5 1 1.5 2 2.5 Fig A classification problem where we are given observations (the points) and class labels (the colors) and the goal is to come up with a rule for determining which class a point belongs to (one such rule is indicated by the lines) The rule can then be applied to new points Classification In classification we are given observed values x and have to predict a discrete response y I.e., we are given discrete observations of some object and have to determine what class the object belongs to, see fig Examples include: \\x88 We are given examples of hand-written digits and have to determine what number (between 0 and 9) is contained in an image This is a multi-class classification problem since there are multiple categories to choose from',\n",
              " 'This is a binary classification problem since there are only two choices (survives or dies) \\x88 We are given a short sound-signal and have to determine which word is spoken This is a classification problem but there are as many classes as there are words (perhaps about 20 000) \\x88 We are given the social Facebook graph for a large group of people and have to determine how likely it is any two random people in the graph will form a friendship (or remain friends) in the next year (binary classification problem as response is discrete, i.e link /not a link between people) \\x88 We are shown pairs of images of faces and have to determine if the images are of the same person Regression In regression problems we are given observed values x and have to predict a continuous response y, see fig Examples include: \\x88 We are given historical data of the stock market and have to predict the performance of a single stock the coming Monday (prediction of a single variable)',\n",
              " 'A one-dimensional regression problem where we have to predict the y-values based on the x\\ufffevalues The fitted regression model is indicated by the black line \\x88 We are given the performance of all stocks in the past and have to predict the performance of all stocks for the next five days (massive regression problem with many output variables) \\x88 We are given weather information from yesterday and have to predict the temperature in five major cities tomorrow (regression of five variables) \\x88 We are given the hospital information of a person and have to determine how many days he is going to survive (prediction of a single variable) Notice these problems are quite different In principle we could imagine we could solve the weather prediction problem perfectly provided our model was good enough and we had enough measure\\ufffements, however we could not dream of being able to exactly predict a person’s weight from his or her height, thus our prediction would in this case be guaranteed to be imperfect',\n",
              " 'These examples are therefore attempts to directly generalize from past experience and in that sense we know what task we have to solve as well as whether we solved it correctly or not Machine learning problems where we have both observed observations and observed target values is known as supervised learning problems or simply supervised learning 1.2.2 Unsupervised learning The oppositive of supervised learning is unsupervised learning Consider an example dataset con\\ufffesisting of images of animals We may immediately consider building a machine learning method8 1 Introduction x1 x2 0 5 10 −8 −6 −4 −2 0 2 4 6 8 x1 x2 0 5 10 −8 −6 −4 −2 0 2 4 6 8 Fig A 2D clustering example A clustering is given a dataset (here the 2D dataset shown in the left-hand pane) and has to estimate plausible divisions of the observations into clusters as indicated in the right-hand pane which tries to discover what animal is in the picture (a duck, a lion, an elephant, etc.)',\n",
              " 'Surely, we can sit down and label a few thousand of the images ourselves, train a supervised method (a classification method in this case) on the labelled images, and then use this method to determine the labels of all other animal pictures on the internet – but this is very boring and not reflective of how humans actually learn Unsupervised learning tries to solve this and similar problems where we do not have access to any “ground-truth” label information (such as the identity of the animal in the image) but we try to discover this labelling from the data alone 1.3 an example of clustering where the goal is to cluster (label) the gray points in the left-hand pane and an example clustering is indicated in the right-hand pane by the coloring Examples of clusterings include: Clustering \\x88 In the animal example, the goal was to group images into clusters such that each cluster represented a given type of animal',\n",
              " '\\x88 Given a large collection of documents, try to determine clusters of similar documents corre\\ufffesponding to topics.1.2 Machine learning tasks 9 x1 x2 −2 0 2 4 6 8 −6 −4 −2 0 2 4 6 x1 x2 p(x) −2 0 2 4 6 8 −5 0 5 0 0.01 0.02 0.03 0.04 Fig A 2D density estimation example Given the black points, the density is estimated and plotted in the right-hand pane Density estimation In density estimation we try to quantify how likely (or unlikely) a given future observation is given past observations, i.e the probability distribution of the data, see fig Consider the hand\\ufffewritten digit example Suppose you are shown four images of hand-written digits and are told they are from the same person Suppose then you have to determine if a fifth (until now) unobserved digit is written by the same person This task involves estimating the relative variability in the person’s hand-writing and how plausibly it is he has written a given digit – this is known as density estimation',\n",
              " 'You have to decide the next place to excavate Estimating the place with the highest probability of a new find from past finds is a density estimation problem \\x88 You are working for an oil company and try to estimate the drill site with the highest chance of finding oil based on past drilling \\x88 You are a microbiologist and you are trying to find out how typical a particular cell is given other observed cells of the same type Being able to detect atypical cells could be relevant to determine diseases such as cancer Anomaly detection Anomaly detection is figuring out which observations significantly deviate from other observations While what constitutes a significant deviation is highly dependent on the context, humans neverthe\\ufffeless have a natural ability to carry out this task We may for instance consider the red observation10 1 Introduction x1 x2 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 Fig',\n",
              " '1.5 to be significanly different from the other observations from a number of perspectives This includes that it is simply quite far away from it’s nearest neighbour relative to the other observations distance to their neighbours or that it appears not to follow the same “tendency” (the banana-shaped curve) as the other observations Anomaly detection can be considered closely related to density estimation since an observation which is very implausible (low density) could be considered an outlier Anomaly detection is relevant in a number of situations including: \\x88 You work for a credit-card company and have to determine if an transaction deviates from common transactions in order to detect fraud \\x88 You supervise a windmill farm and based on past behaviour have to determine if a windmill is beginning to behave differently indicating it may require repair',\n",
              " 'Suppose you work for an online book seller and you are given a large dataset consisting of which books different people bought In order to show relevant adds, you want to come up with1.2 Machine learning tasks 11 {Bread, Coke, Milk} {Beer, Bread} {Beer, Coke, Diaper, Milk} {Beer, Bread, Diaper, Milk} {Coke, Milk} Training Set {Milk} → {Coke} Rules Discovered {Diaper, Milk} → {Beer} Fig Given examples of what people have previously bought, association mining tries to discover rules for what they will likely buy in the future For instance a person who buys milk is likely to also buy coke rules such as: “If the person bought both book X and book Y, then he is likely to buy book Z” This is known as association mining or rule discovery Other applications are: \\x88 Given which items people have historically bought in a supermarket, discover what other items each customer is likely interested in',\n",
              " '\\x88 Given past life experience, figure out that drinking the past night implies hangover Dimensionality reduction In dimensionality reduction, we try to discover a simpler representation of a very high-dimensional dataset, see fig Consider for instance a dataset of faces In one example the dataset is in a modest resolution (the images may be 500×500 pixels) and in the other example the same images are in a very high resolution (say 5000 × 5000) The later dataset contains 100 times more information than the former, however to a human they contain the same information: We can recognize the identity of the people from both datasets, their age, race or gender, their emotional state etc If we think about it M = 750 000 = 500 × 500 × 3 numbers (there are 3 color channels) is still a lot of data If we had access to a large set of numbers such as the distance between the eyes, length of the nose, eyes and mouth, width and height of the face, the color of the skin, the curvature of the mouth, etc',\n",
              " 'Thus dimensionality reduction is learning a representation of an M dimensional object which uses M′ < M numbers while retaining most of the relevant information Other examples are: \\x88 Lossy compression \\x88 Finding a summary of a sentence or book 1.2.3 Reinforcement learning Finally, for the sake of completeness reinforcement learning is worth mentioning Reinforcement learning corresponds to the case where a computer has to control a robot based on sensory input and a reward signal That is, at any given time the robot observes the state of the world (for instance a screenshot if the robot should learn to play a video game), selects an action (for instance pushing a particular button) and possibly receives a reward, for instance simply if the robot loses the video game or not Reinforcement learning can be seen as a type of regression (i.e supervised learning) where we are trying to predict the reward based on the current action and input signal.12 1 Introduction Fig Dimensionality reduction',\n",
              " 'Colors indicate different digits (0, 1,  Notice, digits that are the most dissimilar such as 0 and 1 are mapped to points far apart However, as rewards are rarely observed it is usually considered to be different from supervised learning This course will not consider reinforcement learning, however, many of the techniques used for reinforcement learning will in fact be introduced in this course 1.2.4 The machine-learning toolbox The above taxonomy is not exhaustive or set in stone and there are many problems which does not exactly fit into the above categories Consider a system which has to translate from English sentences to French sentences In some sense it is a classification problem, however there are infinitely many sentences to choose from and treating it as a generic classification problem is not helpful Or suppose you want the computer to learn if two variables are causally related, i.e that smoking causes cancer in a medical records dataset',\n",
              " 'Fortunately, even the most advanced applications of machine learning rely on re-using and combining simpler tools, nearly all of which are introduced in this course 1 This is not to say that automatic translation or inference of causation is beyond machine learning See for instance: https://en.wikipedia.org/wiki/Neural_machine_translation and [Pearl et al., 2016].1.3 Basic terminology 13 x5 001 = y1 = 0 y5 001 = 1 y10 001 = 2 y50 000 = 9 x1 = x10 001 = x50 000 = Fig Four observations (images of handwritten digits) from the MNIST dataset containing a total of N = 60 0000 handwritten digits Each observation consist of a 784-dimensional vector xi and a label yi which can be either 0, 1,  in some form A useful analogy is building a machine where this course supplies the wrench, the screwdriver, the soldering iron and the other tools required to get started',\n",
              " 'The basic architecture of one of the absolute best image-recognition network (Inception v3) is a variant of the humble simple feedforward network introduced in chap\\ufffeter 15 1.3 Basic terminology Let’s make the above discussion more concrete by considering a realistic problem Consider the handwritten digits from the MNIST dataset shown in fig Each digit consists of a 28 × 28 pixel image which, since the images are black and white, can be represented as a vector x consisting of M = 784 real numbers2 and we write this as x ∈ RM The goal is to build a machine which takes such an image x and outputs the identity of the digit, i.e if it is 0, 1,  This is a non-trivial problem since there is a huge variability in how people write digits (stroke, style, open or closed digits, rotation, translation, etc.), however it is a trivial problem for humans Our goal is therefore to construct a function f which takes a M-dimensional vector as input and returns 0, 1,',\n",
              " 'If we adopt a machine learning approach our goal is to construct a system which can learn how to solve the above problem The system learns from experience In this case the past experience (i.e the data) would consist of a number of example images for each type of digit For instance we would have 5 000 examples of the digit 0, x1, x2,  , x5000, then 5 000 examples of the digit 1: x5001, x5002,  , x10 000 and so on up to image x50 000 of the digit 9 Let N = 50 000 be the number of examples, we collect all this information in an N × M matrix X and a N-dimensional vector y: X = \\uf8ee \\uf8ef \\uf8f0 x T 1  x T 50 000 \\uf8f9 \\uf8fa \\uf8fb and y = \\uf8ee \\uf8ef \\uf8f0 0  9 \\uf8f9 \\uf8fa \\uf8fb , 2 The real numbers are all numbers such as 5, −1, π, 1 3 , · · ·  For instance the pixel values can lie in the interval [0, 1].14 1 Introduction D train Training data Model Prediction rule The model learns Future data M the prediction rule f f(x) yi = f(xi) from the training data Training phase Test phase Fig A model in supervised learning',\n",
              " 'Later, in the test phase, this rule can be applied to new, unobserved data where yi is either 0,  , 9 depending on the digit in image xi  Taken together we let Dtrain = (X, y) denote all data available for training the machine learning method and Dtrain is known as the training set 1.3.1 Models Given the training set Dtrain in the above example, machine learning then consists of constructing a program which takes the training data Dtrain and returns a function f : R M → {0,  , 9} Learning the function f from the data is known as the training phase or alternatively as the learning phase or simply learning, see fig Once this function is learned it can be used to determine the identity of unobserved images of digits For instance if for an image x we have that f(x) = 5 this means the algorithm predicts that the image contains the digit 5 These new observations used to test the model is known as the test set denoted Dtest',\n",
              " 'The generalization error should be distinguished from the training error which is the average error on the training set; we will have much more to say about the generalization error in chapter 10 Notice that since the training set was used to train the model, we should expect the training error to be lower than the generalization error A computer program (along with the assumptions it relies upon) which carries out the above steps –i.e based on a training set it constructs a function f– is known as a model Different models will be denoted M1,  1.3.2 A closer look at what a model does⋆ The above description present an accurate but somewhat abstract view of what machine-learning attempts to do In this section we will try to provide an intuition of what happens “inside” the function f so as to get an understanding of what may go wrong',\n",
              " 'In the broadest sense, a machine learning method takes a number of observations (here, images of cars) and build an (approximate) internal representation that captures statistical relationships in the images One should think of each image as bringing a little piece of information about this relationship and the goodness of a method as how well it can make use of this information Since the method does not know what it should focus on, it can either build a successfull representation (center, top), or focus on spurious properties of the training set (center, bottom) For this reason evaluating the method with data not used to train the method (the validation set) is important as these images are unlikely to conform to the (spurious) representation and will therefore offer an accurate idea about how well the method performs',\n",
              " '1.10 we have illustrated an approximate view of what a machine learning method does in such a setting: We start out with a dataset comprised of a collection of images3 (and their labels) and the goal of the method is then to predict which category the images fall within on hitherto unseen data This is done by somehow learn a useful internal representation based on what these images have in common Speaking in broad terms, these learned representation of for instance the cars-class will correspond to a cobbled together collection of car-like elements and an implicit statistical relationship between them A machine learning method trained to detect cars is likely to be sensitive to wheels, but will often be insensitive to the number of wheels and only have a very rough idea about where wheels are supposed to be located relative to each other, as illustrated in fig 1.10 (center, top)',\n",
              " 'In other words, think about each observation as containing a small piece of the overall true meaning of car Machine-learning method can pick out these pieces at varying degrees of efficiency, and as a rule less efficient than humans The advantage machine-learning methods have over humans is in making use of more data than a human can easily comprehend It is therefore the ability to make use 3 Images obtained from https://www.pexels.com16 1 Introduction Fig Left: With more data we should expect the generalization error to drop, however this drop can be expected to occur sooner for less flexible models (blue and red curve) as they are less prone to learn spurious relationships in the data, however, it will be sustained longer for more flexible methods (yellow) which are able to learn a more powerful representation Right: When a model is trained on little data, we should as a rule expect it to learn all the particulars of the dataset, including spurious relationships',\n",
              " 'With more data, these two curves will approach each other as the training error increases and the generalization error drops of lots of data, rather than intrinsic sophistication, which makes machine-learning methods work: That is why data, specially lots of high-quality data, is so important When learning fails The goal of machine learning is to find models which generalize well to future data (i.e., data the model is not trained upon), and this is measured by the generalization error which is what ultimately decide which model is better A model may have a high generalization error for three reasons: Firstly, it may be misapplied, but we will leave that asides Secondly, the method can be too weak (i.e., inflexible) to learn a sufficiently rich representation to solve the problem, and thirdly, since the machine-learning methods do not have any intrinsic idea about what to focus on in a set of images, they might focus on the wrong things This is illustrated in fig',\n",
              " 'This leads to a rule which is useful to categorize images in the training set, but which generalize poorly, hence high generalization error There are two things which determine how prone a given method is to degenerate behavior, both illustrated in fig 1.11, namely the amount of data and how flexible the machine learning method is 1.12 we have tried to give a rough indication of how some of the methods in this book are sorted according to complexity One can think of any type of model in terms of how flexible a representation it can ultimately learn With little data, a very flexible model will be able to learn any number of representations and will therefore often fail, and we say they tend to overfit',\n",
              " 'A rough overview of the relative complexity/flexibility of models encountered in this book; note this illustration is somewhat subjective and depends on assumptions about how the methods are applied Techniques such as regularization serves to make a model less flexible (more robust), whereas ensemble techniques such as bagging/boosting has the opposite goal The machine learning workflow used in this course In the first step the problem is analysed and one obtains an overview of the data including potential issues In the next step an appropriate machine\\ufffelearning method is implemented and potentially modified and in the third step the model is evaluated The lessons learned are used to improve on what happened in step 1 and 2 to produce a new model which is compared to the first The process then repeats At all times knowledge of the domain should be exploited reducing the flexibility of a mode which we will learn about in chapter 14) will be relevant',\n",
              " 'The simplicity of which we can heap extra neurons into an artificial neural network (chapter 15) makes them the poster child of extremely flexible models and that, together with the availability of large datasets and powerful computers, has driven the neural network revolution of the past decade 1.4 The machine learning workflow To summarize the above discussion we will now present the workflow of a machine learning practi\\ufffetioner fig Suppose we are presented with a problem for the first time The first thing we have to understand is what type of problem it is: Is it a supervised problem or unsupervised problem Regression or classification Secondly, we should try to understand the available data: Data is the life blood of any machine learning method and without having a good handle on what our dataset is, if there are issues with our dataset and if the task appears feasible given the dataset it is18 1 Introduction difficult to proceed',\n",
              " 'Having analysed the data and problem we must select an appropriate method and possibly apply modifications to the method This is step 2 where we ensure the method is implemented correctly and produce an output At this point we have our first model: M1 To take the handwritten digit task as an example, the method may produce a prediction rule which can be applied to test data This brings us to step three which is absolutely critical but often neglected: Evaluation and dissemination For a model M1 we must evaluate how well the model performs (generalizes) on previously unseen data and quantify this numerically We should also look at examples where the model failed and try to get a idea on why this happens and how we might do better This is also the step where we disseminate the results to be used by others either in a report or as part of a more general workflow in a scientific team or company',\n",
              " 'The result may be a new model M2 which must again be tested to see if it is better or worse than M1 During this course, we will learn techniques which apply to all these steps The first section of the course relates to the first step; the two next sections treat the second and third step of the workflow, both for supervised machine-learning techniques and unsupervised machine-learning techniques.2 Data and attribute types Without data there would be no need for machine learning In this chapter, we will define what we mean by a data set, attribute types and discuss commonly encountered data issues such as missing values Common data issues such as missing values have been present from the day humans first began recording data but is perhaps particularly treated in depth in for instance clinical psychology where standardized treatment of corrupted data is a major concern and it is also within clinical psychology the distinction of attribute types (ration, interval, etc',\n",
              " '2.1 What is a dataset Data, or a dataset, is a collection of electronically stored information Quite simply, it is what we have to work with Examples could be: \\x88 Biomedical information about patients in a hospital \\x88 A collection of text files, for instance corresponding to news stories \\x88 The temporal development of 10 stocks on the New Your stock market over 50 days \\x88 A collection of 3D models, each model being defined as a (varying) collection of points on its surface \\x88 A social graph, for instance from a social network (who is friends with who) Often, and in all cases considered in this book, a dataset can be thought of as standardized measure\\ufffements of objects of the same basic type For instance, measurements of patients, cars or documents Each such measurement of a single object is called an observation',\n",
              " 'The number of observations in a dataset is denoted N It is useful to distinguish between datasets which are simple and those which are complex A simple dataset is a dataset of N observations where each observation corresponds to a fixed number of recorded values For instance in the patients dataset, we can imagine that for each observation we record the patients name, age, weight, blood pressure and so on Each recorded value is called20 2 Data and attribute types Table 2.1 Ten entries from the Cars dataset comprised of N = 142 observations and M = 9 features ID MPG Cylinders Horsepower Weight Year Safety Acceleration Origin 1 18 8 150 3436 70 4 11 France 2 28 4 79 2625 82 4 18.6 USA 3 26 4 79 2255 76 3 17.7 USA 3 29 4 70 1937 76 1 14.2 Germany 4 NaN 8 175 3850 70 2 11 USA 5 24 4 90 2430 70 3 14.5 Germany 6 17.5 6 95 3193 76 4 17.8 USA 7 25 4 87 2672 70 -100 17.5 France  142 15 8 198 4341 70 2 10 USA an attribute or feature and the number of features will be denoted by M',\n",
              " 'A non-simple dataset is a dataset where there is additional structure or complexity This could be: Temporal If for instance the observations are made sequentially over time (such as the stock market) Varying number of features If each observation has a varying complexity For instance the text files has a varying number of words, and the 3d models a varying number of surface points Self-referential structure For instance in the social graph, the edges refer to the same group of people These definitions are not set in stone and require some common sense For instance, we could claim that the patients dataset was temporal since patients will arrive at different dates, however what matters is if this temporal ordering is considered important for the machine learning task',\n",
              " 'In this course we will consider simple datasets of N observations and M features such as the Cars dataset This may sound very restrictive; however, the techniques suitable for more complicated datasets can often be seen as specialization of the tools we here consider for the simple case In addition, the simple case covers nearly all data that can be plugged into a spreadsheet and as we will see, it is often possible to transform data that at first glance may appear complex (for instance images or text) into the simple format 2.1.1 Attributes If we consider the cars dataset in table 2.1 we immediately notice the attributes are different For instance the Origin feature is one of three text strings, the ID is an increasing sequence, presumably only used for bookkeeping purposes, safety is a number of stars (from 1 to 5) and so on It is useful2.1 What is a dataset 21 to introduce some general vocabulary to describe different types of attributes',\n",
              " 'In particular, we define: Continuous: A continuous attribute is one which, if it can take values a and b, then it can also take any value between a and b Discrete: A discrete feature is one where if it can take a value a, then there is a positive minimum distance to the nearest other value b it can take Binary: A binary feature is a discrete feature which can only take two values Usually these are denoted 0 (false) or 1 (true) For instance the weight of the car is continuous since if a car can weight 1000 pounds and 2000 pounds then presumably it can also take any weight between 1000 and 2000 pounds Notice contin\\ufffeuous does not imply it can take any decimal value since the weight cannot for instance be negative and this is why the definition is somewhat technically sounding The definition of discrete tries to capture the intuition that the variable changes in discrete steps',\n",
              " 'For instance a safety rating which could take the possible values 0, 1 4 , 2 4 , 3 4 and 1 would also be discrete 2.1.2 Attribute types Machine learning methods operate on numbers and not text strings Accordingly, to apply a machine-learning method to the Cars dataset in table 2.1 we must therefore translate the country of origin (which can be USA, France and Germany) into numbers (1, 2, 3) Notice that which country is assigned which number is our convention and should be irrelevant: If we choose to assign USA to 3 (and Germany to 1) this should not affect our subsequent computations (or so we hope!) This makes the country of origin different from the safety rating since a safety rating of 5 is larger than a safety rating of 3 and this feature should inform our machine-learning method In other words the safety rating is ordered (smaller, larger) whereas the country of origin is not ordered This is an example of two variables of different types',\n",
              " 'An example is the country of origin or the id Ordinal: If the variable is ordered (smaller, larger) An example is the safety rating Interval: If the variable is ordered and the relative magnitude of the variable has a physical meaning The year is interval since the difference between say 82 and 85 (three years) has the same meaning as the difference between years 77 and 80, however the safety rating is not interval since a difference in safety rating of 2 and 4 and 3 and 5 does not have a physical meaning Ratio: If the value 0 of the variable has a specific, physical meaning it makes sense to say one value of the variable is “twice as large” as another The year is not ratio since it has no particular meaning to say that 62 is twice as large as 31, whereas the volume of the engine does have a particular physical meaning since a value of 0 means the combustion chamber has volume 0 cm3  Notice the types are a hierarchy',\n",
              " 'It is distinguished from ordinal and nominal as the relative magnitude of the variable also has a physical meaning and therefore categorized as interval Ratio22 2 Data and attribute types and interval are the variables which are most easily confused Suppose for instance we record the longitude of cities as an attribute (the longitude is the east-west location on the globe in degrees) Is this variable ratio One could reason the answer is yes, since a longitude of 0 has the “meaning” that we are on a particular place on earth, in this case the north-south line that passes through the city of Greenwich in England However, what the definition has in mind is that the physical meaning is not purely “by convention” but actually refers to a physical property of the globe Since the city of Greenwich is just a convention, the correct answer is that the longitude is interval and not ratio',\n",
              " 'If the new civilization would assign “zero” the same meaning as we do the variable is ratio, else it is interval In the case of the longitude, if we had to come up with the longitude system anew the longitude of 0 might as well lie anywhere on the globe, and similar for the year where we could start our calendar from any other year than the year where medieval monks estimated Jesus to have been born If the variable is continuous or discrete is often independent of whether the variable is ordinal, nominal, interval or ratio For instance the variable Cylinders is discrete ratio (zero cylinders has a specific meaning) and acceleration is continuous ratio To summarize the variable types for the Cars example: Origin: Discrete, nominal Safety: Discrete, ordinal Cylinders: Discrete, ratio Year: Discrete, interval Miles/Gallon, Horsepowers, Weight and Acceleration: Continuous, ratio',\n",
              " 'Unfortunately, such issues are surprisingly common especially when humans have to enter values and we distinguish between the following issues: Irrelevant or spurious attributes: The ID column is irrelevant as it only depends on the or\\ufffedering of the data Outliers: The safety rating of −100 must be due to some kind of error We call such observations outliers Missing data: The Miles/Gallon attribute for car ♯4 is missing As a rule, attributes which can be known to be spurious or irrelevant such as the ID should simply be discarded, and in doing so we will reduce the number of dimensions of the dataset (M) and make the machine-learning problem easier Missing data can be treated in four main ways: \\x88 Some machine learning methods such as Bayesian learning methods can account for missing data if applied correctly, however, most cannot \\x88 If the missing data is isolated to one particular attribute and that attribute is deemed non\\ufffeessential, we can choose to discard the attribute',\n",
              " 'Processed version of the Cars dataset consisting of M = 8 attributes and N = 142 observations (only 10 are shown) MPG Cylinders Horsepower Weight Year Safety Acceleration Origin 18 8 150 3436 70 4 11 3 28 4 79 2625 82 4 18.6 1 26 4 79 2255 76 3 17.7 1 29 4 70 1937 76 1 14.2 2 15.32 8 175 3850 70 2 11 1 24 4 90 2430 70 3 14.5 2 17.5 6 95 3193 76 4 17.8 1 25 4 87 2672 70 3 17.5 3  15 8 198 4341 70 2 10 1 \\x88 If we have many observations and only few have missing observations, we can discard the observations with missing values \\x88 If we want to keep the affected attributes and observations, we can impute the missing values with some kind of neutral guess For the last method, imputation, a neutral guess can be obtained in several ways In the case of the Miles/Gallon attribute, we can impute the missing value with the mean of all observed instances of the Miles/Gallon attribute (in this case 15.32 Miles/Gallon)',\n",
              " 'In this case we can choose to either round the safety rating, or impute the most commonly encountered safety rating in the dataset, in this case 3 As a rule, changing the dataset by for instance throwing away “outliers” without clear reasons for doing so is a cause for concern since this may affect conclusions drawn from the data Outliers should therefore only be removed if there are strong reasons to think the observations are erroneous such as a negative safety rating 2.3 The standard data format We conclude this section by relating the table to the standard data format used in the course and that we briefly saw in the introduction Suppose we implement the changes to the Cars dataset discussed above, i.e we remove the ID, replaced the country of origin with an (ordinal) numeric coding and imputed the missing values We then obtain the new Cars dataset shown in table 2.2 The way we will represent such a dataset is as an N × M matrix X where N = 142 observations and M = 8 features',\n",
              " '15 8 198 4341 70 2 10 1 \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fb (2.1)24 2 Data and attribute types Each observation in the dataset, i.e a single car, is a row in X We will write xi for the i’th observation, for instance the second observation is the M = 8 dimensional vector (notice the transpose): x2 =  28 4 79 2625 82 4 18.6 1T We will refer to element i, j of the matrix X as Xij or Xi,j  In this way X2,4 = 2625 meaning that the second car weights 2625 pounds To complete the discussion, recall from the introduction we might have access to additional information yi about each feature, corresponding to either a continuous regression (target) value or a discrete class label, and we collected all these values as a N-dimensional vector y All in all this means any dataset considered in this course will be an N ×M matrix X and (if available) a N-dimensional vector y denoting the response or output variable (we will get back to the use of y in part II of the course when we cover supervised learning)',\n",
              " '2.4 Feature transformations Feature transformations refers to the operation of changing an existing feature or adding a new feature to our dataset There are three principal reasons why we may want to do this: \\x88 Many machine-learning methods such as principal component analysis and K-means are sensi\\ufffetive to outliers or features that reside on a different scale and it may therefore be a good idea to standardize (change) features \\x88 Expert knowledge can be used to compute new features from existing ones, thereby (hopefully) making a simpler machine-learning method more powerful \\x88 Ordinal values such as Origin might not be appropriately encoded as an integer (see below) To provide examples of the first type, suppose we consider the Cars dataset of table 2.2 (or equiv\\ufffealently, the processed version as the X matrix in eq (2.1)), the variable Safety is less than 10 whereas Weight is between about 2000 to 5000 and both features have a mean value greater than zero',\n",
              " 'This is done by first computing the empirical mean and standard deviation for each column j: µˆj = 1 N X N i=1 Xij , σˆj = vuut 1 N − 1 X N i=1 (Xij − µj ) 2 and then updating each column j of X of the new matrices X˜ as either: X˜ = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8f0 · · · X1j − µˆj · · · · · · X2j − µˆj · · ·  · · · XNj − µˆj · · · \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fb or X˜ = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8f0 · · · (X1j − µˆj )/σˆj · · · · · · (X2j − µˆj )/σˆj · · ·  · · · (XNj − µˆj )/σˆj · · · \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fb It is easy to verify that in the first case the mean of column j in the updated X-matrix will be 0, and in the second case the mean will be 0 and the standard deviation 1 While subtracting mean and\\x00\\x002.4 Feature transformations 25 standardizing columns are the most common transformations, many other could be considered For instance, suppose X represent observations about animals where one column is the weight',\n",
              " 'In other words, if an animal weights 1020g (compared to 20g) you can tell it is not a mouse, whereas if it weight 1001kg (compared to 1000kg) this extra kilo will not tell you that it is not a rhino, however, the difference in weight in both cases is just 1kg A possible way to make the machine-learning method respect this difference in scale is by applying the logarithm to the column: X˜ = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8f0 · · · log X1j · · · · · · log X2j · · ·  · · · log X3j · · · \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fb because in this case the difference in weight is: log(1.02)−log(0.02) ≈ 3.93 compared to log(1001)− log(1000) ≈ 0.0001 and thus much more informative for the smaller animal A feature transformation consisting of adding and multiplying a feature column xj with constants a, b, xi 7→ axi +b, is called linear (subtracting the mean and dividing with the standard deviation being the prototypical example) whereas all other transformations, such as computing the logarithm, are called non-linear',\n",
              " 'Suppose we consider a hospital records dataset X consisting of M attributes and that two of these features, j and k, corresponds to weight and height of the patient Since small patients are often light and tall patients are often heavy it may be beneficial to add a new feature to the dataset which takes this into account such as the Body Mass Index (BMI) Recall the BMI is the weight divided by the square of the height, in other words we add a new column: X˜ = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8f0 · · · X1jX −2 1k · · · · · · X2jX −2 2k · · ·  · · · XNjX −2 Nk · · · \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fb to X thereby obtaining an N × (M + 1) dataset Adding new features in this manner can make a simple learning method more powerful and will be used extensively when we discuss linear regression in chapter 8 2.4.1 One-out-of-K coding The final type of feature transformation we will consider is one where the type of a feature is changed',\n",
              " 'Suppose we have a discrete ordinal variable x which takes K discrete values, for instance K = 4 and x = 1, 2, 3 or 4 A one-out-of-K coding of x corresponds to a vector z of dimension K where entry i is 1 only if x = i and otherwise 0 For instance if x = 3 then z =  0 0 1 0T  If we consider the Origin-feature in the Cars dataset and recall this variable could take three possibly values (USA, Germany and France) and so a one-out-of-K coding is the mapping:\\x00\\x0026 2 Data and attribute types \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8f0 3 1 1 2 1 2 1 3  1 \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fb ↔ \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8f0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1  1 0 0 \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fb (2.2) What is the advantage of one-out-of-K coding Later, we will see this representation makes certain machine-learning methods easier to describe However, for now notice coding the country as an integer implied an ordering in the countries',\n",
              " 'If we apply a one-out-of-K coding, the assignment is symmetric since no machine\\ufffelearning technique will depend on the ordering of the features For this reason a one-out-of-K coding is recommendable when one has ordinal variables which in fact represent different categories and apply a machine-learning method where the (relative magnitude) of the variable will affect what the method does In other words, we replace the ordinal variable with three binary variables 2.4.2 Binarizing/thresholding Another feature transformation where the type of the feature is changed is binarizing or thresholding Suppose we select a constant θ, then binarizing a number x at θ is simply to replace x with 1 if x ≥ θ and otherwise 0 More formally for a vector x this is written as x ↔ \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8f0 1[θ,∞[(x1) 1[θ,∞[(x2)  1[θ,∞[(xN ) \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fb (2.3) where 1A(x) = ( 1 if x ∈ A 0 if x /∈ A (2.4) is known as the indicator function',\n",
              " 'The rule of thumb is to initially do as little as we can get away with Typically this means we should somehow treat missing values or (gross) outliers if they exist in our data, and then if the method we wish to apply is known to be affected by features being badly scaled or not in a 1-out-of-K coding (this would be the case with for instance PCA in the next chapter) we can apply these transformations Once this is over, we can begin to work with our data and later, once we have set up methods for evaluating the performance of our methods, possibly consider additional transformations.2.4 Feature transformations 27 Problems 2.1 Question 1: Consider the data set described in Ta\\ufffeble 2.3 Which statement about the attributes in the data set is correct Attribute description Abbrev',\n",
              " 'Attributes in a study on risk factors associated with giving birth to a low birth weight (less than 2.5 kg) baby [Hosmer and Lemeshow, Applied Logistic Regression, 1989] The data we consider contains 189 observations, 6 input at\\ufffetributes x1–x6, and one output variable y A Race, HT and UI are ordinal B Age and PV are ratio C Age is continuous and ratio D MW is discrete whereas PV is continuous E Don’t know Question 2: We consider a dataset about the Gal´apagos islands which is the famous group of islands studied by Charles Darwin situated at the equator in the Pacific Ocean The data is taken from http:// www.statsci.org/data/general/galapagos.html and comprises several measurements of characteristics of twenty nine of the islands in the Gal´apagos We will presently consider a subset of this data given by the seven attributes outlined in Table 2.4 Which one of the following statements is correct Attribute description Abbrev',\n",
              " 'elevation above sea-level (in m) Elev x5 Distance to nearest island (in km) DistNI x6 Distance to Santa Cruz Island (in km) StCruz x7 Area of adjacent island (in km2 ) AreaNI Table 2.4 The seven attributes of the data on a selection of 29 of the Gal´apagos islands A All the attributes are ratio and continuous B All the attributes are interval and discrete C Only two of the attributes are discrete but all at\\ufffetributes are ratio D Some of the attributes can take negative values E Don’t know Question 3: No Attribute description x1 Liters of gasoline consumed by an engine per hour x2 Charge, as measured by number of ionized atoms x3 Order in which runners finish a marathon x4 Brand of car (Toyota, VW, BMW, etc.) x5 Longitudinal position of a city on earth Table 2.5 Five different attributes Consider the six attributes with their description in table 2.5 Which of the following statements about the type of the attributes is true',\n",
              " 'B x2 is discrete interval, x3 is discrete ordinal and x5 is continuous ratio C x1 and x5 are continuous ratio and x4 is nominal D x1 is continuous ratio, x2 discrete ratio and x5 is continuous interval E Don’t know Question 4: We will consider the Poverty dataset2 described in table 2.6 The dataset consists of 91 coun\\ufffetries (observations) and six input attributes x1,  , x6 as well as the output yr providing the gross national prod\\ufffeuct pr capita (denoted GNP) Which one of the following statements regarding the dataset is correct 2 Dataset obtained from https://www2.stetson.edu/~jrasp/data/Poverty.xls28 2 Data and attribute types No Attribute description Abbrev x1 Live birth rate per 1000 population BirthRt x2 Death rate per 1000 population DeathRt x3 Infant deaths per 1000 population under 1 year InfMort x4 Life expectancy at births for males LExpM x5 Life expectancy at births for females LExpF x6 Region encoded as 1, 2,',\n",
              " 'Description of the features of the Poverty dataset used in this exam The dataset consists of popu\\ufffelation statistics of countries provided by the 1990 United Nations statistical almanacs , x5 respectively pro\\ufffevide statistics on birth rates, death rates, infant deaths, and life expectancy by gender and x6 denotes location of each country in terms of regions such that 1 = Eastern Europe, 2 = South America/Mexico, 3 = Western Eu\\uffferope/US/Canada/Australia/NewZealand/Japan, 4 = Middle East, 5 = Asia and 6 = Africa The data has been processed such that countries having missing values have been removed We consider the goal as predicting the gross national prod\\ufffeuct (GNP) pr capita both as a regression and classification task For regression tasks, yr will refer to the continuous value of GNP For classification tasks the attribute yb is discrete formed by thresholding yr at the median value and takes val\\ufffeues yb = 0 (corresponding to low GNP level) and yb = 1 (corresponding to a high GNP level)',\n",
              " 'A All the input attributes x1,  , x6 are ratio B One of the six input attributes is nominal C All the input attributes x1,  , x6 are interval D The output attribute yr is ordinal E Don’t know.3 Principal Component Analysis Principal component analysis (PCA) is a widely applicable technique where the goal is to find a lower-dimensional representation of a high-dimensional dataset A lower-dimensional representa\\ufffetion is useful in a variety of circumstances For instance (lossy) compression, as a pre-processing step of very high-dimensional data or as a powerful visualization technique PCA was invented in 1901 by the Statistician Karl Pearson[Pearson, 1901], but has been re-discovered numerous times in other fields under different names such as the Kosambi-Karhunen-Lo`eve transform in signal processing [Kosambi, 1943], the Hotelling transform in quality control [Hotelling, 1933]',\n",
              " 'Before introducing PCA we will first recap standard definitions from linear algebra A reader familiar with subspaces and projections can skip this section 3.1 Projections and subspaces⋆ Recall an M-dimension vector space is simply the set of M-dimensional vectors x where x = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8f0 x1 x2  xM \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fb , (3.1) and we write this as x ∈ RM Further, recall that if x, y ∈ RM and a, b are real numbers then the vector z = ax + by also belongs to RM and we say that RM is closed under linear transformations Finally, recall that the transpose of a vector x is written as x T and corresponds to flipping the vector along its diagonal: x T =  x1 x2 · · · xM  .\\x00\\x0030 3 Principal Component Analysis x1 x2 −5 −4 −3 −2 −1 0 1 2 3 4 5 −5 −4 −3 −2 −1 0 1 2 3 4 5 w2 w1 x1 x2 x3 0 1 2 3 4 5 −2 −1 0 1 2 0 1 Fig Examples of a one- and two-dimensional subspace of R 2 and R 3 respectively The subspaces can be thought of as generated by all linear combinations of the basis vectors shown as the red arrows',\n",
              " 'The key property of a subspace is that it is closed under linear transformations Thus, a subspace V of RM is a set of M-dimensional vectors such that if x, y ∈ V then ax + by ∈ V, for any values of a and b A simpler way to think of a subspace is that the subspace is generated by a set of vectors Suppose x1,  , xn ∈ RM is any set of n vector in RM, we can then define the span of x1,  , xn as all vectors z that can be written as z = a1x1 + a2x2 + · · · + anxn (3.2) where a1,  , an are arbitrary We write this set of vectors as V = span(x1,  , xn) and it is easy to show that V is a subspace of RM To consider a simple example, suppose we consider the span of a single vector V1 = span \\x12\\x141 1 2 \\x15\\x13 , (3.3) then V1 corresponds to all vectors that can be written as \\x14 x y \\x15 = a1 \\x14 1 1 2 \\x15 (for arbitrary a1) and they are shown as the black line in fig 3.1 (left pane) where the red arrow is the vector \\x14 1 1 2 \\x15  A slightly more elaborate example is shown in the right pane of fig',\n",
              " '(3.4) Notice, nothing prevents the span of M vectors to be all of RM To take a few more definitions, remember the length of a vector x is ∥x∥ = √ xT x = q x 2 1 + x 2 2 + · · · x 2 M (3.5) and two vectors x, y are orthogonal if x T y = 0 For instance \\x14 1 −1 \\x15T \\x14 1 1 \\x15 = 0 and the reader can check these two vectors are indeed orthogonal by drawing them on a sheet of paper A set of vectors x1,  , xn are said to be linearly independent if 0 = a1x1 + a2x2 + · · · + anxn implies a1 = a2 = · · · = an = 0 Otherwise, they are said to be linearly dependent This brings us to the first central definition: A basis of a subspace V is a set of vectors v1,  , vn such that span(v1,  , vn) = V and v1,  , vn are linearly independent The definition of a basis simply means that v1,  , vn are sufficient to generate V and at the same time V cannot be generated by fewer than n vectors',\n",
              " 'However, the number of vectors in the basis n will always be the same We can therefore say that n is the dimension of the subspace If we return to fig 3.1, the red vectors form a basis for the two spaces shown in the two panes and they have dimension 1 and 2 respectively corresponding to a line and a plane It is often convenient that the vectors in the basis are of length 1 and pairwise orthogonal, i.e v T i vj = 0 for i ̸= j If this is satisfied for a basis v1,  , vn the basis is said to be orthonormal It is always possible to find an orthonormal basis for a subspace 3.1.2 Projection onto a subspace Suppose we consider any vector x in a subspace V with orthonormal basis v1,  Then by the definition of a subspace x can be written as x = a1v1 + a2v2 + · · · + · · · anvn, for suitable choice of a1, a2,  The reason why an orthonormal basis is so important is that it allows us to easily compute the numbers a1, a2,',\n",
              " 'Left pane: Projection of a 3D point x (blue circle) onto the subspace spanned by the orthonormal basis v1, v2 The projection, shown as the red square, lies within the subspace and the right pane shows the point in the 2D coordinate system given by the basis vectors of the subspace v T i x = a1v T i v1 + · · · + aiv T i vi + anv T i vn = a1 · 0 + · · · + ai · 1 + · · · + an · 0 = ai (3.6) and so we can find ai by simply computing ai = x T vi  However, what if x does not lie in V  We can still compute the n numbers b1 = x T v1, b2 = x T v2,  bn = x T vn and then form a new vector x ′ which does lie in V : x ′ = b1v1 + · · · + bnvn (3.7) One can show x ′ is the point in V closest to x and we say that x ′ , defined above, is the projection of x onto V  We also say the n-dimensional vector b = \\uf8ee \\uf8ef \\uf8ef \\uf8f0 b1 b2  bn \\uf8f9 \\uf8fa \\uf8fa \\uf8fb is the coordinates of x in the subspace V  Notice, this is an n-dimensional vector whereas the space that x was in is M-dimensional In the left pane of fig',\n",
              " 'In the right pane we have plotted the projected point, x ′ , with the coordinates in the new space V .3.2 Principal Component Analysis 33 x1 x2 0 0.5 1 1.5 2 0 0.5 1 1.5 2 Fig (Left:) A simple 2D dataset X comprising two features x1 and x2 that are noisy observations of the same quantity Therefore, the dataset in fact only contains one “data-dimension” even though it is two-dimensional (Right:) A more elaborate dataset example corresponding to N = 9 observations each corresponding to 48 × 48 pixel images of the same digit but rotated From the perspective of the matrix X the dataset contains M = 2304 attributes, (corresponding to the number of pixels), however from another perspective only one dimension matters, namely the rotation PCA is able to discover the lower-dimensional representation of the dataset X in the first example but not in the second Finally, suppose we collect the basis vectors v1, v2,  , vn in a matrix V : V =  v1 v2',\n",
              " '3.2 as the red square: b T =  b1 b2  = x T  v1 v2  3.2 Principal Component Analysis Suppose we consider a two-dimensional dataset, however, unbeknownst to us the two dimensions are just noisy measurements of the same quantity If we plot each observation in the dataset as a point we obtain a figure similar to fig 3.3 (left pane) where the points nearly lie on a straight line Even though the dataset is two-dimensional, there is really only a single dimension that matters,\\x00\\x00\\x00\\x00\\x00\\x0034 3 Principal Component Analysis namely the line along which the observations lie For a more ambitious example, consider a dataset comprised of N = 9 observations of the same image of the digit 1 but rotated around the center shown in fig 3.3 (right pane) Each image is 48 × 48 pixels large so if we consider each pixel as a feature we can represent an image as one long vector in a M = 2304 dimensionsal space',\n",
              " 'That the number of “true” dimensions in the dataset is often much lower than the number of observed dimensions is a common feature of many machine learning problems and the goal of prin\\ufffecipal component analysis is to discover a lower-dimensional representation of the high-dimensional data set where it is assumed the lower-dimensional representations are linear This is the case for 2D example in fig 3.3 (left pane) which PCA can solve, however, not the case for the rotated digits example in the right pane which would require more advanced methods than will be considered here To make the discussion concrete, assume we are in the standard setting encountered previ\\ufffeously where we are given N observations x1, x2,  , xN ∈ RM each consisting of M features or dimensions In principal component analysis we select a number n and then we wish to find a new n-dimensional representation b1, b2,  , bN ∈ R n where n ≤ M and such that bi “represents” the observation xi',\n",
              " '3.3 (left pane) M = 2 (the number of observed features) and the representation we are interested in would have n = 1 The simplest way to transform vectors from a M dimensional space to a n ≤ M-dimensional space is to select an orthonormal basis v1,  , vn of a n-dimensional subspace V and define each bi as the projection of xi onto V  Since we want the projection to be invariant under addition of a constant we first subtract the mean from each xi  The general layout of the PCA algorithm is then: \\x88 Compute the mean m = 1 N PN i=1 xi \\x88 Subtract the mean from xi : x˜i = xi − m (and collect all x˜i into an N × M matrix X˜) \\x88 Project onto V : b T i = x˜ T i V where V =  v1 v2 · · · vn  is the projection matrix corresponding to the basis v1,  Notice the centering step where the mean is subtracted is the same scheme that we encountered in the previous chapter So how do we select the projection matrix V  We will first consider the simplest case in which n = 1, i.e',\n",
              " 'It is useful to consider a concrete example to get some intuition about what different choices of v1 implies 3.4 (top panes) we have shown the projection of the same 2D dataset onto three different choices of v1 and in the bottom panes we have plotted the projected coordinates bi = x˜ T i v1, i.e the 1-dimensional “representation” of each x˜i  From an intuitive point of view the first projection is worse than the last since it lumps the observations together with large residuals (indicated by the blue and red lines) The same pattern is repeated in fig 3.5, here we consider a 3d dataset and still project it onto different 1-dimensional subspaces The first projection has large residuals and also lumps all classes together while in the third the residuals are much smaller and the data in the projection thereby more spread out thus preserving more information about the data What these three projections have in common is that the observations, in the projected coordinates b1,',\n",
              " 'An example 2D dataset colored for our convenience (the dots in the top panes are the same in all 3 panes) is projected onto three different 1D subspaces corresponding to different choices of basis vector v1 The dataset in the projected coordinate system is shown in the bottom pane As can be seen, different choices of basis vectors preserve different amounts of information, with the vector corresponding to the right-most pane preserving the most information since the dataset is the most spread out are more spread out (thereby providing smaller residuals indicated by the lines connecting the points to the 1-dimensional subspace) The degree to which the projected observations are spread out can be measured by the variance of b1,  , bN scaled by a factor of N 1 : W = N × Variance[b1,  , bN ] = N 1 N X N i=1 \\ufffe bi − ¯b \\x012 = X N i=1 \\ufffe bi − ¯b \\x012 , where: ¯b = 1 N X N i=1 bi  (3.10) The reason for multiplying with N will be apparent later',\n",
              " '3.4 and fig 3.5 over the other To put it formally, 1 We here consider the biased estimate of variance where we divide by N, see chapter \\x00\\x0036 3 Principal Component Analysis −5 0 5 −5 0 5 −5 0 5 −5 0 5 −5 0 5 −5 0 5 −5 0 5 −5 0 5 −5 0 5 x T v1 −5 0 5 0 0.2 0.4 0.6 0.8 x T v1 −5 0 5 0 0.2 0.4 0.6 0.8 x T v1 −5 0 5 0 0.2 0.4 0.6 0.8 Fig Similar to the example fig 3.4, a 3D dataset (colored for our convenience) is projected onto three different 1D subspaces corresponding to different choices of basis vector v1 The dataset in the projected coordinate system is shown in the bottom pane As can be seen, different choices of basis vectors preserve different amounts of information, with the vector corresponding to the right-most pane preserving the most information since the dataset is the most spread out v1 = The vector of length 1 that maximize W = arg max vT v=1 W In the next section we will solve this maximization problem and then consider the general case where n > 1',\n",
              " 'The maximization of eq (3.12) under this constraint can be done by introducing the Lagrangian multiplier λ and maximizing the Lagrangian 2 L = W + λ(1 − ∥v1∥ 2 ) = v T 1 (S − λI) v1 + λ (3.13) with respect to λ and v1 Taking the derivatives with respect to the vector and λ we obtain: ∂ ∂λL = 1 − v T 1 v1 = 0 (3.14) ∇v1L = (S − λI)v1 = 0 (3.15) From the first equation we simply observe that v1 should be normalized The second equation can be re-written as: Sv1 = λv1 (3.16) This means that v1 should be an eigenvector of S with eigenvalue λ So which eigenvector should we choose If we look at the cost function eq (3.12) which we wish to maximize it can be re-written: W = v T 1 Sv1 = v T 1 λv1 = λ Thus, we should select v1 as the eigenvector of S corresponding to the largest eigenvalue This solves the case n = 1 The case n ≥ 2 is similar but requires slightly more work First we collect the bi ’s into an N × n matrix B T =  b1 b2 · · · bN T',\n",
              " 'We will simply re-use this idea for the case n > 1 and thereby define the Frobenius norm: W = ∥B∥ 2 F = X N i=1 Xn j=1 B 2 ij We can therefore simply maximize W where we ensure v T i vj = 0 for i ̸= j since we are looking for an orthonormal basis To put it formally, v1, · · · , vn = The n orthonormal vectors that maximize W  2 If you are unfamiliar with Langrangian multipliers see Appendix A and https://en.wikipedia.org/ wiki/Lagrange_multiplier.\\x00\\x0038 3 Principal Component Analysis −5 0 5 −5 0 5 −5 0 5 −5 0 5 −5 0 5 −5 0 5 −5 0 5 −5 0 5 −5 0 5 x T v1 x T v2 4 2 0 −2 −4 −4 −2 0 2 4 x T v1 x T v2 4 2 0 −2 −4 −4 −2 0 2 4 x T v1 x T v2 4 2 0 −2 −4 −4 −2 0 2 4 Fig This time, the same 3D dataset as in fig 3.5 is projected onto three different 2D planes corre\\ufffesponding to the three panes in the top row The inserts in the bottom row is the points in the coordinate system corresponding to the subspace',\n",
              " 'It turns out the solution to this maximization problem is to select v1,  , vn as the n orthonormal eigenvectors of S with the n largest eigenvalues The case n = 2 is illustrated in fig 3.6 where the right-most plane corresponds to the two largest eigenvectors and the other two panes corresponds to different choices of basis We again see the choice of eigenvectors ensures the observations are the most spread out Now that we have defined v1, · · · , vn this formally completes the PCA algorithm However, there is a simple (and natural) way to represent the eigenvectors using the Singular value decomposition (SVD) which makes PCA much easier to compute We will therefore introduce the SVD and explain its relationship to PCA 3.3 Singular Value Decomposition and PCA The singular value decomposition (SVD) provides an easy way to compute the n eigenvectors corresponding to the n largest eigenvalues',\n",
              " '0 0 · · · σM 0 0 · · · 0  0 0 · · · 0 \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fb , U =  u1,u2,  ,uN  V =  v1, v2,  , vM  such that UΣV T = X and V TV = I, U T U = I and σ1 ≥ σ2 ≥ · · · ≥ σM are known as the singular values of X Notice these conditions implies that v T i vj = 0 if i ̸= j and otherwise 1; in other words the columns of V are orthonormal This has some interesting consequences For instance if we compute: V T vi = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8f0 v T 1  v T M \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fb vi = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8f0 v T 1 vi  v T Mvi \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fb = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8f0 0  0 \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fb = ei This can be used to show: (XT X)vi = (V ΣT U T UΣV T )vi = V ΣT Σei = V σ 2 i ei = σ 2 i vi So each vi is an eigenvector of XT X with associated eigenvalue σ 2 i and the eigenvectors are sorted according to their eigenvalues This should sound very familiar',\n",
              " '(3.9), the projection of a single observation x T i onto the subspace spanned by the first n principal components can therefore be written as b T i = x T i V n 3.3.1 The PCA algorithm Gathering the previous discussion, we can define the PCA algorithm on a matrix X where the dataset is projected onto the first n components as follows: \\x88 Subtract the mean: x˜i = xi − m, m = 1 N PN i=1 xi \\x88 Divide by standard deviation (Optional): ˜xij = x˜ij sk , where sk = q 1 N−1 PN i=1 x˜ 2 ik \\x88 Compute the SVD: UΣV T = X˜ \\x88 The n first principal components are v1,  , vn and coordinates of observation i when projected onto the subspace spanned by the first n principal components are b T i = x˜ T i V n or alternatively B = XV˜ n where V n =  v1,  , vn  .\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0040 3 Principal Component Analysis In the above steps are included the optional step indicated in gray to not only center the data but also normalize each attribute by further dividing each attribute by its standard deviation',\n",
              " 'if one attribute have very large variance compared to the other attributes the first principal component will be highly driven by this attribute in order to account for as much of the variance as possible in the data 3.3.2 Variance explained by the PCA The vectors bi in the matrix B represents the coordinates of the vector xi when it is projected onto the n-dimensional subspace, i.e the bottom row in fig What if we want to know what vector in the original space bi =  bi1 bi2 · · · binT corresponds to the intersection with the line in the top-row of fig Similar to eq (3.7) we can find the projected coordinates in the original space as: x ′ i = bi1v1 + · · · + binvn = V nbi , or if we choose this can be written more condensed for all observations as X′ = \\x10 V nB T \\x11T = XV˜ nV T n  (3.17) The case n = M is worth mentioning',\n",
              " 'In this case the projected matrix B is still different from X˜ – it is exactly corresponding to “rotating” all observations (in M dimensions!) and then, when translating back to X′ , we just “rotate back” without losing information In general, the reconstructed matrix X′ will have lost information if n < M (or alternatively, variability in the data) compared to X˜ — in linear algebra terms we lose all variability of X˜ which is orthogonal to the space V n because we project those directions away A natural way to measure how much variance — or information about X˜ — is retained in a reconstruction based on n principal components is the variance explained computed using the Fr¨obenius norm: Variance Explained = ∥X′ ∥ 2 F ∥X˜∥ 2 F Using the fact that ∥X∥ 2 F = trace(XT X) and plugging in the definition of the SVD (exploiting (AB) T = B T A T and trace(AB) = trace(BA)) one can show that ∥X′ ∥ 2 F = Pn i=1 σ 2 i and ∥X˜∥ 2 F = PM i=1 σ 2 i',\n",
              " '(3.18) As we expect the case where n = M guarantees that all variance will be conserved, however, if some σi are zero we can still perfectly represent all variance with fewer than M directions This case corresponds to the dataset residing in a subspace of V having dimension less than M In two dimensions, this could be if the observations fall exactly on a line.\\x00\\x003.4 Applications of principal component analysis 41 x1 x2 x3 5.5 6 6.5 2.6 2.8 3 3.2 3.4 3.6 2.5 3 3.5 4 4.5 5 v1 v2 v3 x1 x2 x3 −0.5 0 0.5 1 −0.5 0 0.5 −1 −0.5 0 0.5 1 1.5 Fig The Fisher Iris dataset consisting of N = 150 observations of three types of flowers In the left pane the dataset is plotted as a scatter plot whereas in the right pane the mean of the dataset has been substracted to obtain the centered matrix X˜ and the three principal directions are plotted as unit vectors',\n",
              " 'The original data contains four features but we will presently only consider three of the features in order to visualize the data prior to the PCA, thus each observation consists of M = 3 features The dataset, labelled according to flower type, is shown in fig 3.7 (left pane) The first step of the PCA analysis is to subtract the mean of the dataset to obtain the centered matrix X˜ (X˜ ij = Xij − 1 N PN i=1 Xij ) Then, a SVD is performed to obtain the decomposition X˜ = UΣV T  The mean vector m and the principal component directions, i.e columns of V =  v1 v2 v3  , are approximately: m = \\uf8ee \\uf8f0 5.8 3.1 3.8 \\uf8f9 \\uf8fb , v1 = \\uf8ee \\uf8f0 0.4 −0.1 0.9 \\uf8f9 \\uf8fb , v2 = \\uf8ee \\uf8f0 −0.6 −0.7 0.2 \\uf8f9 \\uf8fb , v3 = \\uf8ee \\uf8f0 −0.7 0.7 0.3 \\uf8f9 \\uf8fb , and are shown in fig 3.7 as colored vectors Notice the first principal direction follows the main direction of variability in the data Let’s consider the projections onto the principal directions These can be found in fig',\n",
              " 'As can be\\x00\\x0042 3 Principal Component Analysis Xv˜ 1 −2 −1 0 1 2 Xv˜ 1 ˜ Xv2 −1.5 −1 −0.5 0 0.5 1 1.5 −1.5 −1 −0.5 0 0.5 1 1.5 Xv˜ 1 Xv˜ 2 ˜ Xv3 −1 0 1 −0.5 0 0.5 1 0 0.5 1 Fig The Fisher Iris dataset of fig 3.7 projected onto the principal directions In the first pane only the first principal direction is used corresponding to a large loss of information In the second pane two principal directions are used better preserving the structure of the data and finally the third pane use all principal directions and therefore only corresponds to a rotation seen the right-most figure, corresponding to using all principal directions, simply corresponds to rotating the dataset in fig 3.7 until the PCA directions are oriented along the axis The other plots are obtained by projecting away principal direction v3 and then v3 and v2 and therefore lose information Finally let’s turn to the variance explained by the principal directions',\n",
              " '(Left:) Variance explained by each of the three principal directions from the Fisher Iris example of fig Nearly all variation is explained by the first and second principal directions which can be interpreted as the original dataset residing on a 2D plane spanned by the first and second principal directions (Right:) Cumulative variance explained by the subspaces spanned by only v1, then v1 and v2 and finally v1, v2 and v3 Compare to fig computed from Σ and in our example Σ = \\uf8ee \\uf8f0 11.7 0 0 0 3.0 0 0 0 1.5 \\uf8f9 \\uf8fb ,3.4 Applications of principal component analysis 43 and the variance explained by each component can be seen in fig For instance the first com\\ufffeponent alone explains 11.7 2 11.7 2+32+1.5 2 ≈ 92% of the variance 3.4.1 Example 1: Interpreting PCA components The PCA components, along with label information, can often be given a physical interpretation To see this, we will consider a subset of the Cities dataset 3',\n",
              " 'Higher rating means better We apply PCA as described in section 3.3.1 where we first standardize by subtracting the mean, and include the step where we divide by the standard deviation since the ratings have substantially different scale After carrying out an SVD, we obtain the matrices U, Σ, and V , where as usual the two first columns of V are the first two principal components: v1 = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8f0 0.55 0.31 0.42 0.37 0.54 \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fb , v2 = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8f0 −0.11 0.78 0.02 −0.61 0.06 \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fb , Σ = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8f0 29.8 0 0 0 0 0 17.6 0 0 0 0 0 14.5 0 0 0 0 0 13.8 0 0 0 0 0 6.3 \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fb  (3.18) we see these two components accounts for 54 and 19 percent of the variance respectively To interpret any of these components, for instance the first principal component v1, it is useful to imagine what properties an observation which have a very large (or very small) projection onto v1, i.e an observation x = v1 or x = −v1, would have',\n",
              " 'In other words, the feature of a city v1 expresses is that cities that have a high value of one coordinate generally also have a high value of the other coordinates and visa versa To put this in simpler terms, PC one seems to measure if a city is good (versus bad), and cities that are good typically have many hospitals, lower crime, a lot of transportation options, art, and so on If we then focus on v2, we se only two attributes, crime and education, are relevant as their magnitude is quite a lot bigger than the rest In this case they have opposite signs, which means an observation with a large projection onto v2 would have high value of crime and low value of education (i.e., an orderly city with poor education options) and the other way around for an observation with a negative projection (a relatively criminal city with good education options)',\n",
              " 'We see the second principal component might express a big-city effect, such that the two large cities (Las Vegas and New York) are singled out as very orderly cities with a neglected school system, whereas those with the lowest projection (Cumberland and Scranton) are much smaller cities Obviously these specific interpretation are quite subjective and should only be treated as a hypothesis at this point Furthermore, as we consider v3, v4 and so on they will generally be more difficult to interpret and may simply capture noise 3 See https://mathworks.com/help/stats/sample-data-sets.html44 3 Principal Component Analysis -4 -2 0 2 4 6 8 10 12 14 -3 -2 -1 0 1 2 3 4 Cumberland, MD-WV  Las Vegas, NV Miami-Hialeah, FL New York, NY  Scranton-Wilkes Barre, PA  Stockton, CA  Fig Projection of the cities dataset onto the first two principal components Names of cities with the largest/smallest projection onto the second principal component have been inserted',\n",
              " 'We will consider the MNIST dataset and first limit ourselves to N = 1000 observations corresponding to images of the digits 0 and 1 Recall the MNIST dataset contains 28 × 28 pixel images and thus the dataset considered corresponds to a matrix X of size N × M where M = 784 Suppose we compute the first two principal components of X˜ using the PCA algorithm and plot X˜ projected onto these first two components, XV˜ 2 A plot of the projected data can be seen in the top of fig 3.11 where the red dots correspond to 1’s and the blue dots to 0’s From the plot we learn that the first two principal components, and in fact only the first which is plotted along the x-axis, is enough to distinguish these two classes fairly well To get an idea about what the two principal components consist of we place a grid on top of the projected dots (top right pane) and select those observations nearest to the grid points The corresponding observations are plotted in the bottom left pane of fig',\n",
              " 'In the bottom right-most pane we have plotted the same images as in the left pane but projected back into the original space using eq (3.17) (we have added back the mean value for easier visualization) This plot provides a visualization of what we “see” when we consider only the first two principal components The plot confirms our interpretation from before, however, we also see that the two first principal components arguably correspond to a significant loss of information, exactly as we can expect when we project a high dimensional dataset onto only the first two principal components.3.4 Applications of principal component analysis 45 x T v1 x T v2 −4 −2 0 2 4 6 8 −2 0 2 4 6 x T v1 x T v2 −4 −2 0 2 4 6 8 −2 0 2 4 6 Fig N = 1000 observations from the MNIST dataset of the digits 0 and 1 are projected onto the first 2 principal directions as shown in the top-left pane',\n",
              " 'If we select the observations the closest to the grid points in the top right pane and plot the observations in the bottom left pane we see the first principal direction separates 1s from 0s while the second corresponds to slanting and bolding (vertical direction) In the bottom-right pane, we have plotted the PCA projections; we see much of the information is lost when projecting onto the first 2 principal directions To get an idea about how much information we lose, we consider the full MNIST dataset containing 10 classes of digits and a total of N = 60000 observations In the top row of fig 3.12 we plot 10 randomly selected digits from each of the 10 classes, and in the following rows we plot the PCA reconstruction based on n = 2, 5, 20, 50, 100 principal directions As expected, the reconstructions are awful when only a few directions are used',\n",
              " 'For n = 100 only a small amount of smudge separate the reconstruction from the true images; this corresponds to a compression level of almost 8 In46 3 Principal Component Analysis Fig Top row: 10 randomly chosen digits from the MNIST dataset They are then reconstructed from n = 2, 5, 20, 50, 100 PCA components in the next 5 rows We see that about 50 principal directions is enough to make a fairly good reconstruction of the images corresponding to a compression factor of about 16 3.13 and fig 3.14 we have plotted a subset of 5000 digits projected onto the first two principal components as well as when projected onto the space spanned by component 1 and 3 and 2 and 3 We again see the first plot easily allows 0 and 1 to be separated, however, the other digit classes have significant overlap 3.4.3 Uses of PCA PCA can be used in a variety of circumstances and ways For instance Visualization PCA is a easily applicable tool for data visualization',\n",
              " '1) and the harder tasks Feature extraction Applying PCA provides new features that can be used for other machine\\ufffelearning techniques Compression As we saw in the MNIST case, PCA provides a very simple yet efficient lossy compression method Despite these valid points, it is important to remember that PCA, when n < M, implies a loss of information In the MNIST case this loss of information is very significant when n < 50, and one should therefore not automatically apply PCA We will later consider more in depth how to3.4 Applications of principal component analysis 47 0 1 2 3 4 5 6 7 8 9 x T v1 x T v2 −4 −2 0 2 4 6 8 −6 −4 −2 0 2 4 6 Fig N = 2000 observations of the MNIST dataset projected onto principal direction v1 and v2 validate machine-learning techniques and this will provide insight into how to determine if PCA is applicable and also how the number of principal components n should be selected',\n",
              " 'As a final comment, the normalization step in PCA can be of great importance If the coordinates represent the same type of quantity and are on the same scale, for instance pixel intensities as in this example, the normalization step should likely be excluded However, if the coordinates represent different things and are on vastly different scales the normalization step is important For instance, suppose one dataset record the height of a person in meters as well as the person’s annual income in USD PCA will then accurately detect that the variance in the dataset is primarily in the annual income, after all this quantity will vary with many thousands between subjects while the height will only vary with about 1 meter In this manner, the first PC (trivially) becomes the income and PCA will not tell us anything about the interaction between the variables',\n",
              " 'N = 2000 observations of the MNIST dataset projected onto principal direction v1, v3 (left pane) and v2, v3 (right pane)3.4 Applications of principal component analysis 49 Problems 3.1 Question 1: The first and second principal compo\\ufffenents directions of the data in the RAT dataset (consid\\ufffeering only the attributes x1 − x13) in Table 3.1 are: v1 = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8f0 0.0247 −0.0388 −0.3288 −0.2131 0.0477 −0.4584 0.2683 −0.0838 −0.5020 −0.0200 −0.3091 −0.2588 0.3714 \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fb , v2 = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8f0 −0.0764 0.5675 −0.0550 0.2449 0.3115 −0.1999 0.1738 0.3668 −0.0737 0.2988 0.0628 0.4446 0.1051 \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fb  and in Figure 3.15 the data projected onto the first two principal components is plotted against the average con\\ufffesumer ratings (RAT) Which of the following statements is correct Attribute description Abbrev',\n",
              " 'Attributes in a study of ce\\ufffereals (i.e breakfast products, taken from http://lib.stat.cmu.edu/DASL/Datafiles/Cereals.html) The data we consider has 74 observations (i.e., the original data has 77 observations but three observations have been removed due to missing values) The data has 14 input at\\ufffetributes x1–x14 and one output variable y which defines the average rating of the cereal product given by the consumers The output RAT plotted against the first and sec\\ufffeond principal component respectively A Relatively high values of CAL, PROT, FAT, FIB, SUG, POT, VIT, SHELF, and WEIGHT and low values of TYPE, SOD, CARB, and CUPS will re\\ufffesult in a negative projection onto the first principal component B PCA2 primarily discriminates between relatively low values of PROT and high values of SHELF C The data projected onto the second principal compo\\ufffenent (i.e., PCA2) is positively correlated with RAT',\n",
              " 'E Don’t know Question 2: Consider the data set described in Ta\\ufffeble 3.2 Each attribute in the data set is standardized, and we carry out a principal component analysis (PCA) on the standardized input data, x1–x6 The singular val\\ufffeues obtained are: σ1 = 17.0, σ2 = 15.2, σ3 = 13.1, σ4 = 13.0, σ5 = 11.8, σ6 = 11.3 The first and second principal component directions are: v1 = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8f0 0.5238 0.5237 −0.3491 0.1981 −0.3369 0.4204 \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fb , v2 = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8f0 −0.2948 0.3452 0.3584 0.6808 −0.3049 −0.3302 \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fb  Which one of the following statements is incorrect?50 3 Principal Component Analysis No Attribute description Abbrev x1 Age of Mother in Whole Years Age x2 Mothers Weight in Pounds MW x3 Race (1 = Other, 0 = White) Race x4 History of Hypertension (1 = Yes, 0 = No) HT x5 Uterine Irritability (1 = Yes, 0 = No) UI x6 Number of Physician Visits First Trimester PV y Birth Weight in Kilo Grams BW Table 3.2',\n",
              " 'The data we consider contains 189 observations, 6 input at\\ufffetributes x1–x6, and one output variable y A The first three principal component account for more than 90% of the variation in the data B Relatively heavy, old and white mothers that fre\\ufffequently goes to the physician and have a history of hypertension but do not have uterine irritability will have a positive projection onto the first principal component C Relatively young, heavy mothers that are not white and have a history of hypertension but infrequently goes to the physician and do not have a uterine irri\\ufffetability will have a positive projection onto the sec\\ufffeond principal component D Since the data is standardized we do not need to sub\\ufffetract the mean when performing the PCA but can directly carry out the singular value decomposition on the standardized data E Don’t know Question 3: All the attributes of the Gal´apagos data are standardized and a principal component anal\\ufffeysis carried out on the standardized attributes x1–x7',\n",
              " 'A The first principal component accounts for more than 55% of the variance in the data B The first three principal components accounts for more than 90% of the variance in the data C The last principal component accounts for more than 1% of the variance in the data D Five principal components are required in order to account for more than 95% of the variance in the data E Don’t know Question 4: A principal component analysis is ap\\ufffeplied to a dataset composed of 1000 data points Af\\ufffeter applying the principal component analysis, the data\\ufffepoints (gray points) along with the right singular vectors (i.e the principal directions) (black arrows) are plotted Which of the subplots A, B, C, D of figure fig 3.16 cor\\uffferesponds to this description Figur C Figur D Figur A Figur B −1 −0.5 0 0.5 1 −1 −0.5 0 0.5 1 −1 −0.5 0 0.5 1 −1 −0.5 0 0.5 1 −1 −0.5 0 0.5 1 −1 −0.5 0 0.5 1 −1 −0.5 0 0.5 1 −1 −0.5 0 0.5 1 Fig',\n",
              " 'Question 5: A principal component analysis is car\\uffferied out on a dataset comprised of three data points x1, x2 and x3 collected in a N × M matrix X such that each row of the matrix is a data point Suppose the ma\\ufffetrix X˜ corresponds to X with the mean of each columns substracted i.e.3.4 Applications of principal component analysis 51 X = \\uf8ee \\uf8f0 3.00 2.00 1.00 4.00 1.00 2.00 0.00 1.00 2.00 \\uf8f9 \\uf8fb , X˜nm = Xnm − 1 N XN k=1 Xkm and suppose X˜ has the singular value decomposition: X˜ = UΣV ⊤, U = \\uf8ee \\uf8f0 −0.26 0.77 0.58 −0.54 −0.61 0.58 0.80 −0.16 0.58 \\uf8f9 \\uf8fb , Σ = \\uf8ee \\uf8f0 2.96 0.00 0.00 0.00 1.10 0.00 0.00 0.00 0.00 \\uf8f9 \\uf8fb V = \\uf8ee \\uf8f0 −0.99 −0.13 −0.00 −0.09 0.70 −0.71 0.09 −0.70 −0.71 \\uf8f9 \\uf8fb What is the (rounded to two significant digits) coor\\ufffedinates of the first observation x1 projected onto the 2- Dimensional subspace containing the maximal variation A  −3.06 0.31⊤ B  −0.78 0.85⊤ C  −1.07 0.21⊤ D  −3.16 0.23⊤ E Don’t know',\n",
              " 'The mean is subtracted from each attribute and the singular value decomposition (SVD) is applied to the data matrix of size 440 × 6 From the SVD we obtain for the matrices S and V : S=105 · \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8f0 2.69 0 0 0 0 0 0 2.53 0 0 0 0 0 0 1.05 0 0 0 0 0 0 0.83 0 0 0 0 0 0 0.49 0 0 0 0 0 0 0.31 \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fb , V = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8f0 −0.98 −0.11 −0.18 −0.04 0.02 −0.02 −0.12 0.52 0.51 −0.65 0.20 0.03 −0.06 0.76 −0.28 0.38 −0.16 0.41 −0.15 −0.02 0.71 0.65 0.22 −0.01 0.01 0.37 −0.20 0.15 0.21 −0.87 −0.07 0.06 0.28 −0.02 −0.92 −0.27 \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fb  We note that both S and V above have been rounded to the first couple of significant digits Which one of the following statements regarding the principal component analysis is correct A The first principal component accounts for less than 40 % of the variance in the data B The first three principal components account for more than 95 % of the variance in the data',\n",
              " 'D The fourth principal component accounts for more than 5 % of the variance in the data E Don’t know.\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x004 Summary statistics and measures of similarity In this chapter, we will consider more elementary properties and definitions of a dataset We will consider ways to summarize (or describe) attributes of the dataset but more importantly ways to compare observations 4.1 Attribute statistics When working with variables it is convenient to be able to summarize them using elementary statistical measures such as the mean and variance Suppose we record observations x1,  , xN of a particular attribute x, for instance corresponding to the weight of N = 20 schoolchildren',\n",
              " 'In this manner we define the empirical mean, variance and standard deviation as follows: Emperical mean of x: ˆµ ≈ 1 N X N i=1 xi (4.1) Emperical variance of x: ˆs ≈ 1 N − 1 X N i=1 (xi − µˆ) 2 (4.2) Emperical standard deviation of x: ˆσ ≈ √ sˆ (4.3) Notice that for the estimate of the variance (and therefore also for the standard deviation) we divided by N − 1 and not N This is because if we divide by N the estimate of the variance will be unrealistically small as we have used the data to also estimate the mean value 1  The estimates eq (4.2) and eq (4.3) are therefore called unbiased and for a small sample they are considered superior to the biased estimators 2 : 1 For completeness it should be mentioned that if N = 1 it is common to set ˆs = ˆσ = 0',\n",
              " 'The mean value provides important information about a sample, however, it is also affected by outliers A way to get around this is the median which corresponds to the value of x such that “half the observations” are greater than x and “half” are lower; i.e the value of x that’s “in the middle” of the dataset To put this formally, we first sort the values of x, x1, x2,  , xN in ascending order, i.e as x ′ 1 ≤ x ′ 2 ≤ · · · ≤ x ′ N  The median is then defined as the value of x such that “half” of the observations is less than x and “half” of the observations are greater than x If N is odd this is just x ′ (N+1)/2 , and if N is even we compute the average of the two middle values: Median of x: median[x] = ( x ′ (N+1)/2 if N is odd 1 2 \\x10 x ′ N/2 + x ′ N/2+1\\x11 if N is even (4.4) Percentile The concept of the median can be generalized to percentiles',\n",
              " 'Consider for instance N = 200 university students where xi denotes the grade average of student i,s i = 1,  The p = 90%’th percentile is then a value of the grade average xp=90%, for instance xp=90% = 11.7, such that 180 students have a grade average less than xp=90% and 20 students have a grade average greater than xp=90% If we use the notation introduced for the median3 we might reasonably expect xp=90% ≈ x ′ ⌈Np⌉ , compare this to the definition of median which is obtained when p = 50% However, we have to use the approximately equal sign because the definition is slightly ambiguous If 180 students has a grade average less than 11.7, presumably the same 180 students has a grade average less than 11.7001 and just as for the median we therefore has to select a reasonable value of xp=90% somewhere between the grade of student x⌊Np⌋ and x⌈Np⌉',\n",
              " '3 The notation ⌈a⌉ rounds a upwards to the nearest integer whereas ⌊a⌋ rounds a downwards to the nearest integer For instance ⌈2.8⌉ = 3 and ⌊2.8⌋ = 2 4 Nevertheless, as a punishment to the curious, a popular interpolation method is linear interpolation defined as follows: Suppose the dataset is sorted as x ′ 1 ≤ x ′ 2 ≤ · · · ≤ x ′ N  The percentile function for a percentile p can then be defined by first introducing the “granulated percentiles” pi = 1 N (i − 1 2 ) for i = 1,  , N and the function X(z): X(z) = x ′ ⌊z⌋ + (z − ⌊z⌋)(x ′ ⌊z+1⌋ − x ′ ⌊z⌋) Notice if z is an integer X(z) = x ′ z The p’th percentile can then be defined as xp = X(z) where z is selected as z = \\uf8f1 \\uf8f4\\uf8f2 \\uf8f4\\uf8f3 N p + 1 2 if p1 ≤ p ≤ pN 1 if 0 ≤ p < p1 N if pN < p ≤ 1 (4.5)4.1 Attribute statistics 55 corˆ = 1.00 −4 −2 0 2 4 −4 −2 0 2 4 corˆ = 0.83 −4 −2 0 2 4 −4 −2 0 2 4 corˆ = 0.08 −4 −2 0 2 4 −4 −2 0 2 4 corˆ = −0.85 −4 −2 0 2 4 −4 −2 0 2 4 corˆ = −1.00 −4 −2 0 2 4 −4 −2 0 2 4 Fig',\n",
              " 'Mode We also define the mode as the most frequently occurring value of x1,  The mode may not be unique, for instance for the dataset 1, 2, 2, 4, 4 both 2 and 4 occur two times In this case we say both 2 and 4 are the mode of the dataset and that the dataset is multimodal For a value of x, we say that the number of times x occur in the dataset is the frequency of x In the previous example the frequency of 1 is 1, the frequency of 2 and 4 is 2 and the frequency of 7 is 0 4.1.1 Covariance and Correlation Covariance measures how much one variable y can be expected to change when another variable x changes and visa-versa Suppose we have a dataset containing two attributes x and y with recorded values x1, x2,  , xN and y1, y2,  If we let ˆµx and ˆµy denote the empirical mean of the two attributes the covariance of attribute x and y can be estimated as Empirical covariance of x, y: ˆcov[x, y] = 1 N − 1 X N i=1 (xi − µˆx) (yi − µˆy) (4.6) Notice that cov[x, x] = Var[x]',\n",
              " ', xM, we can compute the pairwise covariance between any two attributes cov[xi , xj ] and collect all these in an M ×M matrix Σ˜ where Σ˜ ij = cov[xi , xj ] This matrix is known as the covariance matrix A drawback of the covariance as a summary statistic is that it is affected by the scale of each attribute This can be overcome by standardizing with the empirical standard deviation of the two attributes, ˆσx and ˆσy, leading to the correlation of x and y: Empirical correlation of x, y: ˆcor[x, y] = ˆcov[x, y] σˆxσˆy = 1 N − 1 X N i=1 (xi − µˆx) (yi − µˆy) σˆxσˆy  (4.7) Correlation tells us how (linearly) related attributes are A correlation of 0 means that x tells us nothing about y, a positive correlation tells us that when x is large y is also likely to be large and a negative correlation tells us that if x is large y will typically be small.56 4 Summary statistics and measures of similarity Table 4.1',\n",
              " 'In this case ˆµy = aµˆx + b and ˆσy = |a|σˆx We then obtain: ˆcor[x, y] = 1 N−1 PN i=1 (xi − µˆx) (axi + b − (aµˆx + b)) σˆxσˆy = 1 N−1 PN i=1 a (xi − µˆx) (xi − µˆx) |a|σˆxσˆx = sign(a) So the correlation is −1 if a < 0 and 1 if a > 0 4.1 for further examples 4.2 Term-document matrix Suppose we have a collection of documents (for instance news stories) and we wish to analyse them using machine learning A problem is that the news stories will contain a different number of words and so they cannot naturally be represented as an N × M matrix A way to overcome this is to represent the documents as what is known as the term-document matrix Suppose as an example we consider three “documents” corresponding to three lines from the tale Clumsy Hans by H.C Andersen d1 = \\x1a ”I shall win the Princess!” they both said, as their father gave each one of them a beautiful horse',\n",
              " 'Each document can then be represented as a vector (of the same length as our vocabulary) where most of the entries are zero In addition, it is common to remove words that are very common such as an or the (these are called stop words) as well as remove the tense of the words by removing the last letters (called stemming) For instance horse and horses are considered to count as the same stem hors Doing this we obtain the table seen in table 4.1 where each row correspond to d1, d2 and d3 This table can then be considered as the dataset matrix X (i.e N corresponds to the number of documents and M, the number of features, to the number of4.3 Measures of distance 57 word-stems) and is known as the term-document matrix 5  For instance the first column of X is  0 0 1T because only the last document contains the word “assembled” 4.3 Measures of distance The concept of distance and similarity play a crucial role in machine learning',\n",
              " 'One way to phrase this problem is that we have to compare the image to what a cat ought to look like and what a dog ought to look like and determine which of the two the image is the most similar to A computer learning method will often do something similar, and for that reason studying measure of distance and similarity more explicitly is useful No simple definition exist for what a distance measure is except it is some function of two observations x, y such that the value is large when they are very dissimilar and small when they are very similar, however we are usually interested in measures of distance d which obey the following rules: non-negativity d(x, y) ≥ 0, (4.8) identity of indiscernibles d(x, y) = 0 if and only if x = y, (4.9) symmetry d(x, y) = d(y, x), (4.10) triangle inequality d(x, y) ≤ d(x, z) + d(z, y)',\n",
              " 'A measure of distance which obey the above rules is called a metric A common way to define distances is as the magnitude of the difference6 of observations, x − y which, in a vector space, is called a norm and is denoted by ∥x∥ It must in turn obey: non-negativity ∥x∥ > 0 if x ̸= 0, (4.12) scaling ∥ax∥ = |a|∥x∥ (4.13) triangle inequality ∥x + y∥ ≤ ∥x∥ + ∥y∥ (4.14) Then we can define the distance from the norm as d(x, y) = ∥x − y∥ (4.15) No doubt, the most familiar norm is the Euclidian norm Given a vector x it is defined as ∥x∥ = q x 2 1 + x 2 2 + · · · + x 2 M (4.16) 5 The reader may wonder why it is not called the document-term matrix when it has dimensions documents × terms This is because it is common in text analysis represents documents as the transpose of X, and we have decided to re-use the terminology 6 Naturally, this assume we can meaningfully subtract the two observations x, y from each other without getting into trouble',\n",
              " 'The remedy is ofcourse to apply a 1-of-K encoding to this attribute.\\x00\\x0058 4 Summary statistics and measures of similarity More generally, we have the Lp norm (or simply p-norm) which, for any number p ≥ 1 is defined as: ∥x∥p = (|x1| p + |x2| p + · · · + |xM| p ) 1 p  (4.17) It is common to extend this definition to p = ∞ by the definition: ∥x∥∞ = max{|x1|, |x2|,  (4.18) Based on the norm, we can define the p-distance as dp(x, y) = ∥x − y∥p = \\uf8f1 \\uf8f2 \\uf8f3 \\x10PM i=1 |xi − yi | p \\x11 1 p if 1 ≤ p < ∞ max{|x1 − y1|, |x2 − y2|,  , |xM − yM|} if p = ∞ Note in the particular case of the p = ∞ norm, the distances measures the largest difference in coordinates 4.2 we have plotted a large number of observations and colored those red which have a p-distance less than 1 to (0, 0), i.e dp(x, 0) ≤ 1, for 6 different values of p Note we have included p = 1 2 for completeness (see also Technical Note 4.3.1)',\n",
              " '(4.19) A useful way to think of the Fr¨obenius norm is as measuring the magnitude of the entire dataset: ∥X∥F = PN i=1 ∥xi∥ 2  Technical note 4.3.1: The case p < 1 of the p-norm For technical reasons the p < 1 case is more difficult In general, we define the p-distance when 0 < p < 1 as: dp(x, y) = |x1 − y1| p + |x2 − y2| p + · · · + |xM − yM| p , (4.20) and for the particular case p = 0 it is common to define 00 = 0 and then call the function ∥x∥0 = |x1| 0 + |x2| 0 + · · · + |xM| 0 , (4.21) which counts the number of non-zero coordinates of x the p = 0 norm Note from a math\\ufffeematical standpoint this is a misnomer since it does not obey the mathematical properties of a norm 4.3.1 The Mahalanobis Distance Suppose we are given a covariance matrix Σ, for instance estimated from a dataset as in eq',\n",
              " 'Illustration of the p-distance for various values of p A point x is colored red if it’s p distance to the center 0 is less than 1, dp(x, 0) ≤ 1 Top row: p = 1 2 , 1, 3 2 and bottom row: p = 2, 3, ∞ The red line is the decision boundary dp(x, 0) = 1 Increasing p corresponds to “inflating” the red region dM(x, y) = q (x − y) T Σ−1 (x − y) Notice, if p Σ = I the Mahalanobis distance reduces to the Euclidian distance: dM(x, y) = (x − y) T I(x − y) = ∥x − y∥2 If Σ is estimated from a dataset as in eq (4.6), what the corre\\ufffesponding Mahalanobis distance takes into account is (very roughly said) that the distance between two points should be lower when the points lie within the point cloud of the dataset For instance in fig 4.3 the distance between the two red points according to the Mahalanobis distance is 13 but only 4.15 between the blue points, however in both cases the Euclidian distance is roughly 5.65',\n",
              " 'Obviously, a measure of similarity can be constructed from a distance measure by a simple mapping The most simple way is to define s(x, y) = −d(x, y), however, often it is desirable to have a measure of similarity on a scale that goes from 0 to 1 and so one could choose: s(x, y) = a d(x, y) + a ,60 4 Summary statistics and measures of similarity -2 0 2 4 -3 -2 -1 0 1 2 3 Fig A simple 2D dataset to illustrate the Mahalanobis distance If we estimate the covariance matrix from the dataset, the Mahalanobis distance between the red points is 13 but only 4.15 between the blue points for a constant a > 0 Defining measures of similarity from distance is arguably a bit silly, but for some types of observations, measures of similarity may be easier to define than measure of dissimilarity Consider the important situation where x is binary, i.e xi = 0, 1 for all i',\n",
              " 'Then notice M = f11 + f10 + f01 + f00 and we can then define the following measures: Simple Matching Coefficient SMC(x, y) = f11 + f00 M (4.22) Jaccard Similarity J(x, y) = f11 f11 + f10 + f01 (4.23) Cosine similarity cos(x, y) = f11 ∥x∥∥y∥ (4.24) For general vectors x, y the cosine similarity and the extended Jaccard similarity can also be defined as: Extended Jaccard Similarity EJ(x, y) = x T y ∥x∥ 2 + ∥y∥ 2 − xT y (4.25) Cosine similarity cos(x, y) = x T y ∥x∥∥y∥ (4.26)4.4 Measures of similarity 61 Why do we need three different measures of similarity It is useful to consider the qualitative difference between these measures of similarity in context of the term-document example of table 4.1 We first notice the SMC makes no difference between 0 and 1; i.e if we flip the zeros and ones it makes no difference to the similarity: SMC(1 − x, 1 − y) = SMC(x, y)',\n",
              " 'However, for some datasets what is a zero and what is a one has an assymetric meaning Consider the term-document example For documents there will typically be many more 0s than 1s since a document only use a fraction of the vocabulary and so, since the 0s are counted as “matches”, the SMC will be large even for documents that have nothing in common, simply because they don’t contain many of the same words: According to the SMC a recipe for ice-cream and the US constitution is quite similar since they don’t use words like Armadillo, lumberjack or vacuum cleaner The Jaccard and cosine similarity gets around these problems by focusing on positive matches (i.e words the documents do have in common), however with an important twist: Suppose we compare two documents x and y which are on the same topic, but x is much longer than y',\n",
              " 'If we normalizing by the document length, as is done in the Cosine similarity, this will somewhat correct for this problem and is therefore more suitable if some vectors has much larger magnitude (in the binary case more 1s) than others and this difference is not in itself considered very informative.62 4 Summary statistics and measures of similarity Problems 4.1 Question 1: In table 4.2 is given the pairwise cityblock distances between 8 observations along with a description of the dataset What can be concluded about the similarity of observation o1 and o3 o1 o2 o3 o4 o5 o6 o7 o8 o1 0 4 7 9 5 5 5 6 o2 4 0 7 7 7 3 7 8 o3 7 7 0 10 6 6 4 9 o4 9 7 10 0 8 6 10 9 o5 5 7 6 8 0 8 6 7 o6 5 3 6 6 8 0 8 11 o7 5 7 4 10 6 8 0 7 o8 6 8 9 9 7 11 7 0 Table 4.2 Pairwise Cityblock distance, i.e d(oi, oi) = ∥xi − xj∥1 = PM k=1 |xik −xjk|, between 8 observations Each obser\\ufffevation oi corresponds to a M = 15 dimensional binary vector, xik ∈ {0, 1}',\n",
              " 'A COS(o1, o3) = 0.533 B J(o1, o3) = 0.533 C SMC(o1, o3) = 0.533 D There is insufficient information to draw specific con\\ufffeclusions E Don’t know Question 2: We will let J(A, B), SMC(A, B), and cos(A, B) denote the Jaccard Coefficient, Simple Matching Coefficient and Cosine Similarity respectively between observation A and B We will consider the data in Table 4.3 containing 10 observations denoted NS1, NS2, NS3, NS4, NS5, AS1, AS2, AS3, AS4, and AS5 such that the first observation is given by NS1= {1, 0, 0, 1, 0, 1, 1, 0} Which one of the following state\\ufffements is correct CDY CDN ASTY ASTN SIY SIN HFY HFN NS1 1 0 0 1 0 1 1 0 NS2 0 1 1 0 1 0 1 0 NS3 1 0 0 1 0 1 1 0 NS4 0 1 1 0 0 1 1 0 NS5 1 0 1 0 1 0 1 0 AS1 0 1 1 0 0 1 1 0 AS2 0 1 1 0 0 1 1 0 AS3 0 1 1 0 0 1 1 0 AS4 0 1 0 1 1 0 0 1 AS5 1 0 1 0 0 1 1 0 Table 4.3 Given are the first five subjects with normal se\\ufffemen (denoted NS1, NS2,  ., NS5) as well as the first five subjects with abnormal semen (denoted AS1, AS2,',\n",
              " 'A J(NS1,NS2) = SMC(NS1,NS2) B cos(NS4,NS5) = 1 8 C J(NS5,AS5) = SMC(NS5,AS5) D cos(NS5,AS5) = 3 4 E Don’t know Question 3: We will let J(A, B), SMC(A, B), and cos(A, B) denote the Jaccard Coefficient, Simple Match\\ufffeing Coefficient and Cosine Similarity respectively be\\ufffetween observation A and B We will consider the data in Table 4.4 containing 10 observations denoted S1, S2, S3, S4, S5, NS1, NS2, NS3, NS4, and NS5 such that the first observation is given by S1= {1, 0, 1, 0, 1, 0} Which one of the following statements is correct Y AY Y AN OAY OAN P AY P AN S1 1 0 1 0 1 0 S2 1 0 1 0 0 1 S3 0 1 0 1 1 0 S4 0 1 1 0 1 0 S5 0 1 1 0 1 0 NS1 0 1 1 0 1 0 NS2 0 1 0 1 1 0 NS3 1 0 0 1 0 1 NS4 0 1 1 0 1 0 NS5 0 1 1 0 1 0 Table 4.4 Given are five subjects that survived in Haber\\ufffeman’s study (denoted S1, S2,  ., S5) as well as the five sub\\ufffejects that did not survive in Haberman’s study (denoted NS1, NS2,',\n",
              " 'A Using the Jaccard coefficient S1 is more similar to S2 than to NS1, i.e J(S1, S2) > J(S1, NS1) B Using the Simple Matching coefficient S1 is more similar to S2 than to NS1, i.e SMC(S1, S2) > SMC(S1, NS1) C The Jaccard coefficient between S1 and S2 is identi\\ufffecal to the Cosine Similarity between S1 and S2, i.e J(S1, S2) = cos(S1, S2) D The Simple Matching coefficient between S1 and S2 is identical to the Cosine Similarity between S1 and S2, i.e SMC(S1, S2) = cos(S1, S2) E Don’t know Question 4:4.4 Measures of similarity 63 Mean Std xp=25% xp=50% xp=75% BirthRt 29.46 13.62 14.6 29 42.575 DeathRt 10.73 4.66 7.7 9.5 12.4 InfMort 55.28 46.05 13.025 43 88.25 LExpM 61.38 9.67 55.2 63.4 68.55 Table 4.5 Summary statistics of the first four attributes of the Poverty dataset The column xp=25% refers to the 25’th percentile of the given attribute, xp=50% to the median and xp=75% to the 75’th percentile',\n",
              " 'Table 4.5 contains summary statistics of the first four attributes of the Poverty dataset Which of the his\\ufffetograms in fig 4.4 match which of the attributes accord\\ufffeing to their summary statistics A BirthRt matches histogram 4, DeathRt matches his\\ufffetogram 2, InfMort matches histogram 1 and LExpM matches histogram 3 B BirthRt matches histogram 4, DeathRt matches his\\ufffetogram 1, InfMort matches histogram 3 and LExpM matches histogram 2 C BirthRt matches histogram 2, DeathRt matches his\\ufffetogram 3, InfMort matches histogram 1 and LExpM matches histogram 4 D BirthRt matches histogram 1, DeathRt matches his\\ufffetogram 2, InfMort matches histogram 4 and LExpM matches histogram 3 E Don’t know Question 5: Consider the dataset given in Figure 4.5 We will con\\ufffesider the Mahanalobis distance using the empirical co\\ufffevariance matrix estimated based on the 1000 blue obser\\ufffevations Which one of the following statements is correct A dataset of 1000 observations given by the blue dots',\n",
              " 'A The Mahanalobis distance between the two green circles is smaller than the Mahanalobis distance be\\ufffetween the two black squares B The Mahanalobis distance between the two red crosses is the same as the Mahanalobis distance be\\ufffetween the two green circles C The Mahanalobis distance between the two black squares is smaller than the Mahanalobis distance bewteen the two cyan plusses D The empirical covariance matrix estimated based on the blue observations has at least one element that is negative E Don’t know5 Discrete probabilities and information Correct reasoning is central to many areas of intellectual activity, including philosophy (how ought we reason?), cognitive science (how do we reason?), science (what does reason tell us about theories given experimental evidence?), and artificial intelligence (how do we build reasoning machines?)',\n",
              " '\\x88 Probabilities have something fundamental to say about reasoning under uncertainty In certain important situations, if we want to build an optimal reasoning machine, it ought to reason according to probability theory The reader no doubt has some familiarity with probability theory, however it is our experi\\ufffeence it is the single subject which causes the most difficulties We will therefore provide a fairly detailed introduction to probabilities and probabilistic concepts, with a focus on probabilities as plausible reasoning The reader should note we will introduce probabilities as the probability of true/false statements (i.e., the probability it will rain tomorrow), rather than statements about sets and stochastic variables, which is customary in statistics',\n",
              " 'bibliographical remarks Bayes’ theorem was first described by Thomas Bayes who considered a problem very akin to the binomial distribution example we will consider in 6.4 but his work was only published after his death in 1763 [Bayes and Price, 1763], and the subject was significantly expanded by other early pioneers such as Pierre-Simon Laplace and many others The approach to probability theory, including the interpretation as quantifying rational thought, was revitalized in the first half of the 20th century by Bruno de Finetti [De Finetti, 1937, Barlow, 1992], Harold Jeffreys [Jeffreys, 1939] and Richard T Cox [Cox, 1946] Information theory, which will be covered in the last section, is due to the seminal work by Claude Shannon in 1948 [Shannon, 1948] The normalized version of mutual information, which builds onto Shannon’s work, is due to Strehl and Ghosh [2002].66 5 Discrete probabilities and information Input Output Fig',\n",
              " '5.1 Probability basics An important part of what and intelligent robot should do is to reason correctly in light of evidence Now, reasoning can mean many things, but the specific sense we are interested in is something akin to the legal or scientific sense, in which multiple pieces of evidence are weighted so as to determine the plausibility of a conclusion In a legal context, the proposition we might be interested in could be: G : The accused is guilty (5.1a) E1 : A car similar to his was seen at the crime scene (5.1b) E2 : His mom says he was home on the night (5.1c) E3 : A large sum of money was found in his posession (5.1d) E4 : His fingerprints was found at the door of the bank (5.1e) If the robot was on the jury, we would ask it to determine the truth of G in light of the evidence E1,  That is, the robot should assume E1,  , E4 are true, and based on this form a belief about whether G is true or false1 , see fig',\n",
              " ', E4 are true we can simply ask the robot about G in light of E In fact, we will assume all inputs to the robot is of the form: A|B : Determine the plausiblity of A assuming B is true where it is assumed A and B can be any proposition which is either true or false For instance, in fig 5.1, our query to the robot would be of the form G|E 1 It is assumed there exists a more complete description of the symbols G, E1, etc. For instance, G would refer to a particular bank heist, etc etc.5.1 Probability basics 67 5.1.1 A primer on binary propositions⋆ Since all queries to the robot are binary true/false propositions (sometimes also called Boolean propositions), it is useful to introduce some basic notation governing these In the following sections, upper-case Latin letters A, B, C, etc will denote binary propositions, i.e statements that are either true or false',\n",
              " '(5.2) symbolically E = E1E2E3E4 The notation allows us to conveniently query the robot about hypothetical situations For instance, if the search on the suspects apartment had not turned up money, the evidence would be written as E′ = E1E2E3E4 and we would make the query G|E′  In addition to these operations, we will also define the following two special propositions:2 1 : A proposition which is always true (5.3a) 0 : A proposition which is always false (5.3b) The following identities should be intuitively obvious: A1 = A, A + A = 1, A = A In addition, we have the distributive rule: A(B1 + B2 + · · · + Bn) = AB1 + AB2 + · · · + ABn It is easy to verify this is the case If for instance the left-hand side is true, then both A and at least one of the Bi ’s must be true, but then the right-hand side is also true The following identity will also be useful: A + B = A B',\n",
              " 'If, for instance, both A and B are false then: A + B = 0 + 0 = 0 and A B = 0 0 = 1 = 0 5.1.2 Probabilities and plausibility Continuing the trial example, we cannot logically deduce G is true based on the evidence E (after all, there might be an innocent explanation of all the evidence), however certainly the evidence increases 2 Note we could have used other symbols than 0 and 1, for instance K0 and K1 If these two propositions cause the reader any issues, he or she can mentally substitute them for propositions which are indeed always true or false, for instance 2 + 2 = 4 and 1 + 1 = 4.68 5 Discrete probabilities and information our confidence G is true It is exactly this degree-of-belief in one proposition given another we model based on probabilities Specifically, we denote by the number P(G|E1E2E3E4) the degree-of-belief G is true given E1, E2, E3, and E4 are true',\n",
              " 'The degree of belief is a number between 0 and 1, with 0 and 1 representing certainty P(A|B) = 0 (interpretation: given B is true, A is certainly false) P(A|B) = 1 (interpretation: given B is true, A is certainly true) along with the convention that the plausibility of something which is absolutely certain is 1: P(1|A) = 1 It is worth stressing the symbol P(A|B) represents a state of knowledge of the agent, and to be very careful symbols are not dropped To take the guilty-example, the fact the suspects mom provides an alibi counts against him being guilty However, notice that: P(G|E1E2) < P(G|E1) < P(G|E1E2) (5.4) Why is this',\n",
              " 'We stress the point is not that eq (5.4) is a rule which is always true (it is not), but rather that the reader take great care in following the rules when later manipulating probabilistic statements Technical note 5.1.1: Are probabilities and plausibility really the same A reader might at this point have two concerns: firstly, that by saying probabilities represent plausibility, we are abusing the meaning of probability and giving it a non-scientific meaning Secondly, Why should it be exactly probabilities that quantify plausibility Couldn’t it be some other mathematical theory We offer the following points: \\x88 Isn’t it just true When we speak about probability, it seems like we are making state\\ufffements about how plausible certain statements are given what we know For instance: “It is very probable/plausible Manchester United will not win Champions League 2024” \\x88 What is the alternative',\n",
              " 'But in the case of Manchester United, there is only a single, future event Which two numbers are we supposed to divide [H´ajek, 1997, 2009] \\x88 More importantly, it can be shown that if we make certain assumptions about what plausible reasoning should obey, only probability theory can implement those assump\\ufffetions [Cox, 1946, Jaynes, 2003].5.1 Probability basics 69 5.1.3 Basic rules of probability To summarize the rules of probability: A probability is always written in the form P(A|B) where A and B can be any binary propositions, as long as B ̸= 0 A probability is always a number between 0 and 1, which measures our degree-of-belief in A if we assume B is true Finally, probabilities always obey the following two rules: The sum rule: P(A|C) + P(A|C) = 1 (5.5a) The product rule: P(AB|C) = P(B|AC)P(A|C) (5.5b) Where A, B and C can be any three propositions Note in particular we could select C as the logical constant true, C = 1',\n",
              " 'We therefore have as a special case: P(A) + P(A) = 1, P(AB) = P(B|A)P(A) This is quite remarkable: Reasoning under uncertainty, and most of what we will learn about machine learning in this course, will come down to these two simple rules applied in different ways, and we invite the reader to vigilantly observe if we hold good on this promise 5.1.4 Marginalization and Bayes’ theorem We will begin by deriving Bayes’ theorem as an example of how non-trivial results can be obtained from just the sum and product rule First, with some creative application of the sum and product rule we obtain: P(B|C) = P(B|C)  P(A|BC) + P(A|BC)  = P(AB|C) + P(AB|C) = P(B|AC)P(A|C) + P(B|AC)P(A|C) Next, if we then apply the product rule twice to P(AB|C) we obtain The product rule: P(AB|C) = P(B|AC)P(A|C) The product rule again: P(AB|C) = P(A|BC)P(B|C)',\n",
              " 'Example 1: The taxicab accident So why is Bayes’ theorem so useful Consider the following example due to Kahneman et al [1982]:\\x00\\x0070 5 Discrete probabilities and information Output Fig Example of how our robot in fig 5.1 might reason about the hit-and-run incident First, the available information is transformed into probabilities and then, the query is expressed using the known probabilities and an answer is computed Example 5.1.1: The taxicab accident A cab was involved in a hit and run accident at night Two cab companies, the Green and the Blue, operate in the city You are given the following data: \\x88 85% of the cabs in the city are Green and 15% are Blue \\x88 A witness identified the cab as Blue The court tested the reliability of the witness under the same circumstances that existed on the night of the accident and concluded that the witness correctly identified each one of the two colors 80% of the time and failed 20% of the time',\n",
              " 'To solve the problem, we define the two binary propositions: B : The delinquent was a Blue cab W : The Witness reported the car was blue Since cabs can only be green and blue, B is the event the cab is green We are interested in computing the probability the cab was Blue given the witness said it was blue P(B|W) We first assign these numerical values using the information in the text (see also left-most pane of fig 5.2), then we use the rules of probability to write an expression for the probability we are interested in (here, Bayes theorem, see middle pane of fig 5.2), and finally compute an answer: P(B|W) = P(W|B)P(B) P(W|B)P(B) + P(W|B)P(B) (5.6) = 0.8 × 0.15 0.8 × 0.15 + 0.2 × 0.85 ≈ 41% (5.7) So despite the witness testimony, the hit-and-run cab is more likely to be Green than Blue, i.e',\n",
              " 'Suppose we roll an ordinary die There are then six possible outcomes corresponding to the six events A1 : The side face up A2 : The side face up A3 : The side face up A4 : The side face up A5 : The side face up A6 : The side face up (5.8) Since a die can only show one face up at a time, no two of these propositions can be true at the same time, and they are said to be mutually exclusive This means that for any values of i and j: AiAj = ( Ai if i = j 0 if i ̸= j In general, assuming n events A1,  , An are mutually exclusive, one can show the following gen\\ufffeeralization of the sum rule (see Technical Note 5.1.2): P(A1 + A2 + · · · + An|C) = P(A1|C) + P(A2|C) + · · · + P(An|C) (5.9) As a special case, consider the case the events are also exhaustive, meaning that i.e A1 + · · · + An = 1 This is the case for the die where we know one of the six propositions A1,  , A6 has to be true because one side must be facing up In this case the left-hand side of eq',\n",
              " '(5.10) Furthermore, if A1,  , An are both mutually exclusive and exhaustive then, for any B and C: P(B|C) = P(B|C) · 1 = P(B|C) \"Xn i=1 P(Ai |BC) # = Xn i=1 P(Ai |BC)P(B|C) = Xn i=1 P(BAi |C) = Xn i=1 P(B|AiC)P(Ai |C) (5.11) This general procedure will be used many times in the following and is known as marginalization Our first use of marginalization will be to generalize Bayes theorem to many events: Suppose A1,  , An is a set of mutually exclusive and exhaustive hypothesis and B is some piece of evidence, we then have P(Ai |B) = P(B|Ai)P(Ai) P(B) = P(B|Ai)P(Ai) Pn j=1 P(B|Aj )P(Aj ) .72 5 Discrete probabilities and information Technical note 5.1.2: Derivation of the sum rule for multiple events Suppose A and B are two mutually exclusive events, i.e both cannot happen at the same time Consider the event A or B occurs written as A + B Recall this can be written as: A + B = A B thus, using the sum rule, P(A + B) = P(A B) = 1 − P(A B)',\n",
              " '(5.12) In the case of the die this gives P(A1 +A2) = P(A1)+P(A2)−P(A1A2), however, since the same die cannot show two faces up at once we know P(A1A2) = P(0) = 0 and this simplifies to P(A1 + A2) = P(A1) + P(A2) Repeated applications of this result show that for n mutually exclusive events we get eq (5.9) P(A1 + A2 + · · · + An|C) = P(A1|C) + P(A2|C) + · · · + P(An|C) 5.1.6 Equally likely events We have purposefully introduced probabilities without reference to specific numbers, exactly to make it clear our two rules of probability are true regardless of what the propositions refer to or what their specific values are That being said, we obviously need a way to assign numerical values to probabilities, which is what we will address here There is a tendency, which we warn against, to think familiar counting rules such as P(Positive) = {Number of positive cases} {Number of trials} (5.13) has a fundamental status in probability theory',\n",
              " 'Doing that has the benefit of giving us a clear idea of when it is applicable, and when it is not Let’s begin with a simple case, namely the die from the previous section Now, it no doubt seems intuitively obvious that the chance side or comes up is: P(A4) = P(A3) = 1 6 but why is this true Let us carefully go through the steps involved: \\x88 We don’t have any information about the die, or how it was rolled, which makes it more plausible A4 will occur than A3 or visa versa\\x00\\x005.1 Probability basics 73 \\x88 As no information makes us prefer A4 over A3 (or visa-versa), they are equally plausible As probability measures plausibility, we conclude P(A4) = P(A3) \\x88 Re-doing this argument for all pairs we conclude P(Ai) = P(Aj ) for all i, j \\x88 Since the events are mutually exclusive, we know from eq',\n",
              " 'Let us consider a slightly more elaborate example Suppose we ask the probability the next roll of the die will be a prime If we denote this event by R, we see it can be written as: R = {Next roll is prime} = {Next roll is 2, 3 or 5} = A2 + A3 + A5 Since these events are mutually exclusive, we can use eq (5.9) to get: P(R) = P(A2 + A3 + A5) = P(A2) + P(A3) + P(A5) = 1 6 + 1 6 + 1 6 = 3 6 = 1 2  (5.14) Importantly, in this example we ended up doing exactly the same as eq (5.13), however, the way we arrived at the result was by showing each event was equally probably, and then applying the rule for adding mutually exclusive probabilities As another example, consider once more the cars example from table 2.1',\n",
              " 'But what, exactly, does this probability refer to In light of the previous example, this probability corre\\ufffesponds exactly to the case where we select a cars-instance from the dataset with equal probability, P({Car i}) = 1 N , ask the probability such an instance has four cylinders, written as F1 + F2 + · · · + F142 (where Fi is the proposition car i has four cylinders) and then apply the same computation that lead to eq (5.14) to P(F1 + · · · + F142) This may seem like a rather long discussion to arrive at something intuitively obvious, however, see Example 5.1.2 for a non-trivial combination of simple counting arguments and the the basic rules of probability, or section 5.2.1 for a continuation of the cars-example where we derive counting rules for estimating conditional probabilities',\n",
              " 'This type of generalization can be though of as our first instance of learning, and is one we will return to several times in the coming two chapters, see section 5.4 and section 6.4.74 5 Discrete probabilities and information Example 5.1.2: Two dice⋆ Consider the following problem: Suppose we roll two dice If at least one of the die show five, what is the chance both show five We can easily compute this using the previous ideas Let Ai be the event die 1 shows face i and Bj the event die 2 shows j Using the product rule, and the obvious fact if both dice show five at least one must show five, P({Both } | {At least one }) = P({Both } {At least one )}) P({At least one )}) = P({Both }) P({At least one )}) If we apply the marginalization rule eq',\n",
              " 'A similar argument gives P({Both }) = 1 36 , and therefore P({Both } | {At least one }) = 1 36 11 36 = 1 11  Example 2: The Monty Hall game show⋆ As an illustration of the sum rule consider the following more elaborate problem originally posed by Steve Selvin in 1975 [Selvin et al., 1975]: Example 5.1.3: The Monty Hall game show Suppose you’re on a game show, and you’re given the choice of three doors 1, 2, 3 Behind one door is a car; behind the others, goats You pick a door, say 1, and the host, who knows what’s behind the doors, opens another door, say 3, which has a goat He then says to you, “Do you want to pick door 2?” If you know the host never opens the door with a car is it then to your advantage to switch your choice It is tempting to solve the problem with reasoning along the following lines:5.1 Probability basics 75 Independent of what door we choose, there is a 1 3 chance door 1 contains the car and 1 3 that door 2 contains the car',\n",
              " 'Thus the chance the car is behind door 1 is still 1 2 and there is no advantage in switching This line of reasoning refers to several facts about the problem which are not in dispute (such as the initial probabilities being 1 3 ) Do you think it is true If the argument is true, it should not hurt to examine it with more rigor To do so, let us define the four variables: A1, A2, A3 : The car is behind door 1, 2 and 3 respectively Rg3 : The host reveals a goat behind door 3 Solving the riddle boils down to computing P(A1|Rg3), namely the probability the car is behind door 1 given we initially selected door 1 and the host subsequently revealed the goat was behind door 3, Using our newly derived version of Bayes theorem with mutually exclusive hypothesis we get: P(A1|Rg3) = P(Rg3|A1)P(A1) P(Rg3|A1)P(A1) + P(Rg3|A2)P(A2) + P(Rg3|A3)P(A3) (5.15) Since the car is initially placed randomly we have P(A1) = P(A2) = P(A3)',\n",
              " '\\x88 If the car is behind door 2 and we selected door 1, then P(Rg3|A2) = 1 as the host cannot open our door (containing a goat) or the door with a car \\x88 If the car is behind door 3 and we selected door 1, then P(Rg3|A3) = 0 as the host will never open the door with a car If we plug this information into eq (5.15) we have: P(A1|Rg3) = P(Rg3|A1)P(A1) P(Rg3|A1)P(A1) + P(Rg3|A2)P(A2) + P(Rg3|A3)P(A3) = P(Rg3|A1) P(Rg3|A1) + P(Rg3|A2) + P(Rg3|A3) = 1 2 1 2 + 1 + 0 = 1 3 Since the car is either behind the first or second door, then P(A2|Rg3) = 1 − P(A1|Rg3) = 2 3 and so it is clearly in your best interest to switch doors So what went wrong with the initial argument The argument (subtly) relied on the idea that probabilities referred to the actual state of the world and so should only change when the state of the world changes (the goat and car cannot change places because of what the game host does)',\n",
              " 'This notation is often the cause of unnecessary pain, likely because the name stochastic makes one think about change This is not the case, rather, stochastic variables are simply a notational shortcuts that makes it easier to define binary propositions of the kind we have already encountered More specifically, suppose in some situation we are measuring a quantity X A way to think about that is (for instance) a robot that has a sensor which keep track of the acceleration (on a discrete scale), or in another example, a variable which corresponds to the number of children a family has Specifically, when we write X = x, where x is a number, we define that to be the binary proposition Xx: Xx : {The binary event that the quantity X is equal to the number x} (5.16) In other words, whenever the reader encounters the statement X = x, simply make the above mental substitution and we are back in the usual language of binary propositions Let us make this concrete with a few examples',\n",
              " '(5.15) as: P(A1|Rg3) ≡ P(A = 1|R = 3) = P(R = 3|A = 1)P(A = 1) P3 i=1 P(R = 3|A = i)P(A = i)  As another example, we will consider the silly die Suppose we take an ordinary die and paint each side with the numbers −2, 1, 1, 4, 4 and 10 When we then roll the silly die and read the number on the side facing up, we thereby generate a random number This outcome can be described as a random variable X that takes one of the four different values x1 = −2, x2 = 1, x3 = 4, and x4 = 10 the probability of each outcome being (see also fig 5.3) p(X = x1) = p(X = x4) = 1 6 , p(X = x2) = p(X = x3) = 1 3 (5.17) Note in this example, we chose to enumerate the events as x1,  , x4 rather than having to write their numerical value again and again This type of notation is so convenient we will use it from now one Therefore, suppose X and Y are stochastic variables and they each take values x1, x2,  and y1, y2,  respectively',\n",
              " 'Illustration of the density p(X) of the silly die, note the numbers sum to 1 Summary counts of the cars dataset Origin Four cylinders Six cylinders Eight cylinders France 11 10 9 Germany 17 12 2 USA 28 21 32 Where, once more, by Xxi we simply mean that the variable X, for instance the roll of the silly die, took value xi  To make matters slightly more complicated, it is common to drop the stochastic variable if it is clear from the context, and for instance write eq (5.19) as: p(xi , yj ) = p(xi |yj )p(yj ) summary box 5.2.1 re-states the rules of discrete probabilities we have previously derived in this notation 5.2.1 Example: Bayes theorem and the cars dataset To familiarize ourselves with the new notation, we will now re-visisit the Cars example from sec\\ufffetion 5.1.6 Suppose an inspection of the data in table 2.1 reveal the counts in table 5.1 These should be read as saying there are 2 cars which are both made in Germany and have eight cylinders',\n",
              " 'To solve this, the first thing we should do is define relevant stochastic variables O and C: country of origin: O = 1, 2, 3 (5.20) number of cylinders: C = 4, 6, 8 (5.21) Where O = 1 is USA, 2 is Germany, and 3 is France The query of interest is then P(O = 2|C = 8) Notice that according to the product rule, this can be written as:78 5 Discrete probabilities and information P(O = 2|C = 8) = P(O = 2, C = 8) P(C = 8)  These two probabilities can be computed from the data using the methods in section 5.1.6, eq (5.13); i.e we assume each car observation has a probability of 1 142 and sum those together that matches the query we are interested in Specifically: P(O = 2, C = 8) = 2 142 , P(C = 8) = 9 + 2 + 32 142 , P(O = 2|C = 8) = 2 142 43 142 = 2 43  Let us check this is consistent with Bayes’ theorem To do so, we need to compute the probabilities: P(O = 1) = 11 + 10 + 9 142 = 30 142 , P(O = 2) = 17 + 12 + 2 142 = 31 142 , P(O = 3) = 28 + 21 + 32 142 = 81 142',\n",
              " 'Therefore, we obtain: P(O = 2|C = 8) = P(C = 8|O = 2)P(O = 2) P3 o=1 P(C = 8|O = o)P(O = o) = 2 31 × 31 142 9 30 × 30 142 + 2 31 × 31 142 + 32 81 × 81 142 = 2 43  That these two ways of computing the probability agree match should not come as a surprise: Fundamentally, it derives from our assumption each car-observation has a probability of 1 142 , and then applying the basic rules of probability Since the rules of probability are always true, obviously the result must be consistent Technical note 5.2.1: More comments on notation The keen reader will observe we have changed to a lower-case p This change reflects that from a mathematical perspective, we can simply think of p(yj ) and p(xi , yj ) as the evaluation of the function p(·) and p(·, ·) which compute the probability',\n",
              " ', x˜T ∼ p(·) for t = 1,  , T do Generate u as a random number in the unit interval Select k as the highest value such that Pk−1 i=1 pi ≤ u Set ˜xt = xk end for Summary 5.2.1: Rules of probability, discrete version Consider three stochastic variables X, Y , and Z and suppose xi , yj and zj are three numbers representing values taken by each variable Then p(xi |yj ) ≡ P(X = xi |Y = yj ) ≡ P(Xxi |Yyj ) represents the probability that X takes value xi given that Y takes value yj  In this notation, the sum/product rule is The sum rule: X∞ i=1 p(xi |zj ) = 1 (5.22a) The product rule: p(xi , yj |zk) = p(xi |yj , zk)p(yj |zk) (5.22b) As important special cases, we mention Bayes’ theorem and marginalization: p(yj |xi , zk) = p(xi |yj , zk)p(yj |zk) P∞ j ′=1 p(xi |yj ′ , zk)p(yj ′ |zk) , p(xi |zk) = X∞ j=1 p(xi |yj , zk)p(yj |zk) Note in all these rules, zk may be omitted provided it is done on both sides of the equality sign',\n",
              " 'Suppose a random variable X have N possible outcomes x1,  , xN , and the probability of each outcome is p(X = xi) = pi  We can imagine each pi is a small stick of length pi meters, and if we place the N sticks next to each other they have a combined length of 1 meter If we then pick a random point uniformly within this large stick, it will select stick i with probability pi , and if we do this T times we get our random sample, commonly written using the tilde-symbol: x˜1,  , x˜T ∼ pX(·) Where obviously ˜xt is equal to one of the possible outcomes, x1,  A concrete implementation of the procedure can be found in algorithm 1 and an example using the silly die in fig 5.4.80 5 Discrete probabilities and information Fig Considering each bar in the histogram as a stick, we can generate a random sample ˜xt from the silly die (a roll) using a random uniform number u ∈ [0, 1]',\n",
              " ', xn and f is an arbitrary function The expectation of f is then defined as: Expectation: E[f] = X N i=1 f(xi)p(xi) (5.23) A useful intuition about the expectation is that if we let x˜1,  , x˜T ∼ pX be a random sample generated from p length T (see section 5.2.2), the simple average will approach the expectation when T becomes large enough just as the case of the die: lim T→∞ 1 T X T t=1 ˜f(xt) = E[f] Two expectations are of particular importance namely the mean and variance These can be obtained by setting f(x) = x and f(x) = (x − µ) 2 where µ is the mean of x In particular we write: mean: E[x] = X N i=1 xip(xi), Variance: Var[x] = X N i=1 (xi − E[x])2 p(xi) (5.24) We have briefly illustrated the mean/variance definitions above in Example 5.2.1',\n",
              " 'First, suppose all outcomes are equally probable such that p(xi) = 1 N  In this case: E[x] = 1 N X N i=1 xi , Variance: Var[x] = 1 N X N i=1 (xi − E[x])2  As another example, consider the silly die from eq (5.17) and recall the probability of each outcome was: p(X = −2) = p(X = 10) = 1 6 , p(X = 1) = p(X = 4) = 1 3 Using the definitions we can compute the mean and variance of the silly die as: E[x] = 1 6 (−2) + 1 3 1 + 1 3 4 + 1 6 10 = 3 Var[x] = 1 6 (−2 − 3)2 + 1 3 (1 − 3)2 + 1 3 (4 − 3)2 + 1 6 (10 − 3)2 = 14 5.3 Independence and conditional independence Consider three random variables X, Y and Z and denote their values by xi , yj and zk respectively Independence and conditional independence is then the mathematical relationships: Independent: p(xi , yj ) = p(xi)p(yj ) (5.25a) Conditionally independent given zk : p(xi , yj |zk) = p(xi |zk)p(yj |zk) (5.25b) Which must be true for all i and j',\n",
              " 'If two variables are not (conditionally) independent, they are said to be (conditionally) dependent Conditional independence will later play an important role in structuring our machine-learning models and will usually be based on assumptions about the data-generating mechanism Note that a reader should take great care not to assume that independence implies conditional independence or visa-versa as Example 5.3.1 illustrates.82 5 Discrete probabilities and information Example 5.3.1: Independence Since probabilities has to do with knowledge, conditioning on something can render seem\\ufffeingly independence events dependent and visa-versa',\n",
              " 'Conditional independence does not imply independence: Alternatively, ones math\\ufffeematical skill and height are two highly dependent variables, because young children are usually small and poor at math But if we condition on age, it is reasonable to think they are independent 5.4 The Bernoulli, categorical and binomial distributions As we saw in section 5.1.6, one idea for obtaining probabilities is simply to estimate them from the data matrix X For instance, suppose M = 2 and the two columns correspond to random variables X1, X2 and denote their possible values by x (1) k , x (2) k respectively, the empirical estimate is then P˜(X1 = x (1) 1 , X2 = x (2) 1 ) = n Number of rows i where X1i = x (1) 1 and X2i = x (2) 2 o N',\n",
              " 'Probabilistic models, that is, models that depends on parameters, are a solution to these problems Obviously, how to build these models will be a subject we return to several times in later chapters, however in this chapter we will be concerned with introducing a few building blocks which we will use many times over when constructing more elaborate models 5.4.1 The Bernoulli distribution Consider a setting where we consider a single, binary variable b which can be either false, b = 0, or true, b = 1 The prototypical example of a binary event is a coin flip where b = 0 denote the event the coin landed tails and b = 1 the event the coin landed heads, but the setup applies to all simple5.4 The Bernoulli, categorical and binomial distributions 83 classification problems with two outcomes, for instance we could denote the event a treatment cures a patient such that b = 0 if the patient is not cured and b = 1 if the patient is cured',\n",
              " 'It is worth going over this in some detail The left hand side says that given we know θ, then the probability of b (which has two outcomes) is the expression on the right Notice that: p(b = 0|θ) = θ 0 (1 − θ) 1−0 = 1 − θ p(b = 1|θ) = θ 1 (1 − θ) 1−1 = θ and therefore, we can interpret θ as simply being the probability b = 1 As an example, we can compute the mean and variance of the Bernoulli distribution: E[b] = X 1 b=0 bp(b|θ) = 0 × (1 − θ) + 1 × θ = θ, (5.27a) Var[b] = (0 − θ) 2 × (1 − θ) + (1 − θ) 2 × θ = θ(1 − θ) (5.27b) A notational problem we can anticipate is that when we use p to denote all sorts of probability densities, it can become difficult to figure out exactly which we refer to It is therefore common to introduce special notation for familiar densities We will therefore sometimes write: Bernouilli(b|θ) = p(b|θ) to signify the Bernoulli distribution',\n",
              " 'Suppose there are M possible outcomes, and let y = 1,  , M denote the outcome of the experiment, the categorical distribution is then defined as: Categorical distribution: Catagorical(y|θ) = θ δy,1 1 θ δy,2 2 × · · · × θ δy,K K (5.28) where PK k=1 θk = 1 and θk ≥ 0 We have here used that δy,k = 1 if y = k and zero otherwise This notation is slightly cumbersome, but note once again it simply means that the chance y = k is p(y|θ) = θk To simplify the notation, it is common to 1-out-of-K encode the variable k Specifically, we introduce K new variables, zi = δy,i, such that y = k ⇔ \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8f0 z1  zK \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fb = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8f0 0  0 \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fb84 5 Discrete probabilities and information in which case we can write the categorical distribution as: Categorical distribution: Catagorical(y|θ) = Y K k=1 θ zk k (5.29) 5.4.3 Parameter transformations The parameter θ in the Bernoulli distribution is easy to interpret as the probability of b = 1',\n",
              " 'A way around this problem is to replace θ with a function of another parameter x, θ = h(x) As long as the domain of h is the unit interval, this substitution lead to a well-defined probability density The most common choice is the logistic function θ = σ(x) = 1 1+e−x in which case we can write the density of the Bernoulli distribution as: p(b|x) = (1 − σ(x))1−bσ(x) b (5.30) and now x can be any real number A similar trick can be applied to the categorical function In this case we introduce K new parameters, x1,  , xK and re-define: θk = e xk PK c=1 e xc this operation, when applied to the entire parameter vector, will be written as θ = softmax(x) = h e x1 PK c=1 e xc · · · e xK PK c=1 e xc iT and therefore p(y|x) = p(y|θ = softmax(x)) where the right-hand side is just the ordinary categorical distribution While this is today the most common way to re-parameterize the categorical distribution, the reader should be aware we can alternatively choose to just use K − 1 parameters, x ′ 1 ,',\n",
              " '(5.31) 5.4.4 Repeated events Suppose we flip the coin from before N times or, alternatively, we administer the treatment to N patients and observe the outcome In this case we have N binary (Bernoulli) events b1,  , bN , corresponding to the outcome of each event When the events are based on the same process, it is reasonable to assume each event occurs with a probability θ, but when we know θ the outcome of different coin flips or patients are independent In other words, the outcomes are conditionally independent given θ If we then simply apply the definition of conditional independence (eq (5.25b)) the probability of an entire sequence becomes:5.4 The Bernoulli, categorical and binomial distributions 85 p(b1, · · · , bN |θ) = Y N i=1 p(bi |θ) = Y N i=1 θ bi (1 − θ) 1−bi = θ PN i=1 bi (1 − θ) N− PN i=1 bi = θ m(1 − θ) N−m, m = b1 + b2 + · · · + bN',\n",
              " 'For convenience, we will refer to the sequence of flips using the symbol b =  b1 b2  bN  and write eq (5.32) as p(b|θ) = θ m(1 − θ) N−m 5.4.5 A learning principle: Maximum likelihood Continuing the above example, the probability of the N flips b was: p(b|θ) = θ m(1 − θ) N−m (5.33) When we vary θ, this probability changes The exact way to think about this relationship is that various values of θ makes the occurrence of the data more or less plausible An idea is therefore to select θ as the value that maximizes the probability (plausibility) of the data, and this principle is so often invoked the probability of the data given the parameters is called the likelihood and denoted by the function L: L(θ) = p(b|θ) When we try to implement this idea, we often run into a practical issue, namely that probabilities will often be very small For instance, suppose θ = 0.9 and N = 1000 Then if m = 900, we have p(b|θ) ≈ 6.6 · 10−142',\n",
              " 'In our case the log likelihood is: log L(θ) = log p(b|θ) = m log θ + (N − m) log(1 − θ) Maximizing the probability is the same as maximizing the likelihood, and learning θ by maximizing the likelihood is known as the maximum likelihood principle 5.5 we have illustrated the likelihood function L(θ) = p(b|θ) for different values of θ, N and m We see that as N increases, a smaller range of values of θ makes the data remotely possible The keen eyed reader will also observe the value of θ that maximizes the probability, called the maximum likelihood estimate and referred to as θ ∗ , seems to be m N , i.e the empirical frequency',\n",
              " 'Examples of the likelihood L(θ) = p(b|θ) from eq (5.33) for different numbers of flips N and different number of heads m The top left figure corresponds to heads, the top-right to heads, tails, bottom left to heads, tails, heads and bottom right to N = 100 flips where m = 51 came up heads Notice the dramatic change of scale on the y-axis Summary 5.4.1: Common notation When Bayes’ theorem is used as a learning principle, for instance as in the Monty-Hall example, it is common to give the different expressions names Specifically, suppose x play the role of data, y the role of a hypothesis, and we apply Bayes’ theorem to find the probability of our hypothesis y given data x: p(y|x) = p(x|y)p(y) p(x) It is then common to use the following names for the terms: Posterior = Likelihood × Prior Evidence',\n",
              " 'The binomial distribution p(m|N, θ) for N = 4, 10, 60 and θ = 0.7 5.4.6 The binomial distribution⋆ The binomial distribution will play a minor role in this course, and a reader may choose to skip this section Briefly, suppose once more we have a sequence b1,  , bN of Bernoulli events As we have seen many times, their probability is p(b|θ) = θ m(1 − θ) N−m However, suppose we wish to compute p(m|θ), namely the probability of observing m positive outcomes in a sequence of N Bernoulli events that each occur with probability θ This probability can be computed using the sum rule: p(m|N, θ) = {Sum of the probability of all sequences of length N with m positive outcomes } = \\x1a Number of sequences of length N with m positive outcomes \\x1b × \\x1a Probability of a sequence with m positive outcomes\\x1b = \\x1a Number of sequences of length N with m positive outcomes \\x1b × θ m(1 − θ) N−m (5.34) Computing the quantity in the bracket requires a combinatorial argument, but it can be shown to be equal to \\ufffeN m \\x01 = N',\n",
              " 'We therefore have: Binomial distribution: p(m|N, θ) = \\x12 N m \\x13 θ m(1 − θ) N−m, (5.35) In fig 5.6 we have shown the probability density function of m computed from eq (5.35) when θ = 0.7 and N = 4, 10 and 60 5.5 Information Theory⋆ Shannon’s theory of information attempts to describe the information content in a random vari\\ufffeable [Shannon, 1948] While information theory is an important topic in machine learning, it will play a minor role for the subjects we will discuss, and a reader may choose to simply use Box 5.5.1 as a reference and skip the following justifications With these warnings out of the way, the measures which we will introduce are\\x0088 5 Discrete probabilities and information Information How much information is contained in observing a single outcome xi of a random variable Entropy The complexity of the distribution of a a random variable, measured in bits Mutual information How much information is shared between two random variables, measured in bits',\n",
              " '5.5.1 Measuring information How do we measure information First, we must recognize that information is a word that can take many meanings, and information theory is a theory which explore one, particular, meaning of the word According to information theory, we consider the information contained in repeated, random events For instance, we can imagine a weather-station which each day send home a weather-report consisting of one of the following three events: E1 : The weather is stormy E2 : The weather is windy but not exceedingly so E3 : The weather is fair What we specifically wish to quantify is the amount of information the receivers of the weather\\ufffereport obtains when they learn for instance E3 occurred Since the events are discrete, they happen with some probability, which we will write in the usual way: P(E1) = p1, P(E2) = p2, P(E3) = p3 Let’s suppose there exists such a measure of information which we will write as I(E) : The information obtained by hearing E occurred',\n",
              " 'For instance, if it is stormy nearly every day, learning it is stormy again today does not tell us much, but on the other hand, if we learn something surprising, like the weather was good, that contains a lot of information Accordingly, our measure of information is a function of the probability of E: I(E) = I(P(E)) = I(p), where p = P(E) Let’s consider two important examples: Suppose we know an event will occur (P(E) = 1) The information we obtain by hearing that E occurred is then zero, I(E) = I(1) = 0 Next, consider two events E1 and E2 which are independent, meaning: P(E1E2) = P(E1)P(E2) = p1p2.5.5 Information Theory⋆ 89 However, since the events are independent, the information in knowing both events happened should be the sum of the information of both events taken independently',\n",
              " 'In general, if we consider n events we obtain: I(p n ) = I(p · p n−1 ) = I(p) + I(p n−1 ) = nI(p) (5.36) To proceed we will use a small trick Notice for any integer m ≥ 0 and probability p we can write p = p m m = \\x10 p 1 m \\x11m  (5.36) we get: I(p) = I \\x10\\x10p 1 m \\x11m\\x11 = mI \\x10 p 1 m \\x11 , (5.37) or more conveniently this can be written as I \\x10 p 1 m \\x11 = 1 m I(p) Let’s then consider any rational number r = n m where n, m are integers Combining eq (5.37) and eq (5.36) we obtain: I \\ufffe p n m \\x01 = I \\x10\\x10p 1 m \\x11n\\x11 = nI \\x10 p 1 m \\x11 = n m I(p) (5.38) If we assume the measure of information is continuous, it therefore holds for general positive x that I(p x ) = xI(p) If we differentiate according to x we get: I ′ (p x )p x log p = I(p) Since this is true for any x it follows I ′ (p x ) = A 1 px for an unknown constant A From this we conclude: I ′ (z) = A 1 z which implies I(z) = A log(z) + B where B is a constant However since I(1) = 0 we can conclude B = 0',\n",
              " 'A particular convenient choice is A = − 1 log 2 which ensures information is measured in bits3 We have now derived that the information content of an event that occurs with probability p is: I(p) = − 1 log 2 log p + 0 = − log2 (p) (5.39) where log2 (p) is the base-2 logarithm For instance, suppose you flip a single, unbiased coin The amount of information obtained is then I( 1 2 ) = − log2 1 2 = 1 bit and the amount of information in N such coins is log2 1 2N = n bits 3 Alternatively, if we choose A = −1 the information is said to be measured in nats\\x0090 5 Discrete probabilities and information 5.5.2 Entropy Suppose we consider a source of random events, for instance a die (the random events are which of the six sides face upwards in a roll) or the next character in a newspaper article',\n",
              " 'Such a source is quantified by the average information content it produces which is simply the average of the information H[p1,  , pn] = Xn i=1 piI(pi) = − Xn i=1 pi log pi This quantity is known as the entropy and is a measure of the amount of uncertainty associated with events produced from a given distribution4  Since we don’t want to write the probabilities every time, let’s suppose the probabilities relates to a random quantity k = 1, · · · , K and that we write pk(1), pk(2), · · · , pk(K) for the probability of each event k = 1,  In this case, we will use H[pk] to denote the entropy of the random variable k defined as before: H[pk] = X K k=1 pk(k)I(pk(k)) = − X K k=1 pk(k) log pk(k) (5.40) Example 5.5.1: Example 1: Entropy of a coin flip The entropy of a single (biased) coin c = 0, 1 is given by writing the probability of heads and tails as pc(0), pc(1) = 1 − pc(0) The entropy is then: H [pc] = −p log p − (1 − p) log(1 − p), where p = pc(0)',\n",
              " 'we know the outcome of flipping the coin beforehand) and maximal when p = 1 2  In this case the entropy is H[pc] = log 2 or H[pc] = log2 2 = 1 if we use the base-two logarithm Intuitively, this is saying that a random, binary event where we are completely uncertain about the outcome beforehand contains 1 bit of information This definition easily allows us to consider the entropy of multiple variables Suppose we have a density of two quantities k = 1,  , K and m = 1,  We define their joint density as: pkm(k, m), for k = 1,  , K and m = 1,  , M We stress that pkm is just the regular old probability and the subscript km are only there to make referencing easier later For instance, the marginal density of k, m is as usual given by the sum rule: 4 Two comments: Firstly, we are no longer using the base 2 logarithm but the regular logarithm, however, as we saw in the previous section, this is only a matter of scale, and the natural logarithm is somewhat easier to write',\n",
              " 'In the case of two variables the entropy is simply: H[pkm] = − X K k=1 X M m=1 pkm(k, m) log pkm(k, m) The following two examples illustrates how the entropy can be calculated for distributions of two variables Example 5.5.2: Example 2: Entropy of two variables Since it will be relevant later, let’s consider an example with two variables Suppose M = K = 2 and pkm(1, 1) = 0.4, pkm(1, 2) = 0.2, pkm(2, 1) = 0.1 and pkm(2, 2) = 0.3 the entropy is then: H[pkm] = − X K k=1 X M m=1 pkm(k, m) log pkm(k, m) = −0.4 log 0.4 − 0.2 log 0.2 − 0.1 log 0.1 − 0.3 log 0.3 ≈ 1.28 For K outcomes, the entropy is largest when all events has the same probability, and in general the entropy becomes lower when one particular outcome has high probability This is simply saying that the uncertainty in a random phenomenon is smaller when we know one outcome is very likely to occur',\n",
              " 'A way to view mutual information is as a way to quantify how dependent two variables are; if the two variables are independent, the mutual information is 0, and otherwise greater than zero More specifically, Mutual information tell us how many bits of information we learn about X if we know Y  Specifically, given a probability assignment pkm(k, m) the Mutual information is defined using the entropy as: MI[pkm] = H[pk] + H[pm] − H[pkm]92 5 Discrete probabilities and information A loose justification of this definition is that it computed the sum of information in the two quan\\ufffetities, and then subtract a term which is low if the two variables are highly redundant That is, the mutual information becomes low if the two variables are highly highly redundant, and otherwise it will be high Note the mutual information can be re-written as: MI[pkm] = X K k=1 X M m=1 pkm(k, m) log pkm(k, m) pk(k)pm(m)  To get some more intuition, we will consider two extreme cases',\n",
              " 'In this case: MI[pkm] = X K k=1 X M m=1 pk(k)pm(m) log pk(k)pm(m) pk(k)pm(m) = X K k=1 X M m=1 pk(k)pm(m) log 1 = 0 This makes sense intuitively: If k and m are not informative about each other, the mutual infor\\ufffemation (information shared between them) should be zero On the other hand assume k actually determines m, for instance that the two variables are the same quantity measured twice In this case pkm(k, m) = pk(k) = pm(m) and so: MI[pkm] = X K k=1 X M m=1 pk(k) log pk(k) pk(k)pm(m) = X M m=1 pk(k) log 1 pm(m) = H[pk], (5.41) which also makes sense from an intuitive standpoint: If k tells us what m is (for instance if they are the same), then the mutual information is all the information in k or H[pk(k)] 5.5.4 Normalized mutual information Sometimes, the mutual information is normalized to lie on a scale from 0 to 1 to make it easier to interpret',\n",
              " '(4.7) in chapter 4 NMI[pkm] = MI[pkm] p H[pk] p H[pm]  (5.42) We see now that if k determines m and visa-versa we obtain: NMI[pkm] = MI[pkm] p H[pk] p H[pm] = H[pm] H[pm] = 1 Therefore, an NMI of 0 means the variables are independent, and 1 means they are maximally dependent.5.5 Information Theory⋆ 93 Method 5.5.1: Information theory The information contained in an event which occur with probability p is I(p) = − log(p) Next, consider two random quantities m and n, such that k can take values k = 1,  , K and m can take values m = 1,  We assume we know the joint distribution of n, m, which is the K × M matrix: pkm(k, m), for k = 1,  , K and m = 1,  , M Based on this matrix, we can define the marginal distributions as the K and M-dimensional vectors: pk(k) = X M m=1 pkm(k, m), pm(m) = X K k=1 pkm(k, m) The Entropy in the 1 and 2d-case is then defines as: H[pk] = − X K k=1 pk(k) log pk(k) H[pkm] = − X K k=1 X M m=1 pkm(k, m) log pkm(k, m)',\n",
              " 'In addition, the mutual information and normalized mutual information is defined as: MI[pkm] = H[pk] + H[pm] − H[pkm] NMI[pkm] = MI[pkm] p H[pk] p H[pm]  When we use the natural logarithm (log(x)), The information, entropy, and mutual informa\\ufffetion are all measured in nats If we instead use the base-2 logarithm log2 (x), or alternatively simply divide each quantity by log(2), the quantities are measured in bits.94 5 Discrete probabilities and information Problems 5.1 Question 1: Suppose that you have a deep neural network that can binary classify whether an image con\\ufffetains a penguin or not If an image contains a penguin, the network will correctly classify it as a penguin with probability 97% If an image does not contain a penguin, the network will classify it as a penguin with probability 3% You apply the classifier to a dataset where 1% of the images contain a penguin',\n",
              " 'A ≈ 0.97 B ≈ 0.75 C ≈ 0.50 D ≈ 0.25 E Don’t know.6 Densities and models So far we have considered the probability of binary events such as A, B, Ai and so on When working with machine-learning models, input is usually defined as continuous numbers and so we have to work with the probability of continuous quantities We do so by using probability densities defined on continuous numbers These may appear so different from probabilities they signify a departure from the basic sum-and-product rules applied to binary events, however, we will here stress how densities, and the rules relating to densities, follow from the basic rules and therefore do not signify any new formalisms We will begin by providing an intuitive introduction to this connection, and subsequently dis\\ufffecuss the most commonly used continuous density, the multivariate normal distribution, and the connection between continuous probabilities and learning',\n",
              " '6.1 Probability densities Let us consider a simple example Suppose we denote by r the amount of daily rainfall in Denmark Clearly, r is random since the amount of rain varies for different days However, the problem is that it does not strictly speaking make sense to talk about the probability r takes a specific value After all, suppose we ask: What is the probability there will be r = 2.3mm of rain a given day We could just as well have asked for r = 2.31 or r = 2.299mm, and so a little thought reveals the probability there will be exactly r = 2.3mm of rain must be zero The way we overcome this is to rather ask What is the probability there will be between 2 and 3mm of rain? This is a proper yes/no question that can be formulated by introducing a binary variable A[a,b] : There will be between a and b mm of rain, i.e r ∈ [a, b], and then simply write P(A[2,3]) for the probability r ∈ [a, b]',\n",
              " '6.2 (left) we have tabulated96 6 Densities and models Rainfall in mm / day Probability 0-1mm 1-2mm 2-3mm 3-4mm 4-5mm 5-6mm 6-7mm 7-8mm 8-9mm 9-10mm 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 P(A[5,10]) = 0.075 P(A[2,3]) = 0.145 P(A[0,1]) = 0.393 Rainfall in mm / day Probability density 0 1 2 3 4 5 6 7 8 9 10 0 0.1 0.2 0.3 0.4 0.5 Fig Left: The probability of rainfall per day illustrated as a histogram Each bar denotes the event that on a given day there are between 0 − 1mm of rain, 1 − 2mm of rain, 2 − 3mm of rain etc These well\\ufffedefined binary events can be estimated from historical rainfall Right: If we introduce a function p(r), we can define the probability of the event A[a,b] (that there was between a and b mm of rainfall a given day) as p(A[a,b]) = R b a p(r)dr The three colored regions thus correspond to three events, and each area corresponds to their probability different intervals of amounts of rainfall in Denmark and their respective probabilities',\n",
              " 'After all, suppose someone ask for P(A[2.5,3.5]) We can perhaps make a qualified guess at this variable by eye-balling neighboring bins in the histogram (a reasonable guess would be around 12%), however, we would like a convenient and exact way to represent all such binary variables This is exactly the task a probability density function accomplishes A probability density function is simply a function p that is non-negative and integrates to one Using this function, we can then represent the probability of a particular event such as A[a,b] as the integral P(A[a,b]) = Z b a p(x)dx (6.1) In fig 6.1 (right) is shown the probability of the events A[2,3], A[0,1] and A[5,10[ with their respective probabilities corresponding to the area under the density function 6.1.1 Multiple continuous parameters As we have seen, probability densities are simply functions that are useful as bookkeeping devices to make statements about continuous random variables, such as the amount of rainfall r',\n",
              " 'We stress these new rules are not some new postulate of probability theory, but merely a consequence of the binary sum-and-product rules To do so, consider a very small interval of width dx, A[x,x+dx] (for instance dx = 0.1) Since p will be nearly flat assuming dx is small enough then (see fig 6.2) P(A[x,x+dx]) ≈ p(x)dx In general, suppose we have two variables x, y In direct generalization of the 1d case, the probability that x, y both fall within some 2d subset D of R 2 is then6.1 Probability densities 97 P(A[x,x+dx]) ≈ p(x)dx = 0.303dx Rainfall in mm / day Probability density 0 1 2 3 4 5 6 7 8 9 10 0 0.1 0.2 0.3 0.4 0.5 Fig Continuing further the rainfall example, rather than talking about the probability there will be exactly x mm of rain, we can talk about the probability there will be between x and x+dx mm of rain This can be approximated as p(A[x,x+dx]) ≈ p(x)dx which becomes more and more exact when dx approaches 0',\n",
              " '6.3 where this corresponds to the red area If we shut off our brain and apply the product rule: P(A[x,x+dx]B[y,y+dy]) = P(B[y,y+dy] |A[x,x+dx])P(A[x,x+dx]) (6.3) However using that dx, dy are both small we can again approximate this as P(A[x,x+dx]B[y,y+dy]) ≈ dxdyp(x, y), (6.4) P(B[y,y+dy] |A[x,x+dx]) ≈ dyp(y|x), (6.5) P(A[x,x+dx]) ≈ dxp(x), (6.6) where p(y|x) is a new function of two parameters If we plug these definitions into eq (6.3) and divide both sides by dxdy we obtain the more familiar form: p(x, y) = p(y|x)p(x) We say that p(x, y) is the joint density of x, y and p(y|x) is the density distribution of y given x In general, we can define the sum and product rules for continuous densities:98 6 Densities and models y + dy y x + dx x 0 1 0 1 0 0.5 1 Fig Suppose we have a 2d density p(x, y) For a subset D ⊂ R 2 we can define the probability (x, y) lies in D as p(AD) = R (x,y)∈D p(x, y)dxdy',\n",
              " 'Since the machine-learning models we are interested in use continuous variables we will in the coming sections and chapters mostly use these rules as applied to densities However, it is worth stressing this is not because these rules are more fundamental or a departure from a simpler theory about binary probabilities: rather, they are consequences of the simple sum-and-product rules introduced at the very beginning of this chapter provided we choose to represent probabilities using densities Notice, x, y, z in the above can also be vectors or discrete variables in which case we only have to modify the integral in the sum rule to be either an integral over vectors or a sum over discrete6.2 Expectations, mean and variance 99 variables as we have already encountered For completeness we also provide Bayes’ theorem for continuous variables in summary box 6.1.1',\n",
              " 'Note these are just numbers We assume the joint density is written as p(x, y, z) (in this case, a function of three variables) The sum and product rule is: The sum rule: Z p(x|z)dx = 1 (6.9a) The product rule: p(x, y|z) = p(x|y, z)p(y|z) (6.9b) As important special cases, we mention Bayes’ theorem and marginalization: p(y|x, z) = p(x|y, z)p(y|z) R p(x|y ′ , z)p(y ′ |z)dy′ , p(x|z) = Z p(x|y, z)p(y|z)dy',\n",
              " 'Specifically, for any function f and random quantity x we have: E[f] = Z f(x)p(x)dx (6.10) provided p is the density of x Once more, mean and variance can be obtained by setting f(x) = x and f(x) = (x − µ) 2 where µ is the mean of x In particular we write: mean: E[x] = Z xp(x)dx, variance: Var[x] = Z (x − E[x])2 p(x)dx (6.11) The rules governing expectations are the same in both cases The reader is therefore invited to use either eq (6.11) or eq (5.24) to verify the following useful identities: E[ax + b] = aE[x] + b, Var[ax + b] = a 2 Var[x] where a, b are constants.100 6 Densities and models -2 0 2 4 6 8 10 0 0.5 1 1.5 -2 0 2 4 6 8 10 0 0.5 1 1.5 -2 0 2 4 6 8 10 0 0.5 1 1.5 Fig The density of the normal distribution N (x|µ, σ2 ) for µ = 4 and σ = 0.3, 1 and 2 Note the density can be greater than 1 Multidimensional expectations Because it will be particularly relevant later, we will consider the more general case of a distribution of several variables, say, x, y',\n",
              " 'An important special case is when we consider the sum of several variables In this case: Ex,y[x + y] = Z Z (x + y)p(x, y)dxdy = Z Z xp(x, y)dxdy + Z Z yp(x, y)dxdy = Z xp(x)dx + Z yp(y)dy = Ex[x] + Ey[y] (6.12) More generally, if x1,  , xn are n random variables with joint density p, then for constants a1,  , an we have: E \"Xn i=1 aixi # = Xn i=1 aiE[xi ] (6.13) Furthermore, if x1,  , xn are independent, that is, p(x1,  , xn) = Qn i=1 p(xi): Var \"Xn i=1 aixi # = Xn i=1 a 2 i Var[xi ] (6.14) Both of these identities also hold in the discrete case 6.3 Examples of densities In this section, we will consider two examples of densities: The normal distribution (and it’s general\\ufffeization, the multivariate normal distribution) which provides a convenient density for K-dimensional vectors',\n",
              " 'Example of the probability density function of a 2d multivariate normal distribution In left it is plotted as a function of x = [x y] T , i.e p(x|µ, Σ), whereas on the right the same distribution is shown as a contour plot 6.3.1 The normal and multivariate normal distribution In one dimension, the normal distribution with mean µ and variance σ 2 has the density: N (x|µ, σ2 ) = 1 √ 2πσ2 e − (x−µ) 2 2σ2  The symbol N is simply used for convenience; the normal density is nothing but a function which depends on the three numbers x, µ and σ, and in more familiar notation we would write it as p(x|µ, σ) = N (x|µ, σ2 ) Obviously, it follows from the sum rule eq (6.9a): Z N (x|µ, σ2 ) = 1 The normal distribution has the familiar bell shaped curve seen in fig The parameters get their name because if we computed the mean and variance using eq (6.11): E[x] = µ, and Var[x] = σ 2',\n",
              " 'Example of multivariate Gaussians when the covariance matrix is given as Σ1, Σ2, Σ3 and Σ4 in eq When the covariance matrix is diagonal, the multivariate Gaussians are “cigars” oriented along either of the two axis indicating that x1, x2 are independent (top row), however with off-diagonal elements, the multivariate Gaussian indicate a dependence between x1, x2 Notice the sign determines how they are slanted where Σ is known as the covariance matrix which must be symmetric and positive definite and |Σ| is the determinant of Σ and µ is known as the mean of the multivariate normal distribution1  6.5 is shown the multivariate normal distribution corresponding to Σ = \\x14 1 0.8 0.8 1 \\x15 and µ = \\x14 0 0 \\x15  Notice, the distribution for this choice of µ is centered on (0, 0); this is no accident For a general probability density p we can define the covariance matrix C as: 1 The determinant quantifies the volume of the column-vectors of Σ In 2d it corresponds to the cross\\ufffeproduct, i.e',\n",
              " 'In higher dimensions, the reader should consult a linear-algebra textbook or use a numerical library to compute the determinant, however, see also section 6.3.2.6.3 Examples of densities 103 x1 x2 −2 −1 0 1 2 −2 −1 0 1 2 x1 x2 −2 −1 0 1 2 −2 −1 0 1 2 x1 x2 −2 −1 0 1 2 −2 −1 0 1 2 Fig Example of multivariate Gaussians when the covariance matrix is given as Σ1, Σ2 and Σ3 in eq Increasing the off-diagonal elements increases the covariance Cij = cov(xi , xj ) = Ex [(xi − E[xi ])(xj − E[xj ])] = Z ( xi − E[xi ])(xj − E[xj ])p(x)dx For the special case of the multivariate normal distribution, it holds that µ = E[x] and Σ = C This can allow us to get insight into how the multivariate normal distribution behaves for different choice of covariance matrix Different examples are illustrated in fig 6.6 where in each instance the mean is chosen as µ =  0 0T and Σ1 = \\x14 0.2 0 0 1\\x15 , Σ3 = \\x14 1 0 0 0.2 \\x15 , (6.15a) Σ2 = \\x14 1 0.7 0.7 1 \\x15 , Σ4 = \\x14 1 −0.7 −0.7 1 \\x15',\n",
              " '6.7) correspond\\ufffeing to Σ1 = \\x14 1 0 0 1\\x15 Σ2 = \\x14 1 0.45 0.45 1 \\x15 Σ3 = \\x14 1 0.9 0.9 1 \\x15  (6.16) Notice, the distribution becomes more slanted (skewed) when the off-diagonal elements increase 6.3.2 Diagonal covariance Consider the case where covariance matrix Σ is diagonal Σ = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8f0 σ 2 1 0  0 0 σ 2 2 0  σ2 d \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fb ,\\x00\\x00104 6 Densities and models 0 0.2 0.4 0.6 0.8 1 0.5 1 1.5 2 2.5 3 3.5 0 0.2 0.4 0.6 0.8 1 0 0.5 1 1.5 2 0 0.2 0.4 0.6 0.8 1 0 1 2 3 4 5 Fig Examples of the beta prior density of eq (6.17) for different choices of α, β These two numbers control the mean and variance of the beta distribution, in particular notice the choice α = β = 1 corre\\ufffesponding to the flat prior',\n",
              " 'the xi ’s are independent 6.3.3 The Beta distribution The normal distribution gave us a distribution defined for all real numbers For reasons that will be apparent in a moment, we will be particular interested in quantities θ that are known to lie between 0 and 1 A particularly interesting family of distributions for such a quantity is the so-called Beta distribution This distribution depends on two parameters α, β > 0 and has density2 Beta density: Beta(θ|α, β) = Γ(α + β) Γ(α)Γ(β) θ α−1 (1 − θ) β−1  (6.17) The two parameters α and β are related to the mean and variance as: 2 In the definition, Γ(x) is the Gamma function If x is an integer then Γ(x) = (x − 1) denotes the factorial function, i.e., 4 = 4 · 3 · 2 · 1 = 24, and 0 For further details see https://en.wikipedia org/wiki/Gamma_function6.3 Examples of densities 105 Ep(θ|α,β) [θ] = α α + β , Varp(θ|α,β) [θ] = αβ (α + β) 2(α + β + 1) (6.18) A reader should be warned these integrals are not easy to compute analytically',\n",
              " 'Notice in particular the choice α = β = 1, which exactly corresponds to a prior where no value of θ is preferred This is often called the uniform prior on the unit interval and is sometimes written as U([0, 1]) 6.3.4 The cumulative density function Consider once again our rain-fall example from the beginning of this chapter, and recall that if X denotes the amount of rain-fall and p(x) is the density at X = x, then the chance there will be between a and b millimeters of rainfall is given by the integral indicated in eq (6.1) p(a ≤ x ≤ b) = Z b a p(x)dx = Z b −∞ p(x)dx − Z a −∞ p(x)dx (6.19) where in the last equality sign we have assumed that p(x) = 0 for x < 0 and used basic properties of the integral This inspires the definition of the cumulative density function as: Cummulative Density Function cdf(z) = Z z −∞ p(x)dx (6.20) this allows us to write p(a ≤ x ≤ b) = cdf(b)−cdf(a)',\n",
              " 'Note the cumulative density function, being defined as an integral of a density, will be increasing We can therefore invert the cumulative density function to obtain the inverse cumulative density function cdf−1  It is defined as: cdf−1 (y) = {the value x such that cdf(x) = y}  (6.21) We have illustrated the inverse of the CDF in fig 6.9 (left), but we will also provide a more concrete example Suppose x is a random quantity with range [0, 1] and density p(x) = Beta(x|α = 3, β = 1) = 3x 2 , 0 ≤ x ≤ 1 (6.22) We can now compute the cumulative density function explicitly as: cdf(x) = Z x 0 p(z)dz = 3 Z x 0 z 2 = x 3 (6.23) If we want to invert the cumulative density function, then the value cdf −1 (y) is found by solving cdf(x) = y for x Note that y = cdf(x) = x 3 implies x = y 1 3 and therefore cdf−1 (y) = y 1 3  (6.24) So why is this useful Consider once more a general density p(x), and suppose we want to find an interval [xL, xU ] where x is likely to reside',\n",
              " 'Left: Illustration of the cumulative density function For a given value of θ, then cdf(θ) is the area under the curve up to θ For a given value of the area A, then the inverse of the cumulative density function cdf−1 (A) computes θ such that cdf(θ) = A Right: An interval where θ is likely to reside can be defined using the cumulative density function as [θL, θU ] where θL, θU are defined as in eq (6.26) with α = 0.2 \\x88 The chance x belongs to the interval [xL, xU ] should be high, i.e equal to 1 − α for a small value of α \\x88 We want the interval to be symmetric, in other words the chance x < xL should be equal to the chance x > xU We can translate these statements into statements about the cumulative density function as p(xL ≤ x ≤ xU ) = 1 − α implies 1 − α = cdf(xU ) − cdf(xL) (6.25a) p(x < xL) = p(x > xU ) = α 2 implies α 2 = cdf(xL), 1 − α 2 = cdf(xU ) (6.25b) We have here used that the three above probabilities must sum to 1',\n",
              " 'Then we can find xL and xU from the last line as: θL = cdf−1 \\x10α 2 \\x11 , and θU = cdf−1 \\x10 1 − α 2 \\x11  (6.26) In other words, once we know cdf−1 , we can find a symmetric interval where x resides with a probability 1−α according to p(x) Many confidence intervals are based on intervals of this form, a topic we will return to in chapter 11 An illustration of this type of interval can be found in fig 6.9 (right) where we have used α = 0.2 In other words, according to the density, there is a 1 − α = 0.8 chance θ is found in the middle (red) area 6.3.5 The central limit theorem⋆ The central limit theorem is a key theorem in statistics and provides both an explanation for why the normal distribution is so common, but also a justification for why variance is reduced when6.3 Examples of densities 107 0 0.5 1 1.5 0 0.5 1 1.5 2 0.2 0.4 0.6 0.8 1 1.2 0 0.5 1 1.5 2 2.5 3 0.5 0.6 0.7 0.8 0.9 0 2 4 6 8 Fig',\n",
              " 'The inserted red curve is the normal approximation computing averages; as so many quantities in machine learning and statistics are averages, this makes the central limit theorem a key theoretical concept It is easier to introduce the central limit theorem by way of example Once more, suppose we flip N weighted coins and count the number of heads m As we saw in the previous chapter, the distribution of m is the Binomial distribution eq (5.35) p(m|θ, N) = \\x12 N m \\x13 θ m(1 − θ) N−m and in fig 5.6 we have shown the probability density function of m when θ = 0.7 and N = 4, 10 and 60 If we look at these plots from arms length, they sort of look like the normal distributions approximately centered at Nθ In fact, this may give us an idea Suppose we define the (random) quantity ν ≡ m N = X N i=1 bi N Since we are re-scaling by 1 N , we should expect it to have mean θ We can in fact compute both the mean and variance analytically using first eq (6.13) and eq (6.14), and next eq',\n",
              " 'First, that we are right ν has mean θ, but also that the variance is inversely proportional to 1 N  We should therefore expect the normal density N \\ufffe ν|µ = θ, σ2 = θ(1 − θ)N −1 \\x01 = 1 q 2π θ(1−θ) N e − (ν−θ) 2 2 θ(1−θ) N = s N 2πθ(1 − θ) e − N(ν−θ) 2 2θ(1−θ) to at least provide an approximate match to the true density of ν We have plotted both these densities in fig 6.10 for N = 4, 10, 60 While it should not be surprising the mean and varianc\\x00108 6 Densities and models -5 0 5 10 0 0.05 0.1 0.15 0 2 4 6 0 0.1 0.2 0.3 0.4 1.5 2 2.5 3 3.5 4 4.5 0 0.2 0.4 0.6 0.8 1 Fig The average of N rolls of the silly die for N = 2, 10, 60 and inserted normal approximations Notice average of the rolls converge rapidly to the normal distribution match (we just showed this to be the case in eq (6.27)), it should be surprising that the exact shape of the curves seem to match perfectly as N increases We might suspect this has something to do with the Bernoulli distribution, but this is not the case',\n",
              " 'For instance if N = 2 the chance of getting ν = 10 (two 10’s) is p(ν = 10|N = 2) = p(ν = 10|N = 1)p(ν = 10|N = 1) = 1 6 2 , however it is easy to simulate many realizations of the distribution, compute ν, and plot the estimated p(ν|N) for different N The result is shown in fig 6.11 for N = 2, 10, 60 as the gray histogram While the distribution is difficult to derive, a computation similar to eq (6.27), along with the mean/variance computed in Example 5.2.1, show that E[ν] = {Mean of a single die} = 3, Var[ν] = {Variance of a single die} N = 14 N Both the true (simulated) density ν and the normal approximation N (ν|µ = E[ν], σ2 = Var[ν]) is plotted in fig As we can clearly see in the figure, the normal approximation is very nearly identical to the true distribution This is the content of the central limit theorem: Consider N random variables X1,  , XN , each taking values x1,',\n",
              " '(6.30) It is this normal distribution, and in particular that the variance shrinks towards zero as N increases, that guarantees averages converge in statistics to well-defined values If the central limit theorem did not hold there would be no reason to increase the number of patients in a clinical trial to get a better idea about the average effect or increase the number of test examples in machine learning to better judge the performance of a method, and it implies the normal distribution can be expected to pop up in all kinds of circumstances because most quantities are (in one way or another) representative of average effects 6.4 Bayesian probabilities and machine learning In this section, we will consider a very basic learning problem which nevertheless encapsulates how probabilities are applied in general in machine learning',\n",
              " '\\x88 Formulate the machine-learning task (prediction, classification, etc.) in terms of a probability which can be derived using the sum and product rule We will illustrate this with a very simple inference problem Suppose your friend shows you a coin he bought at a flea market The salesman informed him that it might be a magic coin (a magic coin is a coin where one side comes up more often than 50%), but he wasn’t sure and in either case he doesn’t know which side is supposed to come up more often A simple learning problem could be to flip the coin a number of times and use the information to figure out the chance it will come up heads in a new flip As usual, let bi = 0 be the event the coin comes up tails in flip i and bi = 1 heads We once more represent the sequence heads, tails, heads as b1 = 1, b2 = 0, b3 = 1, which we will write as a vector b',\n",
              " 'In section 5.4.5 we saw one idea, namely to maximize the likelihood function L(θ) = p(b|θ) and thereby obtain θ ∗ = m N  A moments thought will reveal this answer is quite plainly wrong For instance, if we observe just N = 3 flips of a coin, nobody in their right mind would rule out the possibility the coin was fair (i.e θ = 1 2 ), but the only possible values of θ ∗ we could compute would be θ ∗ are 0, 1 3 , 2 3 and 1 Obviously something has gone wrong The problem is maximum likelihood is a principle, in the sense of a sometimes-good-idea, and not something we have derived from first principles The correct way to proceed is the only way to proceed, namely to ask our rational robot from fig 5.1 which only operates according to the rules110 6 Densities and models of probability What we wish to learn is θ based on a sequence of coin flips b',\n",
              " 'Inspecting the above, we see that in order to proceed, we must specify p(θ) Since we know just one distribution for a quantify defined on the unit interval, the beta distribution, we will assume θ is beta distributed with (so far) unknown parameters α, β > 0 Technical note 6.4.1: Deriving the posterior density of the coin Returning to our coin, to compute the posterior p(θ|b), we need to compute the numerator and denominator of eq Beginning with the numerator, using the likelihood eq (6.31) and the Beta prior eq (6.37) we obtain p(b|θ)p(θ) = p(b|θ)p(θ|α, β) (6.33) = θ m(1 − θ) N−m × Γ(α + β) Γ(α)Γ(β) θ α−1 (1 − θ) β−1 = Γ(α + β) Γ(α)Γ(β) θ m+α−1 (1 − θ) N−m+β−1 (6.34) The denominator is obtained by integrating this expression with respect to θ; the integral is somewhat complicated analytically, but nevertheless based on well-known rules',\n",
              " '(6.35) and eq (6.34) into eq (6.32) we obtain: p(θ|b, α, β) = Γ(α+β) Γ(α)Γ(β) θ α+m−1 (1 − θ) β+N−m−1 Γ(α+β) Γ(α)Γ(β) Γ(α+m)Γ(β+N−m) Γ(α+β+N) = Γ(α + β + N) Γ(α + m)Γ(β + N − m) θ α+m−1 (1 − θ) β+N−m−1  (6.36) All that remains is to note eq (6.36) has the same form as the Beta density eq (6.37), but with new parameters a = α + m, b = β + N − m.6.5 Bayesian learning in general 111 p(θ) ≡ p(θ|α, β) = Γ(α + β) Γ(α)Γ(β) θ α−1 (1 − θ) β−1 (6.37) We now have expressions for all terms on the right-hand side of eq (6.32); simply plugging these in and computing the integral we see: p(θ|b) = Beta(θ|a, b), a = α + m, b = β + N − m = p(θ|b, α, β) (6.38) In the last line, we include α and β to signify the posterior depends on these two numbers (see Box section 6.4 for details on the derivation) In other words, when we use a Beta(·|α, β) prior for θ, the posterior density remains a Beta distribution This important property is known as conjugacy and is one of the motivations for using a Beta prior',\n",
              " 'In other words, we can interpret α and β in the prior as a number of pseudo-counts where the specific case of the flat prior α = β = 1 corresponds to observing two coin flips, one positive and one negative 6.4.1 Choosing the prior Continuing the example of the flat prior (α = β = 1), if we plug these values into either eq (6.36) or eq (6.38) we obtain p(θ|b, α = β = 1) = (N + 1) θ m(1 − θ) N−m (6.39) In fig 6.12 this figure is plotted for different sequences of flips, starting with just one flip that came up heads N = 1, m = 1 and ending with N = 100 flips where m = 51 came up heads Several important aspects can be read off from this example We observe that the distribution of θ is peaked at around the expected value, i.e However when the number of observations increase we become more and more certain that θ is near to this value',\n",
              " 'This answer may not feel as satisfying as a single number (“θ is really 0.5”), or the familiar confidence interval from classical statistics (“with a confidence level of 95% θ is in the interval 0.5±θ0”), however, the Bayesian answer is more general and later in chapter 10 we will see there exist a simple recipe for constructing the Bayesian equivalent of the confidence interval, the credibility interval 6.5 Bayesian learning in general Let us turn to the general problem of learning parameters w from a dataset D = (X, y) consisting of N observations in the usual format First, the density we are interested in is112 6 Densities and models 0 0.2 0.4 0.6 0.8 1 0 0.5 1 1.5 2 0 0.2 0.4 0.6 0.8 1 0 0.5 1 1.5 0 0.2 0.4 0.6 0.8 1 0 0.5 1 1.5 2 2.5 0 0.2 0.4 0.6 0.8 1 0 2 4 6 8 10 Fig Examples of the posterior probability p(θ|b) from eq (6.39) for different numbers of flips N and different number of heads m',\n",
              " 'p(w|D) = p(w|y, X) (6.40) We will make the following two assumptions: p(y|X, w) = Y N i=1 p(yi |xi , w) (6.41a) p(w|X) = p(w) (6.41b) What the first assumption tells us is that when we know the parameters w and xi , the other observations are irrelevant in terms of predicting yi  The second assumption encode the idea X alone does not tell us anything about w At this point, the reader no doubt expect what will happen: Applying Bayes’ theorem to eq (6.40), and the then the two assumptions eq (6.41a) and eq (6.41b), we get: p(w|X, y) = p(y|X, w)p(w|X) p(y|X) = QN i=1 p(yi |xi , w)p(w) p(y|X) (6.42)6.5 Bayesian learning in general 113 There are two general ways to proceed from here In the coin-example, we proceeded by simply computing the numerator and simplifying the expression In that case, w was equal to θ, there was no X, p(yi |xi , w) ≡ p(bi |θ) and p(w) = Beta(θ|α, β) was a Beta distribution',\n",
              " 'Maximizing eq (6.42) is equivalent to maximizing the logarithm, which can be written as: Maximize: log L(w) + log p(w), where L(w) = X N i=1 log p(yi |xi , w) (6.43) Sometimes, the prior term log p(w) (which does not depend on the data) will be ignored, and sometimes not It will often be more convenient to formulate the maximization problem as instead the corre\\ufffesponding minimization problem of the cost-function obtained by multiplying eq (6.43) with −1 Furthermore, to easier compare the cost-function for models trained on different-size dataset, the cost function is re-scaled by 1 N so that it measures a cost-per-observation In that case the mini\\ufffemization problem becomes: Minimize: E(w) = − 1 N X N i=1 log p(yi |xi , w) (6.44) Sometimes, we will add a regularization term to the right-hand side of this expression (see chap\\ufffeter 14) This discussion has been somewhat abstract, but inspecting eq',\n",
              " '(6.44) to learn w We will see examples for how this can be implemented in chapter 8, chapter 14, and chapter 15 We summarize this discussion in summary box 6.5.1.114 6 Densities and models Summary 6.5.1: Maximum likelihood framework Many machine-learning methods can be motivated within the following, general, framework Given data X, y, we select, based on expert knowledge, the likelihood density function: p(yi |w, xi) (6.45) Here, w are the parameters in the model We then learn the weights w by letting them be equal to the value w∗ found by either: Maximize: w∗ = arg max w \" log p(w) +X N i=1 log p(yi |xi , w) # (6.46) Minimize: w∗ = arg min w E(w) (6.47) where: E(w) = − 1 N X N i=1 log p(yi |xi , w) + {Optional regularization term}  If we ignore either the prior or regularizations term (or they have the same analytically form), these two formulations are equivalent, and can be derived using Bayes’ rule and the maximum likelihood principle, see eq',\n",
              " 'Question 1: A factory produces cars We consider three properties of the cars produced by the factory and each property can only take two values: \\x88 The color which can be either red or blue \\x88 The weight which can be either heavy or light \\x88 The model which can be either 2-doors or 4-doors There are thus 23 = 8 possible car types such as (red, heavy,2-doors) or (blue,light,4-doors) Suppose you are given the following information about cars produced from the factory: \\x88 The probability a car has four doors is 0.5 \\x88 The probability a car is heavy given it has four doors is 0.8 \\x88 The probability a car is heavy given it has two doors is 0.2 \\x88 The probability a car is heavy and red is 0.1 Given the above information, what is the probability a car is blue given it is heavy A 0.2 B 0.5 C 0.8 D 0.9 E Don’t know Question 2: Based on Haberman’s Survival Data found in Table 6.1 it is found: \\x88 56 pct of the subjects had positive axillary nodes detected',\n",
              " 'of the subjects that did not have positive ax\\ufffeillary nodes survived What is the probability that a subject that has survived would have positive axillary nodes according to the study by Haberman Attribute description Abbrev x1 Young (< 60 years), x1 = 0 or Age Old (≥ 60 years), x1 = 1 x2 Operated before, x2 = 0 or OpT after 1960, x2 = 1 x3 Positive axillary nodes detected PAN No, x3 = 0 or Yes, x3 = 1 y Lived after 5 years Surv No, y = 0 or Yes, y = 1 Table 6.1 A modified version of Haberman’s Survival Data taken from http://archive.ics.uci.edu/ml/machine-learning\\ufffedatabases/haberman/haberman.names The attributes x1-x3 denoting the age, operation time and cancer size as well as the output denoting survival after five years are binary The data contains a total of N = 306 observations A 20.2 % B 36.0 % C 56.0% D 76.6% E Don’t know Question 3: In Figure 6.13 is given the denstity function p(x) of a random variable x What is the ex\\ufffepected value of x, i.e',\n",
              " 'Outside the region from 0 to 0.9 the density function is zero A 0.450 B 0.532 C 0.600 D 1.000 E Don’t know.7 Data Visualization “The drawing shows me at one glance what might be spread over ten pages in a book.” wrote Ivan S Turgenev in 18621 , thereby repeating the literary trope a picture is worth a thousand words It is worth reflecting on why this is so widely thought to be the case One idea is that, simply put, more of the brain is adapted to the direct processing of visual information than any other type of sensory information This in turn means we can distinguish between two senses a picture is worth a thousand words: the first is it allows us to quickly comprehend and therefore learn new information visually than from any other source and, the second, that it allows us to find and learn new patterns in data; it is notable we often refer to this as seeing a new pattern',\n",
              " 'The remaining sections will re-visit the machine\\ufffelearning workflow of fig 1.13, with a focus on the second use of using visualizations to see — namely as a window into what machine-learning does We will also use this as an oppertunity to discuss the machine-learning workflow in slighly more details to provide a backdrop for the remaining sections of this book 7.1 Basic plotting Visualization can be thought of as compressing a large quantity of information into a few visual elements This section will review some ways this can be accomplished roughly ordered according to how much compression is desired Visualization of a single attribute Consider each of the four attributes of the Fisher Iris dataset and suppose we wish to visualize a single attribute The histogram allows us to represent multiple observations in a limited space while preserving nearly all the information A histogram is constructed in two steps',\n",
              " 'Histograms based on N = 16 bins of the four features in the Iris dataset most often of equal length We then count how many observations in the dataset fall within each such bin and draw a rectangle where the base of the rectangle is the interval and the height is the number of observations that fall into the interval That is, the sum of the height of all rectangles will be the number of observations This procedure is also known as binning 7.1 is shown the histograms of all four attributes of the Iris dataset We see some of the histograms look roughly symmetric and bell-shaped (this indicates the attribute is likely normally distributed) whereas for instance the sepal width has two humps (it is multimodal) The advantage of the histogram is that it tells us nearly all there is to know about a variable, the disadvantage is that they take up quite a lot of space and that we have to select the number of bins manually and too many or too few will create uninformative histograms',\n",
              " 'Boxplots of the four attributes of the Fisher Iris data is shown in fig Here, the middle red line corresponds to the median (the p = 0.5 percentile), the upper and lower bounds, l75 and l25, of the blue box is the p = 0.75 and 0.25 percentile, the black lines are known as the whiskers and attempt to outline how wide the distribution is The upper/lower whiskers are defined as: upper whisker: min(l75 + 3 2 (l75 − l25), vN ), (7.1) lower whisker: max(l25 − 3 2 (l75 − l25), v1), (7.2)7.1 Basic plotting 119 petal width petal length sepal width sepal length 0 1 2 3 4 5 6 7 8 petal width petal length sepal width sepal length 0 2 4 6 8 Fig A boxplot (left pane) is a way to condense the information in a histogram into a stereotypical representation An advantage of the boxplot is it allows us to read off relevant quantities of the dataset, such as the medium value, however, compared to the histograms in fig 7.1 we also loose information such as the bimodality of the sepal width',\n",
              " 'The right-most pane provides an example of how the same information can be communicated with a simpler visual element, namely by simply plotting each observation as a point and adding a bit of x, y jitter to make the points distinct where vN denotes the value of the largest observation, and v1 the value of the smallest observation Observations that fall outside these bounds are marked as red crosses and they are said to be outliers insofar as the boxplot is concerned A similar effect to the boxplot and histogram can be obtained with a bit of simple data-processing 7.2 (right) we have simply plotted each value of the attributes plus a bit of random noise applied to the x and y coordinate This allows us to distinguish each individual point and convey similar information as that found in the boxplot and the histogram Visualization of one-dimensional data Suppose we have to visualize a single 1d dataset, for instance, the sale of widgets produces by a company over 12 months',\n",
              " '7.3 where we have illustrated the line plot, a “dot” plot and a bar chart Notice the bar chart start at 0 and so should primarily be considered for variables which are ratio, i.e 0 has some specific meaning The use of lines often help to “ground” the eye and provide guidance when there is correspondence between observations whereas the dot and bar chart are easy to read and compare different values Also notice the bar chart and the other plots tend to guide the reader to different aspects of the data The first two plots would be useful for pointing out the variability of the data, whereas the bar chart would be useful for pointing out the variability in absolute terms Having in mind what we want to communicate should always inform us about what graphical elements we choose and how we decide to select or scale for instance the y-axis',\n",
              " 'We120 7 Data Visualization Month Widgets sold 1 2 3 4 5 6 7 8 9 10 11 12 9500 10000 10500 11000 11500 Month Widgets sold 1 2 3 4 5 6 7 8 9 10 11 12 9500 10000 10500 11000 11500 Month Widgets sold 1 2 3 4 5 6 7 8 9 10 11 12 0 5000 10000 15000 Month Widgets sold 1 2 3 4 5 6 7 8 9 10 11 12 9500 10000 10500 11000 11500 Fig Different attempts to visualize a simple 1D dataset corresponding to widget sale over months Top row is the line plot and the dot-plot Bottom left is the bar plot (notice the y-axis start at 0) and an attempt to combine the line and dot plot to better guide the readers eye have also increased the line width slightly In all four charts, we use grid lines to guide the reader’s eye making it easier to compare the first months to the last Several one-dimensional series Suppose we tests four different models on eight datasets and for each model we obtain a performance rating We believe our method (Method 1) is the better How do we best communicate this',\n",
              " 'However, suppose we want to include a visualization of this data in for instance a presentation or in the main pages of the report and wish to include the table as an appendix 7.4 are four attempts to visualize this dataset Notice the three methods we have seen so far are all fairly difficult to read The lines cross many times for the line plots, the dot plots too seem difficult to compare and the bar chart has an almost psychedelic effect One strategy to fix this is to sort the datasets in descending order In this way, connecting the datasets with lines makes the (relative) performance easier to read It is now fairly apparent the yellow method seems to have some benefits, especially for the medium-difficult problems whereas the blue method seems to perform worse We have also sorted the methods such that the first (best!) method is first in the legend and in addition (try to zoom in) we make sure to plot the graphs such that the first method are on top of the others',\n",
              " 'This is an example where arranging the data is important for easier communication In addition to what we have already done, one could try to select a color or line scheme for the other method7.1 Basic plotting 121 Dataset Accuracy 1 2 3 4 5 6 7 8 0.5 0.6 0.7 0.8 0.9 1 Dataset Accuracy 1 2 3 4 5 6 7 8 0.5 0.6 0.7 0.8 0.9 1 Dataset Accuracy 1 2 3 4 5 6 7 8 0 0.2 0.4 0.6 0.8 1 Method 1 Method 2 Method 3 Method 4 Dataset Accuracy 1 2 3 4 5 6 7 8 0.5 0.6 0.7 0.8 0.9 1 Fig Illustration of four 1D datasets corresponding to the performance of four machine-learning meth\\ufffeods on eight datasets In the bottom right pane we have tried to sort the datasets and use lines to connect related datasets Which are easier to read that made them stand out less For instance by marking them all in graytone, which would further emphasize that we were comparing our method against three others',\n",
              " '7.5 we have plotted two coordinates of the the Fisher Iris data against each other and used colors to denote the classes A 2D plot quickly provides an overview of how spread out the data is and in this case, it immediately tells us that determining if a flower is setosa (as opposed to the two other types) is a trivial problem whereas the other two classes, insofar as these two features are concerned, are more difficult to discern When making 2D scatter plots, be aware of the scaling of the axes; if the units of the axes are the same (length) then it may be sensible to ensure they have the same scale A difficulty in the 2D scatter plot is that we only see two dimensions at the same time This can (to some extend) be overcome by plotting all dimensions against each other in pairs constituting what is known as a matrix plot, see fig',\n",
              " 'What we perhaps learn from this plot is that sepal width and sepal length may be two features useful for distinguishing versicolor and virginica, which may leave us even more optimistic in terms of the classification problem However, one cannot conclude that because no two features in and by themselves can be used to separate two classes then the problem122 7 Data Visualization 5 6 7 petal width 0 1 2 sepal length 2 3 4 petal length 2 4 6 sepal width 1 2 sepal length 2 4 6 sepal width 3 4 petal length 5 6 7 8 petal width setosa versicolor virginica Fig A matrix plot in which the four attributes are plotted pairwise against each other and colors are used to indicate class labels is impossible to solve: Firstly, this tells us nothing about how three features can perform, and secondly it only tells us about certain (axis-oriented) projections onto a 2D plane Higher-dimensional observations To go beyond 2d requires either changing the visual element or accept some distortion',\n",
              " 'The problem with 3D plots is that they have to be projected onto a 2D screen or paper which ruins most of the benefits of the 3D plot Another type of technique for high-dimensional data is to represent each multi-dimensional observation by a more complex visual element than a point One such example is the coordinate plot illustrated in fig 7.7 (right) where an observation7.2 What sets apart a good plot 123 1 8 2 3 4 6 5 6 8 4 7 6 5 2 petal width petal length sepal width sepal length 0 2 4 6 8 setosa versicolor virginica Fig Higher-dimensional objects are difficult to visualize meaningfully To the left is shown a 3D scatter plot where three attributes are plotted against each other 3D plots are best when one can interactively move the camera around since their 2D projection onto paper necessarily ruins much of the information that can be extracted',\n",
              " 'is represented by a line passing through the 4 points with coordinates (coordinate × value) As a rule, one should consider using selection or projection of the data set before including plots of high-dimensional observations 7.2 What sets apart a good plot Having introduced the basic plots, a natural question to ask is when to use which plot type Beyond the basic requirement our visualizations should provide a truthful summary of the data there is no single optimal answer to this question, however, there are useful guidelines2  A useful analogy is to consider technical writing Suppose we are writing a section in a report What are the relevant questions to keep in mind Arguably, the first, and most important, question is what the point of the section actually is: What particular question are we hoping to answer If we are unsure about what point we are trying to convey, the text will only confuse the reader, and we should be better of discarding the section entirely',\n",
              " 'An abstract definition first and then illustrations Draw on other parts of the text Perhaps begin by explaining the reader why he or she should care 2 The guidelines illustrated here are adopted from http://junkcharts.typepad.com/junk_charts/124 7 Data Visualization The question What do we want the reader to learn Align this point with text, conclusion A single question/point per figure The data What data is sufficient to answer the question Exclude everything else Select transformations, scaling, etc The visual element As simple as possible Let it be stand-alone (labels, titles, captions) Use colors, markers, etc insofar they add value Fig A visualizations is first and foremost about providing a truthful summary of the data, but the clarity of a visualization can be greatly increased by carefully considering the following three points: (i) what question are we trying to answer',\n",
              " 'is more suitable setosa versicolor virginica petal width petal length 4 5 6 7 8 2 2.5 3 3.5 4 4.5 5 Fig Scatter plot of two attributes of the Fisher Iris data Colors are used to visualize the three classes After we have narrowed in on which ques\\ufffetion we want to answer, and how (in the broad picture) this will be accomplished, we get to the low-level issue of putting our thoughts into well-structured and readable English sentences While this is arguably the least important as\\ufffepect of writing3 , it is certainly important to en\\ufffesure the text is enjoyable or, as a bare mini\\ufffemum, readable For visualizations we can imagine a similar thought-process illustrated in fig 7.8 The question: The most important aspect of a visualization is what question the graph\\ufffeical element will pose and answer A fig\\ufffeure should attempt to convey one (or a very few) interesting facts to the reader and nothing more',\n",
              " 'The data: Next we should determine what data is useful to answer the question and possi\\ufffebly what transformations should be applied to the data to (say) reduce noise, change scale, etc The rule is to go with the bare minimum of data transformations 3 Or so we hope7.3 Visualizing the machine-learning workflow⋆ 125 The visuals: Lastly, what visual element (i.e the type of plot) should be used to represent the data and answer the question Prefer\\ufffeence should be given to simplicity Consider how to make important visual feature stand out, use correct labels to guide the reader, etc There are many answers as to how these steps4  However, the main point is that some thought is given to the process of making visualizations For instance, no person would hand in a report written in a font that was unreadable However, it is common to see plots where axis or labels are quite literally impossible to read due to pixelization and poor font size choices',\n",
              " 'As a final recommendation, consider in the future to occasionally ask yourself if a particular graphical element in a book or slide show works well (or not!) and ask yourself why and if any of the ideas are worth copying 7.3 Visualizing the machine-learning workflow⋆ In this section, we will focus our attention on how visualizations can help us at the various stages of the machine-learning workflow we first encountered in fig Our hope is to convince the reader that visualizations are useful when working with a practical machine-learning problem as encountered later during the course and, therefore, building visualizations for our own benefit should become a natural part of our machine-learning toolkit and workflow As this is more of a general suggestion than a single, practical method we have chosen to make the point early and at once rather than scattering it throughout the text',\n",
              " 'We emphasize a first-time reader is not supposed to understand the methods fully at this point, and a reader should focus their reading on the general point we try to convey rather than the specifics Notice that this section (including subsections) is marked by a ⋆ indicating it is not necessary to understand the main text 7.3.1 Visualizations to understand loss To meaningfully distinguish between any two methods you need a well-defined goal Therefore, begin by figuring out a quantifiable way to express one model is preferable to another Sometimes this is trivial, but sometimes it is much harder: Suppose you are designing a method to automatically re-stock a supermarket Is the goal to ensure on average there are always n packs of ground beef on the shelves, that on average no more than m packages of ground beef are discarded as waste, or that no more than p percent of the customers are unable to buy the product they came for',\n",
              " '[1990], see also https://www edwardtufte.com/tufte/) or the ACCENT principles [Burn, 1993]126 7 Data Visualization 4 5 6 7 8 9 10 11 6 8 10 12 14 4 5 6 7 8 9 10 11 6 8 10 12 14 10 20 30 40 0 0.05 0.1 0.15 0.2 Fig Example of how the performance metric has a qualitative impact on the choice of model For the 2D dataset shown in the left-most pane, we consider a simple model (a line) but using two performance metrics: One is the standard L2 error typically used in regression, the other is the L1 error defined as the sum-of-distances between the points and the line The middle figure illustrates the best linear models using these two methods and the circles the relative contribution of each point to the total error (the histogram in the right-hand pane are the same values sorted in ascending order) The optimal model change qualitatively between a slightly positive/negative trend because the L2 error is much more affected by outliers A more concrete example is given in fig',\n",
              " 'typical error The figure shows a simple prediction problem where the interpolating line is selected so as to minimize the sum-of-distances between the line and the observations, however, we try different measures of distance as defined by the Lp norm (see eq (4.17) in chapter 4) The figure illustrates the standard L2 error (square loss) and the L1 error (the sum-of-distances to prediction) and how this results in qualitatively different predictions A temptation is to take a wait-and-see attitude where several losses are computed, however this encourage working in an ad-hoc manner where one is unable to reliably track progress Alternatively, it may seem impossible to find such a number, in which case one should wonder if the problem is too poorly specified Having a single, well-defined loss does not mean you cannot change your loss if it turns out to be poorly selected, or you should not compute alternative metrics as you go along',\n",
              " '7.3.2 Use visualizations to understand mistakes A simple but versatile idea is to visualize the outcome of the machine learning method Suppose we are trying to distinguish between cars and cities A thing that can always be done is to plot a meaningful number of members of these two classes to get an idea about what the images look like Even more useful, once a method is set up plot the images that are wrongly classified This is illustrated5 in fig 7.10 where we have plotted 6 members of each class here assumed to be wrongly classified: we can immediately notice some interesting facts, such as the “cars” class contains images of the interior of cars, things that does not look like cars at all (lower, right), wrongly labeled images (lower, left or upper, right) and a motorbike',\n",
              " 'A simple way to visualize the result of a method is to picture wrongly classified observations For instance suppose the above 12 images show (wrongly) classified instances of the cars and city class; this would tell us there are issues with the labelling (the motorcycle and truck), as well as hint as a possible methodological problem of assigning a single label to an image One should perhaps also wonder if the method has a problem with very dark images; notice this could be further illuminated with other visualizations accurate (ii) perhaps it is more useful to measure performance by looking at the top-5 predicted labels as the labels are somewhat ambiguous 7.3.3 Visualization to debug methods Suppose your method does not work as well as you expect Two recommended approaches is to attempt to use a simpler version of the method, for instance by reducing the number of neurons or layers in a neural network, or applying the method on a simplified version of the data set',\n",
              " 'Once more, we stress visualizations are the single most useful way to understand what might go wrong Simply put, extracting information about what the method does internally should be the go-to technique, and doing so in a visual format is often the easiest and most re-useable way An example is shown in fig 7.11; we assume an artificial neural network (see chapter 15) is applied to a dataset and performs poorly Neural networks often consist of thousands (or millions) of weights which are hard to visualize, but in the figure we try to plot the output of each layer as a histogram We see that for the first layer, the histogram show a variety of activation of the neurons indicating they maintain some information about the input In the third and 10th layer things look a bit askew: Neurons are now either fully on or off (-3 and 3) and we should wonder why Is this natural could it be this is arbitrary where does the number 3 come from',\n",
              " 'More experience with neural networks will tell us a histogram such as layer 3 can be expected if the layer weights are initialized to have a too high value, and layer 10 if they have a too low initial value, how the true benefit of such a visualization is it allows us to learn such experience: it can readily be re-used when the network is applied to a simpler dataset where it is perhaps known to work well, and then we can see, even if highly approximately, what a good network is supposed to look like if all layers look more or less as the layer 1 histogram, this should inform us something is going wrong, and we can begin to prod and poke the network to see what that is Simply put,128 7 Data Visualization -1 0 1 2 0 50 100 150 200 -3 -2 -1 0 1 2 3 0 200 400 600 800 -3 -2 -1 0 1 2 3 0 200 400 600 800 Fig Even models with millions of parameters can be meaningfully visualized with some creativity and with the right visual element',\n",
              " 'In the first layer, we see a broad distribution of activity indicating the neurons are probably exhibiting varying degrees of activity for the input as we would hope The center and right-most pane show behaviour that should make us slightly suspicious: in the center pane, neurons are either fully on or off (obviously, we should ask ourselves if the number 3 is what we expect), and in the right-most pane nearly all neurons have no activity Notice these histograms are not supposed to be a gold-standard for visualizing networks, but an illustration of what can be done with simple means when things go wrong, attempt to figure out the problem by writing code to see what goes wrong rather than sit in the armchair and figure out what might be wrong 7.3.4 Use visualization for an overview Visualizations can often provide an immediate overview of what to expect in terms of performance',\n",
              " 'A well\\ufffechosen baseline should be quick to compute, simple and foolproof; think of it as what you would do if you had 10 minutes to solve the problem Examples could be: Classification Classify everything as belonging to the class with the most elements Regression Output the mean of the sample (i.e make a constant prediction) Density estimation Return a uniform density, i.e all outcomes are equally likely Outlier detection Mark everything (or nothing) as outliers These examples are very naive and refers to the situation where we simply ignore X in our learning problem and only focus on y When working with more elaborate methods, for instance an artificial neural network (see chapter 15), it is common to use a simple linear model (see chapter 8) as baseline Regardless of ones choice, the point of the baseline is twofold: First, to be able to recognize when a method is not learning anything or very little',\n",
              " 'Scatterplot of M = 11 attributes considered pairwise and colored according to class labels The inserted yellow line indicate the decicion boundary of a simple classification method, logistic regression, and the corresponding errors are shown as inserts The target, or ceiling, performance The baseline provides a lower bound of performance and the target (or ceiling) performance refers to an upper bound Such an upper bound may arise for different reasons depending on the situation: For instance, it may refer to how well a human performs at the task, or how well we have to perform the task for our machine-learning method to be useful, or the performance of a comparable method from the literature',\n",
              " 'Continuing the example of fig 7.12, the figure indicates the pairwise plots of a dataset projected onto K = 4 PCA components Note the first two components easily seperates the classes and give rise to a very low error, whereas the other attributes appears to be fairly uninformative A plot such as this may reveal important information about how relatively easy/difficult the classification problem is scoring), or predict the exact number of goals in a highly random game like soccer, or if 10% of the observations in a dataset are mislabeled we should not expect to be more than 90% accurate6  The point of the baseline and ceiling performance is to get an intuitive feeling for what our, specific, performance means as well as how easy the problem is',\n",
              " 'On the other hand, suppose the dataset contains 100 classes, each with the same number of elements, then the naive baseline level is about 1% and a performance of 15% mean the method is doing something (we will return to the point of class imbalance in chapter 16) Example: To make this concrete we will consider a 12-feature classification problem7 where the goal is the predict the wine type based on 12 different features 7.12 we have made a scatter plot of each pair of feature and colored the two classes If we inspect the plots we can see several things: (i) some of the features (for instance feature 8 and 3) pairwise allow good separation (ii) others (such as feature 11 and 4) does not (the two point clouds 6 A technical point: If the observations are mislabeled in a predictable manner, for instance all wolves are mislabeled as dogs, we can learn to accurately predict the wrong label if that is all we have access to What we refer to here is the true class',\n",
              " '[2009] and obtained from http://archive.ics.uci edu/ml/datasets/Wine+Quality (note dataset has been processed to remove outliers).7.3 Visualizing the machine-learning workflow⋆ 131 20 40 60 80 100 0 0.05 0.1 0.15 0.2 0.25 0.3 2 4 6 8 10 12 0 0.05 0.1 0.15 0.2 0.25 0.3 0 500 1000 1500 0 0.05 0.1 0.15 0.2 0.25 Fig Illustration of the relative difficulty of the classification task in fig Left: Dotted lines indicate baseline model as well as a model trained on all features The blue and red curves indicates the classification error of each of the 55 plots in fig 7.12; as shown these ranges from worse than random guessing to nearly as good as using all the data A similar plot for the PCA-projected version of the same dataset is shown in fig The last figure illustrates how the method improves (in terms of test error) as more data is used to train a linear model using all the features are on top of each other)',\n",
              " 'On the other hand, suppose we only had access to the pair of features shown in the bottom-right corner of fig In this case, we can see the two classes are so intermixed, and nothing suggests they can be separated with any sort of rule, that we should at the very least conclude the problem is very difficult and throwing one advanced method at the problem after another is unlikely to do us any sgood Obviously, for high dimensional data, eye-balling becomes infeasible and dimensionality reduc\\ufffetion methods may be of use 7.13 we have illustrated the data projected onto the first 4 principal components and again we clearly see the first two principal components would easily solve the problem to a high accuracy 7.3.5 Illustration of baseline and ceiling performance The simplest baseline is obtained by classifying everything as belonging to the largest class',\n",
              " '7.13 suggests we can do a lot better For illustrative purpose we have visualized a simple, linear classifier (specifically, logistic regression, which we will introduce in chapter 8) where everything on one side of the line is classified as belonging to one class and everything on the other The error of the classifier is shown for each pair of coordinates and we see the best pair of PCA components obtain an error of just 2% on the training set The error of all linear classifiers using pairs of features are shown in fig 7.14 (left and middle figures) These plot show the baseline error 25% as well as the error obtained by training a model on all features (about 2.5%) Visually inspecting the randomness in the data in fig 7.12 an error of 2.5% is probably quite close to the best we can hope to do on this dataset',\n",
              " 'While it is important to quantify model performance using a single number, visualizing learning curves can often reveal important facts about our method including how much we should trust these numbers as providing an absolute truth The examples indicate seperate runs of two method, and the performance of the methods would normally be computed after learning (at T = 200, 300, 1000 respectively) and compared using a standard test Such a test would reveal method 1 perform better than 2 in the first two panes (p = 0.012 and p = 0.048) (T = 200, 300), however inspecting the learning curve reveal such a conclusion would be highly spurious due to the non-normal behaviour of method 2 (the jumps) as well as the error is obviously not stationary In T = 1000 we in fact see that method 2 seems to perform better than methdo 1 (p = 0.0071) from abysmal (worse than the trivial baseline) to nearly as good as when using all features For the PCA projections (middle) this is even more pronounced',\n",
              " '7.3.6 Visualizing learning curves We previously argued it is important to quantify the performance of a given method as a single number, however it is worth emphasizing that a single number can often hide important information about the method which visualizations can make apparent Example 1: Continuing our wine-example from the previous section, in fig 7.14 (right pane) we have shown how the error (on a training and test set) of a linear classifier depend on the number of training observations What we see is an important, general, feature of a well-functioning machine-learning method: When using very few training observations, the method can fit the training data perfectly, but does not learn to generalize to the test set (because there is insufficient data to learn the true underlying statistical features of the problem; we say the method overfits)',\n",
              " 'We will return to how such learning curves are interpreted in section 10.4 Example 2: A plot may provide insights which are not apparent from a statistical test, both because it is often intuitively easier to judge a plot than a p-value, but also more importantly, that the distribution of the error of our method may (and often, will) violate assumptions of the statistical test in more7.3 Visualizing the machine-learning workflow⋆ 133 or less pronounced ways, thereby significantly weakening (or completely invalidating) the utility of the statistical test An example of this is shown in fig This curve illustrates the performance (here: accuracy, higher is better) of two methods as a function of training time (it is assumed we are using a model that benefits from more training time; a large neural network is an example of such a method)',\n",
              " 'This kind of behaviour is in fact quite common for methods which operate on a discrete internal representation or in a discrete environment At any rate, if we look at these curves we should quickly draw the conclusions that \\x88 The error of method 2 is not normally distributed meaning our statistical test is only suggestive \\x88 The need to evaluate method 2 longer and be aware performance of the two methods may shift depending on initial conditions \\x88 there are good reasons to think tweaking of method 2, such as initial conditions or other learning parameters, can dramatically improve it’s relative performance.134 7 Data Visualization Problems 7.1 Question 1: We will only use the attributes x1– x10 as well as the output y in our modeling of the data The attributes x1–x10 are standardized (i.e., the mean has been subtracted each attribute and the attributes divided by their standard deviations) In Figure 7.16 a boxplot of the standardized data is given',\n",
              " 'Boxplots of the 10 attributes x1–x10 where the data has been standardized A The value of the 50th and 75th percentiles of the attribute DB coincides B Even though the distribution of AlA and AsA may have a similar shape this does not imply that the two attributes are correlated C The attribute TB is likely to be normal distributed D The attribute GDR has a clear outlier that should be removed E Don’t know Question 2: A 1-dimensional dataset is composed of N = 60 observations; exactly 40 of these observations take the value 1, 10 take the value 2 and the remaining 10 observations take the value 3 Which of the four boxplots in fig 7.17 is a boxplot of the dataset A B C D 1 1.5 2 2.5 3 3.5 Fig Boxplots A Boxplot A B Boxplot B C Boxplot C D Boxplot D E Don’t know Question 3: We will consider a dataset on wholesale taken from http://archive.ics.uci.edu/ ml/datasets/Wholesale+customers The data set in\\ufffecludes 440 customers',\n",
              " 'The data provides the costumers’ annual expenditures in monetary units of fresh prod\\ufffeucts (FRESH), milk products (MILK), grocery prod\\ufffeucts (GROCERY), frozen products (FROZEN), deter\\ufffegents and paper products (PAPER), and delicatessen products (DELI) The attributes of the data and their abbreviations are also given in Table 7.1 In Figure 7.18 is given a boxplot of the six input at\\ufffetributes of the data Which one of the following state\\ufffements is correct Attribute description Abbrev x1 Fresh products FRESH x2 Milk products MILK x3 Grocery products GROCERY x4 Frozen products FROZEN x5 Detergents and paper products PAPER x6 Delicatessen products DELI y Region REGION Table 7.1 The six input attributes x1–x6 denoting the an\\ufffenual consumption in monetary units of customers as well as the output y denoting which of the three regions; Lisbon, Oporto, and one additional region denoted Other, the cus\\ufffetomers came from in the wholesale customer data.7.3 Visualizing the machine-learning workflow⋆ 135 Fig',\n",
              " 'A The boxplot contains prominent outliers that must be removed B All the attributes appear to be normal distributed C If we do not standardize the data (i.e., for each at\\ufffetribute subtract the mean and divide by the standard deviation) a PCA would give equal importance to all the attributes D The mean and median values are not likely to be very close to each other for any of the attributes E Don’t know.Part II Supervised learning8 Introduction to classification and regression We will now turn our attention to supervised learning In supervised learning we are given a training set comprised of N observations, x1,  , xN and N targets y1,  , yN and we wish to come up with a way to predict y from x: y = f(x, w) + ε, (8.1) where w is a vector of tunable parameters and ε represents a noise term Learning then consists of selecting the parameters w based on the training data X, y',\n",
              " 'On the other hand if y is discrete, i.e , C as in the MNIST example we encountered in chapter 1, we will say M is a classification model In this chapter, we will discuss the linear and logistic regression models for regression and classification, starting by first explaining what f(x, w) looks like and then show how probabilities can be used to treat the noise term ε The history of linear regression can be traced back to mathematicians Adrien-Marie Legendre and Carl Friedrich Gauss who independently in 1805 and 1809 applied linear regression models to astronomical observations of the orbit of planets [Legendre, 1805, Gauß, 1809] Meanwhile logistic regression, which we will consider in a later section, has it’s origin with the discovery of the logistic function by Pierre Fran¸cois Verhulst and Adolphe Qu´eteletin in 1838 [Garnier and Qu´etelet, 1838] where it was originally applied to growth curves of populations',\n",
              " 'Recall in a linear model, the output y in eq (8.1) is modelled as a linear combination of the input features: f(x, w) = w0 + w1x1 + · · · + wMxM, and x = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8f0 x1 x2  xM \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fb  (8.2) The reason this is known as a linear model is that it is a linear function of the input features x To140 8 Introduction to classification and regression y = f(x, w) x y −1 −0.5 0 0.5 1 1.5 2 −2 −1 0 1 2 3 x1 x2 f(x, w) 0 0.5 1 0 0.5 1 0 0.5 1 1.5 Fig The linear regression models prediction is a linear combination of the features f(x, w) = w0 + w1x1+· · ·+wMxM This allows for lines (left pane), y = w0+w1x, planes (right pane) y = w0+w1x1+w2x2 and in general hyperplanes consider a very simple example, consider the linear model with w0 = 1, w1 = −1 shown in fig 8.1 as the blue line y = f(x, w) = 1 − x This naturally also extends to multiple input features In the right-hand pane of fig 8.1 is shown the two-dimensional regression example with w0 = 0, w1 = 1, w2 = 1 2',\n",
              " 'More generally, we can consider a feature transformation of x such that y = f(x, w) = w0 + M X−1 j=1 wjϕj (x) where ϕ1(x),  , ϕM−1(x) are M − 1 basis functions If we define ϕ(x) = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8f0 1 ϕ1(x)  ϕM−1(x) \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fb (that is, the first basis function is just a constant) we can write the linear regression model more compactly as simply y = f(x, w) = ϕ(x) T w and w = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8f0 w0 w1  wM−1 \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fb  (8.3)8.1 Linear models 141 y = f(x, w) x y −1 −0.5 0 0.5 1 −1 −0.5 0 0.5 1 1.5 y = f(x, w) x y −10 −5 0 5 10 −2 0 2 4 Fig Applying a non-linear transformation to the input x allows much more complicated curves to be fitted by the linear regression model In the left-hand pane is shown a polynomial y = w0+w1x+w2x 2+w3x 3 and in the right-hand pane a sinusoidal model y = w0 + w1 cos(x) + w2 sin(4x) The use of non-linear basis functions allow the linear regression model to model non-linear features',\n",
              " '(8.4) The second example corresponds to two trigonometric functions suitable for a periodic signal ϕ(x) =  1 cos(x) sin(4x) T and w =  1 −2 1T  (8.5) Since the transformation by a basis function does not change the linearity in w the discussion in this chapter will be independent on the choice of basis functions In practical terms, applying a basis functions to a dataset X to obtain the transformed dataset X˜ is equivalent to applying feature transformations such as the ones we encountered in chapter 2 x˜i = ϕ(xi), and X˜ = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8f0 ϕ(x1) T ϕ(x2) T  ϕ(xN ) T \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fb and we can write the prediction of observation i as yi = x˜ T i w 8.1.1 Training the linear regression model To learn the parameters of the linear regression model, we will follow the general procedure outlined in section 6.5, in particular eq The first step of which is to come up with an expression for p(y|x, w) (see eq To this end, note the linear regression model eq',\n",
              " 'An actual observation will be noisy which we will capture with a noise parameter ε:\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00142 8 Introduction to classification and regression y = f(x, w) + ε = x˜ ⊤w + ε Since we don’t know what ε is, we have to model it with our only tool for handling unknown quantities: probabilities Therefore, assume that for each observation ε follows a normal distribution with mean 0 and variance σ 2  Using this assumption, the the probability density of y is then a normal distribution centered around x˜ ⊤w: p(y|x, w, σ) = N (y − x˜ ⊤w|µ = 0, σ2 ) = 1 √ 2πσ e − (y−x˜⊤w) 2 2σ2 (8.6) Our objective (see eq (6.40)) is to find w as the value which is most plausible given the data, i.e as maximizing p(w|X, y) Using Bayes’ theorem this can be written as p(w|X, y) = p(y|X, w)p(w) p(y|X)  (8.7) As we saw earlier (see eq',\n",
              " '(8.9) We will now assume the prior of w is flat, p(w) = 1, which is also known as the uniform or improper prior1 , and furthermore we will choose to formulate the problem as a minimization problem by dropping constant terms and re-scaling the above expression The problem of finding w∗ is therefore equivalent to minimizing the sum-of-squares error function (compare to eq (6.47)): w∗ = arg max w p(w|X, y) = arg min w E(w) where E(w) = 1 N X N i=1 \\x10 yi − x˜ ⊤ i w \\x112  (8.10) As we know from analysis, this can be accomplished by setting the derivative of E equal to zero and solving for w If we differentiate eq (8.10) with respect to a weight wj we obtain: ∂ ∂wj E(w) = 2 N X N i=1 (yi − x˜ T i w)X˜ ij = 2 N X N i=1 yiX˜ ij − 2 N \"X N i=1 Xijx˜ T i # w (8.11) The gradient is therefore 1 Notice the choice p(w) = 1 strictly speaking does not make sense since the density is no longer normalized: R p(w)dw = ∞',\n",
              " 'Examples of two datasets for which we will apply linear regression In the left-hand pane is a 1-d dataset comprised of x, in the right-hand side a 2d dataset comprised of red dots lying on a curved plane ∇E(w) = \\uf8ee \\uf8ef \\uf8ef \\uf8f0 ∂E(w) ∂w1  ∂E(w) ∂wM \\uf8f9 \\uf8fa \\uf8fa \\uf8fb = 2 N X˜ T y − 2 N (X˜ T X˜)w (8.12) Setting the gradient equal to zero and solving we obtain w∗ = (X˜ T X˜) −1X˜ T y = (X˜ T X˜)\\\\X˜ T y (8.13) Thus, training the linear regression model can be accomplished using one line of code in many com\\ufffeputing environments Since the linear regression model is so basic and important we will illustrate it in two scenarios in the following Example 1: Linear regression applied to a 1d dataset Consider the 1d dataset shown in the left-pane of fig Suppose we wish to fit two models to the dataset, one corresponding to plain linear regression and the other to feature transforming the data to correspond to a second-degree polynomial',\n",
              " '1 xN \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fb (8.14) then we compute w(1) = (X˜ T (1)X˜(1))\\\\X˜ T (1)y and and the red curve for an arbitrary point x can be predicted as y = f(x, w(1)) =  1 x  w(1) In the right-hand pane of fig 8.4 we illustrate the second-degree polynomial linear regression corresponding to the feature transformation:\\x00\\x00144 8 Introduction to classification and regression x f(x, w) 0 0.2 0.4 0.6 0.8 1 0.2 0.3 0.4 0.5 x f(x, w) 0 0.2 0.4 0.6 0.8 1 0.2 0.3 0.4 0.5 Fig Examples of applying the linear regression model to the dataset shown in the left-hand pane of fig The two panes respectively show a basic linear regression model y = X˜(1)w(1) without feature transformations, and linear regression model with feature transformation by adding the feature x 2 to pro\\ufffeduce a second-polynomial curve, y = X˜(2)w(2) See text for details X˜(2) = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8f0 1 x1 x 2 1 1 x2 x 2 2',\n",
              " 'Example 2: Linear regression applied to a 2d dataset In the second example, we will consider the 2d dataset shown in the right-hand pane of fig We will again consider two models, one corresponding to plain linear regression and the other to feature transforming the data to correspond to a second order Taylor expansion In the left-hand pane of fig 8.5 we illustrate the second-degree polynomial linear regression corresponding to the (trivial) feature transformation: X˜(1) = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8f0 1 X11 X12 1 X21 X22  1 XN1 XN2 \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fb , (8.16) then we compute w(1) = (X˜ T (1)X˜(1))\\\\X˜ T (1)y (notice w is three-dimensional) and for an arbitrary point x we can predict y = f(x, w(1)) =  1 x1 x2  w(1) This is used to generate the plane shown in the left-hand pane of fig In the second example, we will attempt to fit a second-order expansion to the same dataset This is accomplished by the feature transformation:\\x00\\x00\\x00\\x008.2 Logistic Regression 145 0 0.5 1 0 0.5 1 −0.4 −0.2 0 0 0.5 1 0 0.5 1 −0.4 −0.2 0 Fig',\n",
              " 'The left-hand pane shows the basic linear regression model y = X˜(1)w, and in the right-hand pane we make a feature transformation to include second order terms corresponding to y = X˜(2)w See text for details X˜(2) = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8f0 1 X11 X12 X2 11 X2 12 X11X12 1 X21 X22 X2 21 X2 22 X21X22  1 XN1 XN2 X2 N1 X2 N2 XN1XN2 \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fb (8.17) Again, learning w (which is now six-dimensional!) can be accomplished as w(2) = (X˜ T (2)X˜(2))\\\\X˜ T (2)y and predictions, as shown in the right-hand pane of fig 8.5, for a new point x =  x1 x2 T can be made as y = f(x, w(2)) =  1 x1 x2 x 2 1 x 2 2 x1x2  w(2) In the later case the found value of w(2) is w(2) =  −0.5 0.5 0.5 −0.25 −0.25 −0.125T , which is exactly (at this precision at least) equal to the value of w used to generate the data 8.2 Logistic Regression The goal of classification and regression may seem very different, however, it turns out linear regression can easily be extended to classification by the use of probabilities',\n",
              " 'We will now proceed exactly as we did in the case of linear regression by first finding an expression for p(y|x, w) (8.18) and apply the maximum likelihood framework from section 6.5 Since y is binary, our immediate idea should be to model it’s density eq (8.18) as a Bernoulli variable However, as the output of a linear model is a general continuous number, and the parameter\\x00\\x00\\x00\\x00\\x00\\x00146 8 Introduction to classification and regression z σ(z) −10 −5 0 5 10 0 0.2 0.4 0.6 0.8 1 Fig The logistic sigmoid σ(z) = (1 + e −z ) −1  Notice as z → −∞ then σ(z) → 0 and when z → ∞ then σ(z) → 1 θ of the Bernoulli distribution belongs to the unit interval [0, 1], we re-parameterize the Bernoulli distribution using the sigmoid function Recall that according to eq (5.30) from section 5.4.3 the Bernoulli density could be written as: p(b|z) = Bernouilli(b|θ = σ(z)) = σ(z) b (1 − σ(z))1−b , σ(z) = 1 1 + e−z  (8.19) Where the function σ(z) is the logistic sigmoid and is shown in fig',\n",
              " 'Specifically, define: yˆi = σ(x˜ ⊤ i w) The probability density of a given observation yi is then: p(yi |xi , w) = Bernouilli(yi |yˆi) = ˆy yi i (1 − yˆi) 1−yi  (8.20) If we then proceed exactly as in the case of the linear regression model, by using eq (8.20) and eq (6.47), we see we should select the parameters w∗ as the solution of the optimization problem: w∗ = arg min w E(w) where: E(w) = − 1 N log \"Y N i=1 p(yi |xi , w) # = − 1 N X N i=1 [yi log ˆyi + (1 − yi) log(1 − yˆi)] , yˆi = σ h x˜ ⊤ i w i , (8.21) However, at this point our discussion has to departs from linear regression: there is no closed\\ufffeform analytical solution for the minimum of the error function How we find w∗ in practice will be discussed later in the chapter for neural networks where we will consider a general method for minimizing error functions, however, until then simply rely on the commands build into your computing environment for solving logistic regression problems',\n",
              " 'A one-dimensional logistic regression example The left-hand pane shows the intermediate (linear) output Xw and the right-hand pane the true logistic-regression decision boundary ˆy = σ(Xw) applied to it asides being pre-fixed with 1s as is required for any regression problem 8.7 is shown a basic logistic regression example for a simple 1-dimensional dataset The procedure is exactly similar to linear regression We first define: X˜(1) = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8f0 1 x1 1 x2  1 xN \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fb (8.22) Then, the left-hand pane shown the intermediate linear regression value z = X˜(1)w as the black line, and the right-hand pane the predicted probabilities ˆy = σ(X˜(1)w) are plotted as a black line As expected for such a simple problem the logistic regression learns how to separate the two classes For completeness, fig 8.8 illustrates a 2d example, where the two classes are fitted with a logistic regression model and the decision surface ˆy is shown',\n",
              " 'Notice the decision boundary is linear and quite steep Logistic regression will have linear decision boundaries unless we apply (non-linear) feature transformations to our dataset 8.2.1 The confusion matrix While the error function E(w) could be used to evaluate a logistic regression model it is important to keep in mind that the error function measures the probability of the data, however, at the end of the day, we are probably more interested in how often the logistic regression model classifies correctly and how often it classifies wrongly To this end, we must turn the output of the logistic regression (which is a probability) into a class label',\n",
              " '2d logistic regression example The dataset shown in the left-hand pane is fitted with a logistic regression model and the class-membership prediction ˆy is shown in the right-hand pane There are now four different combinations of what class an observation actually belongs to and what it is predicted to belong to by the model They are called: True Positives, TP: Number of observations which are in fact positive yi = 1 which the classifier correctly labels as positive ˆyi > 1 2 False Positives, FP: Number of observations which are in fact negative yi = 0 which the classi\\ufffefier incorrectly labels as positive ˆyi > 1 2 False Negatives, FN: Number of observations which are in fact positive yi = 1 which the clas\\ufffesifier incorrectly labels as negative ˆyi < 1 2 True Negatives, TN: Number of observations which are in fact negative yi = 0 which the classifier correctly labels as negative ˆyi < 1 2 These are illustrated in fig',\n",
              " 'In the right-hand pane the true positives, false negatives, etc are collected in what is known as the confusion matrix, where the inserted ticks on colored background indicate which observations counts towards which numbers As mentioned we will return to the meaning of these numbers in more detail in chapter 10, however, for now we will simply focus on how often the classifier is right which is known as the accuracy (or equivalently how often the classifier is wrong which is known as the error rate): Accuracy = TP + TN N , Error rate = FP + FN N = 1 − Accuracy For instance the accuracy of the logistic regression model in fig 8.9 is 5+2 N = 7 10  8.3 The general linear model⋆ The overall form of the cost-function in the linear and logistic regression models can be generalized into what is known as the general linear model Since this is the form of these models which is mostly commonly encountered in a computing environment, we will briefly discuss it here',\n",
              " '(Left:) A small N = 10 observation binary classification problem The colors indicate the predic\\ufffetion made by a logistic regression classifier obtained by thresholding ˆyi at 1 2  (Right:) The confusion matrix of the classifier in the left-hand pane The inserts (ticks on background) indicate which observations counts towards which numbers in the confusion matrix it decompose the model into two parts: a link function g and a cost function d It then assumes the output of the model is: y = f(x, w) = g(x˜ ⊤w) and that the cost function can be written as: E(w) = 1 N X N i=1 d(yi , g(x˜ ⊤ i w)) (8.23) Parameters are found in the usual way by minimizing E(w) For a summary, see Box 8.3.1.150 8 Introduction to classification and regression Method 8.3.1: The general linear model Given a dataset consisting of N pairs (xi , yi), we first define x˜i as a feature-transformation of xi , in the simplest form obtained by pre-fixing xi with a constant intercept term: x˜i =  1 x ⊤ i ⊤',\n",
              " 'The linear regression model can be recovered by defining g(x˜ ⊤w) = x˜ ⊤w and d(y, yˆ) = (y − yˆ) 2 and the logistic regression model as: g(x˜ ⊤w) = σ(x˜ ⊤w) and d(y, yˆ) = −y log ˆy − (1 − y) log(1 − yˆ).\\x00\\x008.3 The general linear model⋆ 151 Problems 8.1 Question 1: We fit a linear regression model to the PM10 data shown in Table 8.1 The input attributes are standardized (i.e., we have subtracted the mean of each input attribute, x1–x7, and divided by their stan\\ufffedard deviations) whereas the output logPM10 is kept in its original format We obtain the following model: f(x) = 3.27 + 0.36x1 − 0.01x2 − 0.19x3 + 0.01x4 + 0.05x7 Which one of the following statements about the model is incorrect Attribute description Abbrev',\n",
              " '2001 y Logarithm of PM10 logPM10 concentration Table 8.1 The attributes of the PM10 data The output is given by the hourly values of the logarithm of the concentra\\ufffetion of PM10 particles (logPM10) A According to the model WINDDIR and HOUR are not relevant for predicting the pollution level B According to the model fewer cars and more wind will result in lower pollution levels C According to the model it seems that pollution is decreasing over time D According to the model higher temperatures will re\\ufffesult in lower pollution levels E Don’t know Question 2: We consider the Wholesale dataset shown in Table 8.2 and wish to predict whether a con\\ufffesumer is from Lisbon (y=0) or Oporto (y=1) by discard\\ufffeing observations from the Other region included in the wholesale data After discarding the observations per\\ufffetaining to the Other region we standardize the attributes x1–x6 (i.e., for each attribute subtract the mean and divide by the standard deviation) and fit a logistic re\\ufffegression model',\n",
              " 'Which one of the following statements about the model is cor\\uffferect Attribute description Abbrev x1 Fresh products FRESH x2 Milk products MILK x3 Grocery products GROCERY x4 Frozen products FROZEN x5 Detergents and paper products PAPER x6 Delicatessen products DELI y Region REGION Table 8.2 The six input attributes x1–x6 denoting the an\\ufffenual consumption in monetary units of customers as well as the output y denoting which of the three regions; Lisbon, Oporto, and one additional region denoted Other, the cus\\ufffetomers came from in the wholesale customer data A According to the model it seems that people in Lis\\ufffebon buy more FRESH products, MILK products and DELI products than people in Oporto B According to the model if a costumer after the stan\\ufffedardization has x1 = x2 = x3 = x4 = x5 = x6 = 0 the customer is more likely to come from Oporto than Lisbon C The logit function will return the probability a per\\ufffeson is from Lisbon',\n",
              " 'E Don’t know Question 3: We consider the Galapapos dataset shown in Table 8.3 fit with a linear regression model which predicts the area of an island x3 based on the remaining attributes, i.e x1, x2, x4, x5, x6, x7 We obtain the following model for the prediction of an islands area (x3) using the raw untransformed attributes that are plotted in Figure 8.10: f(x1, x2, x4, x5, x6, x7) = 63.4 + 4.3x1 − 34.7x2 + 3.0x4 − 7.2x5 − 1.4x6 − 0.5x7 Which one of the following statements about the model is correct?152 8 Introduction to classification and regression No Attribute description Abbrev x1 Number of plant species Plants x2 Number of endemic plant species E-Plants x3 Area of island (in km2 ) Area x4 Max elevation above sea-level (in m) Elev x5 Distance to nearest island (in km) DistNI x6 Distance to Santa Cruz Island (in km) StCruz x7 Area of adjacent island (in km2 ) AreaNI Table 8.3 The seven attributes of the data on a selection of 29 of the Gal´apagos islands',\n",
              " 'A According to the model AreaNI is irrelevant for pre\\ufffedicting the Area of islands B According to the model it seems that the closer the neighboring island is the larger area the island has C According to the model endemic plants is the most important predictor of island area D According to the model an island that is highly ele\\ufffevated and close to Santa Cruz Island will in general be predicted to be relatively small E Don’t know Question 4: We will consider survived as the pos\\ufffeitive class (i.e, y = 1) and died as the negative class (i.e., y = 0) in Haberman’s survival dataset shown in Table 8.4 Considering again the confusion matrices for the logistic regression and decision tree classifiers given in Figure 8.11, which one of the following statements is correct Attribute description Abbrev',\n",
              " 'A modified version of Haberman’s Survival Data taken from http://archive.ics.uci.edu/ml/machine-learning\\ufffedatabases/haberman/haberman.names The attributes x1-x3 denoting the age, operation time and cancer size as well as the output denoting survival after five years are binary The data contains a total of N = 306 observations The confusion matrix for the logistic regression and decision tree classifiers used to predict survival based on leave-one-out cross validation A The precision of the logistic regression classifier is higher than the precision of the decision tree classi\\ufffefier B The recall of the logistic regression classifier is higher than the recall of the decision tree classifier C The true negative rate of the logistic regression classi\\ufffefier is lower than the true negative rate of the decision tree classifier.8.3 The general linear model⋆ 153 D The false positive rate of the logistic regression clas\\ufffesifier is higher than the false positive rate of the de\\ufffecision tree classifier',\n",
              " 'Question 5: x2 x1 Class 1 Class 0 x2 x1 −1 −0.5 0 0.5 1 −1 −0.5 0 0.5 1 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 −1 −0.5 0 0.5 1 −1 −0.5 0 0.5 1 Fig top pane: Observed data Bottom pane: Estimated probability of belonging to class 1 according to the logistic re\\ufffegression classifier Recall the logistic function is defined as logistic(z) = 1 1 + e−z  Suppose logistic regression classifier is trained on obser\\ufffevations from two classes as shown in the top pane of fig 8.12 and the trained classifier produces an estimate of the probability of belonging to class 1 as shown in the bottom pane If the classifier takes the following form f(x1, x2) = logistic(w0 + w1x1 + w2x2 + w3x1x2) what are the values of w0, w1, w2, w3 A w0 = 2, w1 = w2 = 0, w3 = 10 B w0 = −2, w1 = w2 = 0, w3 = −10 C w0 = −2, w1 = w2 = 1, w3 = 10 D w0 = 2, w1 = w2 = 1, w3 = −10 E Don’t know.9 Tree-based methods In this section, we will consider tree-based methods for classification or regression',\n",
              " 'However it is accomplished quite differently than linear or logistic regression, in that we consider the value of yi as being determined by asking a series of questions organized as a tree about xi and then, based on the answers, assign yi a constant value Decision trees were originally developed by Earl B Hunt (and coauthors) in 1966 in his Concept Learning System where the construction of the sequence of questions was intended to model human concept acquisition [Hunt et al., 1966] However, today decision trees have grown to be an important yet simply supervised learning model In the next sections, we will introduce regression and classification trees as well as discuss how they can be learned using Hunt’s algorithm Animals dataset A dataset of N = 15 observations and M = 4 binary features where the goal is to predict if the animal is a Mammal or not',\n",
              " 'Initially just the full dataset if The stop criterion is met then Add a leaf node to the tree which assigns every observation to the most prevalent class in Dr else Try a number of different splits on Dr For each split, compute the purity gain and select the split Dr = {Dv1 ,  , DvK } with the highest purity gain Recursively call the method on Dv1 ,  , DvK end if 9.1 Classification trees Consider the dataset in table 9.1 comprised of N = 15 animals For each animal, we have recorded M = 4 features (cold blooded, has legs, lay eggs, and has fur) and we wish to build a classifier which determines y, if the animal is a mammal or not Of course this corresponds to our usual situation where we are given a matrix X and a vector y, however, for the moment we will limit ourselves to the case where X is binary and consider the general case later The decision tree can then be constructed using what is known as Hunt’s algorithm and is outlined in fig',\n",
              " 'This question partitions the 15 animals into two new groups (top right pane); since one group (the cold blooded animals) are all non-mammals they are classified as such in a leaf node and we say this node is pure The other group consists of a mixture of animals and so we ask a new question: “lay eggs?” in the bottom-right pane This partitions the animals into two new groups and since they only contain mammals or non-mammals (i.e they are pure) the method terminates The general procedure, Hunt’s algorithm for decision-tree induction, is a simple recursive ap\\ufffeplication of the same yes/no questioning procedure we just illustrated on the animal dataset In general we will consider splits which are not just binary but multi-way 9.2 we consider 5 example splits for different attribute types',\n",
              " 'We then assume we at every step in the procedure has access to many potential splits and select the best split based on the purity gain that we will discuss shortly The method terminated for the animal dataset when a branch contained only one type of animal, however, in general we will stop when a general stop criterion is met The full method can be found in algorithm 2 9.1.1 Impurity measures and purity gains So how do we determine when one question is better than another 9.3 we have outlined two potential root-node questions In the left pane we ask if the animals have legs, and in the right pane we ask if it has fur There are generally two components to a good question: Firstly, how balanced the question is If the question is very specific, then one branch will only contain very few animals and the question will therefore not be very informative If we consider the left-pane of fig',\n",
              " 'Construction of a decision tree using Hunt’s algorithm to classify whether an animal is a mammal or not Initially, all observations are assigned to the root (top left pane) and we consider a question The question divides the animals into two sets, if a particular set is pure, i.e only contains mammals (or non\\ufffemammals) the method terminates (top right), else we recursively apply the method (bottom left) The method terminates in the bottom-right pane because all leaf branches are pure In the general method, we consider many question at each branch, and select the best according to it’s purity gain  tree, v1, contains N(v1) = 7 animals whereas the right-most branch contains N(v2) = 8 animals The question is thus fairly balanced compared to the right-most branch where we have N(v1) = 11 and N(v2) = 4.158 9 Tree-based methods Binary Discrete Continious Has Legs Shirt Size Age {XS,S} {M} {L,XL,XXL} {XS,S,M} Yes {L,XL,XXL} No ≤ 30 > 30 < 10 [10; 20[ [20; 35] > 35 Fig',\n",
              " 'Binary attributes only allow binary (yes/no) splits, whereas discrete and continuous attributes allow either binary splits or many-way splits Starfish Bluebird Blackbird Earthworm Chameleon Snake Ant Jellyfish Snail Sea-urchin Dolphin Rat Dog Lion Monkey Starfish Earthworm Snake Jellyfish Snail Sea-urchin Dolphin Bluebird Blackbird Chameleon Ant Rat Dog Monkey Lion Starfish Bluebird Blackbird Earthworm Chameleon Snake Ant Jellyfish Snail Dolphin Sea-urchin Rat Dog Monkey Lion N(r) = 15 p(M|r) = 2 3 N(r) = 15 p(M|r) = 2 3 N(v1) = 11 p(M|v1) = 1 11 N(v2) = 4 p(M|v2) = 1 N(v2) = 8 p(M|v2) = 1 2 N(v1) = 7 p(M|v1) = 1 7 Has Legs Two different potential splits (left and right pane) The splits divide the animals at the root r into different groups corresponding to the left v1 and right v2 branch When choosing between two splits, we are interested in how balanced they are (i.e if N(v1) ≈ N(v2)) and to what extend it is pure i.e',\n",
              " 'From these quantities we can compute the purity gain ∆ On the other hand, we also want the split into different groups of animals to be as pure as possible, that is to contain (preferably) only one kind of animal In the left-pane of fig 9.3 the left\\ufffebranch v1 contains only one mammal (i.e the probability the animal is a mammal in this branch is p(M|v1) = 1 7 ) and in the right-branch p(M|v2) = 1 2  However, the fur-split in the right hand pane9.1 Classification trees 159 is much more pure since the probability of a mammal in the left-branch is p(M|v1) = 1 11 and in the right-pane p(M|v2) = 1 A measure of how good a question is should therefore consider both how balanced the question is and how pure the resulting classes are This can be accomplished by first quantifying how impure the classes are at the root and at the K potential branches using an impurity measure We will write this as I(r) for the impurity at the root and I(v1), I(v2),  , I(vK) for the impurity at the branches',\n",
              " 'By contrasting the impurity before the split to the overall impurity after the split we obtain the purity gain ∆ for the question, which is given by the formula ∆ = I(r) − X K k=1 N(vk) N(r) I(vk) (9.1) A high purity gain indicates that the impurity of the individual splits, I(v1),  , I(vK) is low, i.e the classes have become more pure relative to the root impurity I(r) The weighting by the fraction N(vk) N(r) is used to make the measure focus on the larger (important) groups in the split This only requires us to specify the impurity The impurity function I(v) only depends on the (relative) size of the classes in the given branch v, i.e the probabilities p(c|v) If in general we consider there are C classes, we have C such probabilities in each branch p(c = 1|v),  , p(c = C|v) (in the animals example we had two classes corresponding to C = 2 and p(M|v), p(not M|v))',\n",
              " '(9.4) Here log2 p(c|v) is the base-2 logarithm Suppose we consider the example in the right pane of fig 9.3 and we use the ClassError impurity measure we obtain: I(r) = 1 − 2 3 = 1 3 , I(v1) = 1 − 10 11 = 1 11 and I(v2) = 1 − 1 = 0 (9.5) We can then compute the purity gain as ∆ = I(r) − 11 15 I(v1) − 4 15 I(v2) = 1 3 − 1 15 = 4 15  (9.6) As mentioned, the purity gain can easily be computed for many types of splits and having multiple classes 9.4 we consider a three-way split (K = 3) for N(r) = 12 objects (the colored balls) corresponding to a total of C = 4 true classes In the example, the impurity gain would be ∆ = I(r) − 5 12 I(v1) − 1 4 I(v2) − 1 3 I(v3) (9.7)160 9 Tree-based methods v3 v1 v2 N(r) = 12 N(v3) = 4 N(v2) = 3 N(v1) = 5 p(Y |v3) = p(B|v3) = 1 4 p(R|v3) = 1 2 p(G|v3) = 0 p(B|v2) = 2 3 p(R|v2) = 1 3 p(Y |v2) = p(G|v2) = 0 p(Y |v1) = 3 5 , p(B|v1) = 0 p(G|v1) = p(R|v1) = 1 5 p(R|r) = p(Y |r) = 1 3 p(G|r) = 1 12 p(B|r) = 1 4 r Fig',\n",
              " 'The classes are indicated by the colors See text for details on how the purity gain ∆ can be computed from the given numbers In practice, we are of course primarily interested in applying classification trees to the case where X contains general continuous features The splits most often considered are binary, two\\ufffeway splits obtained by considering each of the M features of X and then attempting different possible split-values: xm < x∗ (9.8) where x ∗ is the split-value varied over the range of the observed data points This gives a very large number of potential splits, each being axis aligned This is illustrated for a 2D dataset in fig We start by considering all binary splits x1 < x∗ and x2 < y∗ where x ∗ and y ∗ are varied The split with the highest purity gain is selected and indicated by the colors in the top-left pane The method is applied recursively for each of the two new splits',\n",
              " 'This procedure is continued recursively in the bottom row and the method terminates when it encounters pure classes 9.1.2 Controlling tree complexity Hunt’s algorithm terminates if it encounters pure splits, i.e the current set of observations in a leaf only contains one class However, it is often a good idea to terminate the method earlier Consider for instance fig 9.5 bottom-right pane where in order to place all observations in a pure leaf node the method creates some rather odd-looking boxes In general, there are two strategies for ensuring this does not happen Early stopping The simplest way to control the complexity of the tree is to stop Hunt’s algorithm before it encoun\\ufffeters pure splits There are several criteria for stopping:9.1 Classification trees 161 Fig Construction of a decision tree using Hunt’s algorithm We consider binary K = 2 splits where we as candidate splits consider if x1 (and x2) is less than or greater than a sequence of split-values',\n",
              " 'Hunt’s algorithm is then applied recursively (top right pane) to produce two additional splits, then it is applied recursively on the non-pure groups (bottom left) and after several steps produces the final split in the bottom-right pane Notice the final configuration likely overfits the data \\x88 Stop splitting when a branch contains less than a specific number of observations \\x88 Stop splitting if a certain depth of the tree is reached \\x88 Stop splitting if purity gain ∆ for the best split is below a certain value This of course leaves open the question of how we should select for instance the minimum number of observations in a branch For now simply assume it is selected manually - in chapter 10 we will consider how cross-validation can be used to solve this problem Pruning* Early stopping is simple to implement, but comes with an important disadvantage known as the horizon effect',\n",
              " 'Pruning tries to get around this problem by first growing a full tree with no (or very little) early stopping and then afterwards select which branches in the tree should be replaced by a single leaf (i.e should be pruned) How the pruned subtrees are selected differ from pruning strategy to pruning strategy but a simple strategy is cost complexity pruning [Breiman et al., 1984] In cost complexity pruning, we construct a series of trees T0, T1, · · · , Tm where T0 is the initial (full) tree produced by Hunt’s algorithm and Tm is a tree only consisting of the root',\n",
              " 'A simple 1D example regression data set containing N = 100 observations is constructed from Ti−1 by first trying to collapse each subtree t of Ti−1 into a single node and for the collapsed tree compute the cost-complexity tradeoff which measures the relative increase in error per removed node; the intuition being that the removal of many nodes should be favored over the removal of a single node Once the cost-complexity has been computed for each internal branch the branch with the lowest cost-complexity is collapsed producing Ti  Algorithmically the method is shown in algorithm 3 Once the sequence T0, · · · , Tm has been produced, the tree Ti with the lowest generalization (i.e test) error is selected How to estimate the generalization error is discussed in chapter 10 as two-layer cross-validation 9.2 Regression trees In regression, yi for an observation i is no longer discrete but continuous The decision tree method may however very easily be altered to accommodate for this change',\n",
              " 'We can ask exactly the same questions, but then in order to predict the mean life span yi for a given branch, say for instance the right-most branch in the right-most pane of fig 9.3, we would simply predict the mean value of the animals in that branch:9.2 Regression trees 163 Algorithm 4: Hunt’s algorithm for regression trees Require: Initial tree T only containing the root node Require: Dr : Dataset associated with the current branch Initially just the full dataset if The stop criterion is met then Add a leaf node to the tree which assigns every observation the mean value of the nodes in Dr: y(r) = 1 N(r) P i∈r yi else Try a number of different splits on Dr For each split, compute the purity gain using the sum-of-squares impurity measure and select the split Dr = {Dv1 ,  , DvK } with the highest purity gain Recursively call the method on Dv1 ,',\n",
              " 'This can be done by simply introducing a new impurity measure: I(v) = 1 N(v) X i∈v (yi − y(v))2 where y(v) = 1 N(v) X i∈v yi , (9.11) and then simply use Hunt’s algorithm as already introduced where the stopping criteria may for instance be that the purity gain (or the impurity) falls below a certain value The algorithm is very similar to algorithm 2 but for completeness it is listed in algorithm 4 We will consider this method applied to the simple 1-d regression problem in fig 9.6, the result can be seen in fig We again consider recursive, binary splits In the first iteration of the algorithm, all observations are assigned to the same branch and we simply predict the mean value of all observations (top left pane) Then, the optimal split is selected as the split which increases the purity gain the most and we split the x-values once at the dotted vertical line to produce two predicted y-values (right pane)',\n",
              " 'As can be seen, this method very quickly allows for a flexible but piece-wise constant prediction of y.164 9 Tree-based methods x y 0 0.2 0.4 0.6 0.8 1 −2 −1 0 1 2 x y 0 0.2 0.4 0.6 0.8 1 −2 −1 0 1 2 x y 0 0.2 0.4 0.6 0.8 1 −2 −1 0 1 2 x y 0 0.2 0.4 0.6 0.8 1 −2 −1 0 1 2 Fig Application of the regression tree method to the 1d example First, all observations are assigned a constant y-value (top left pane) Then we consider various splits (along the x-axis) and select the one with the highest purity gain computed using the sum-of-squares impurity measure (top right) The method is applied recursively on each section until a stopping criterion is met (bottom row).9.2 Regression trees 165 Problems 9.1 Question 1: We consider a dataset on survival of breast cancer taken from http://archive.ics.uci edu/ml/machine-learning-databases/haberman/ haberman.names The data has been binarized as out\\ufffelined in Table 9.2 The dataset contain a total of 306 observations',\n",
              " 'We would like to build a decision tree and consider using positive axillary nodes detected (PAN) as an attribute condition at the root of the tree We thereby split according to whether positive axillary nodes were detected and find: \\x88 For the 170 subjects that had positive axillary nodes detected 62 survived \\x88 For the 136 subjects that did not have positive axil\\ufffelary nodes 19 survived What is the gain, ∆, of splitting according to whether a subject had positive axillary nodes (PAN) using the Gini as impurity measure I(t), (i.e., I(t) = 1 − PC−1 i=0 p(i|t) 2 ) Attribute description Abbrev x1 Young (< 60 years), x1 = 0 or Age Old (≥ 60 years), x1 = 1 x2 Operated before, x2 = 0 or OpT after 1960, x2 = 1 x3 Positive axillary nodes detected PAN No, x3 = 0 or Yes, x3 = 1 y Lived after 5 years Surv No, y = 0 or Yes, y = 1 Table 9.2 A modified version of Haberman’s Survival Data taken from http://archive.ics.uci.edu/ml/machine-learning\\ufffedatabases/haberman/haberman.names',\n",
              " 'The data contains a total of N = 306 observations A -0.025 B 0 C 0.025 D 0.036 E Don’t know Question 2: We will use the decision tree given in Figure 9.8 to attempt to solve the classification problems given to the right of Figure 9.8 corresponding to the clas\\ufffesification problem also considered in Figure 9.9 Which one of the following choices for the two decisions A and B in the decision tree would be the most well suited to separate the two classes A decision tree with two decisions denoted A and B that if given the right decisions can be used to perfectly separate the red crosses from black circles given in the clas\\ufffesification problem to the right that was also considered in Figure 9.9 The decision boundaries given in white and gray of four different classifiers used to separate red crosses from black circles',\n",
              " 'Question 3: Consider a one-dimensional data set of features X and 3-class responses y shown in table 9.3; there are thus N = 7 observations X 1 3 1 2 1 4 2 y 2 2 2 0 0 1 0 Table 9.3 Table of data and responses Suppose a decision tree is used to classify y on X Consider an attempted split at X = x1 > 2.5 What is the impurity gain ∆ of this split for the data set if the classification error is used as impurity measure A ∆ = 0.123 B ∆ = 0.143 C ∆ = 0.239 D ∆ = 0.428 E Don’t know Question 4: Class 1 Class 0 x2 x1 −1 −0.5 0 0.5 1 −1 −0.8 −0.6 −0.4 −0.2 0 0.2 0.4 0.6 0.8 1 Fig Two-class classification problem Class 1 Class 0 Class 1 Class 0 A B C (true) (true) (false) (true) (false) (false) Fig Decision tree with 3 nodes A, B and C Suppose we wish to solve the two-class classification problem in fig 9.10 using a classification tree of the form fig',\n",
              " 'A A : ∥x∥2 ≥ 1 2 , B :         x − \\x14 −1 1 \\x15        ∞ > 1 C :         x − \\x14 1 −1 \\x15        1 > 2 B A : ∥x∥2 ≥ 1 2 , B :         x − \\x14 1 −1 \\x15        1 > 2 C :         x − \\x14 −1 1 \\x15        ∞ > 1 C A :         x − \\x14 1 −1 \\x15        1 > 2, B :         x − \\x14 −1 1 \\x15        ∞ > 1 C : ∥x∥2 ≥ 1 2 D A :         x − \\x14 1 −1 \\x15        1 > 2, B : ∥x∥2 ≥ 1 2 C :         x − \\x14 −1 1 \\x15        ∞ > 1 E Don’t know.10 Overfitting and cross-validation For some practitioners of machine learning the most interesting aspect is devising new and exciting algorithms and words such as “evaluation” or “testing” is likely to be treated as an afterthought However, testing and quantifying the performance of machine-learning methods is possibly the most important aspect of data modelling Suppose we are in a situation where we has S different models M1,  ,MS that each tries to solve a particular supervised learning problem Without an objective way of comparing the models we will not know which to choose',\n",
              " 'Worse yet, if we are working in a company, it will be impossible to quantify if progress is being made at solving the problem or if there is any benefits for the company to have a machine learning department at all Seen in this way quantification (and comparison) of model performance is something a machine\\ufffelearning practitioner should be obsessively preoccupied with In this chapter, we will discuss common issues with model performance evaluation and provide the industry standard, cross-validation, for estimating the generalization error which allow us to evaluate a given models performance and thereby select between different models The chapter will finish with a discussion of how the gener\\ufffealization error provides more qualitative information about the goodness of a given model 10.1 Cross-validation The principal way of comparing and validating models is by cross-validation',\n",
              " 'We will use the simple linear regression model as a running example 10.1.1 A simple example, linear regression To provide a concrete example, consider the simple regression problem in fig 10.1 where the goal is to predict y from x and we have access to 9 data points collected in a training data set Dtrain The data consists of noisy observations of the black curve and and we wish to fit a regression model to the data We assume we have access to three different models168 10 Overfitting and cross-validation x f(x, w) 0 0.5 1 0.2 0.3 0.4 0.5 x f(x, w) 0 0.5 1 0.2 0.3 0.4 0.5 x f(x, w) 0 0.5 1 0.2 0.3 0.4 0.5 Fig A small dataset of nine observations generated from the true curve shown in the black line The three red lines are three different linear regression models M1,M2,M3 fitted to the dataset Clearly the most complicated model M3 fits the dataset best, however, the second model M2 is better suited to account for the true black curve',\n",
              " 'Training error for each of the three models M1,M2,M3 computed on the training data set The most complicated model has the lowest training error M1 = {1’st order polynomial, i.e }fM1 (x, w) = w0 + w1x M2 = {2’nd order polynomial, i.e }fM2 (x, w) = w0 + w1x + w2x 2  M3 = {6’th order polynomial, i.e }fM3 (x, w) = w0 + w1x + w2x 2 + w3x 3 + w4x 4 + w5x 5 + w6x 6  The red line indicates the fitted polynomials For each model we quantify how well the model fits the training data by the training error which for model Ms is E train Ms = 1 Ntrain X i∈Dtrain (yi − fMs (xi , w))2  Here fMs is the model Ms fitted to the training data and Ntrain = |Dtrain| is the number of observations in the training data set The training error of each of these three models is shown in fig',\n",
              " 'The example from before with a test dataset of three new points If the models are evaluated in terms of how they predict the new points M2 is preferred Nevertheless, we are not interested in a model like M3 as it clearly will not generalize well to new data We say model M3 is overfitting the data Thus, we can’t tell the models apart by how well they fit the training data and in fact this can give us an entirely misleading picture of the models performance due to overfitting This is such an important principle it is worth framing: Never, ever should you estimate how well a model performs by its predictions on data it was trained upon However, let’s assume we obtain access to some new data, the test data Dtest, indicated by the green squares in fig Testing the models on this new test-dataset gives us the ability to estimate how well the models generalize to new data We can define the test error as E test Ms = 1 Ntest X i∈Dtest (yi − fMs (xi , w))2',\n",
              " 'The test error of each of these three models is shown in fig Notice, the test error allows us to select the correct model, i.e the model that can be expected to generalize better to new data The problem is that as a rule nobody is going to turn up and give us a test dataset when we need it The basic idea in cross-validation is to overcome this problem by taking our existing fixed data set D and manually divide it into a training set, Dtrain, and a testing data set, Dtest, and then use these two to select the appropriate model 10.1.2 The basic setup for cross-validation The basic setup for cross-validation is as follows: We consider a supervised learning problem with a data set D = (X, y) It is important to keep in mind the dataset is finite and this is all the data we have As in the regression example, we consider different models for solving the problem, M1,M2,',\n",
              " 'In the regression example the loss function was the least square error L(yi , yˆi ) = ∥yi − yˆi∥ 2 , but in general the loss function will be defined according to the specific modeling purpose.170 10 Overfitting and cross-validation Test error Training error Model index Mk Error 1 2 3 0 0.005 0.01 0.015 Fig Test error for each of the three models M1,M2,M3 computed on the test data set The test error correctly singles out model M2 as the better model x f(x, w) 0 0.5 1 0.2 0.3 0.4 0.5 x f(x, w) 0 0.5 1 0.2 0.3 0.4 0.5 x f(x, w) 0 0.5 1 0.2 0.3 0.4 0.5 Fig The basic regression problem for model M2 and three random test sets Since the test sets are random, the test error too will vary depending on the particulars of the test set The generalization error overcomes this by averaging over all test sets',\n",
              " '(10.2) These definitions are similar except fM is fitted on the training set in both cases Generalization error A problem with the test error is that it depends on the specific test set Since we have to construct the test set ourselves, this makes the test error slightly random This is illustrated in fig 10.5 for the10.1 Cross-validation 171 Generalization error Test errors Model Mk Error 1 2 3 0 0.002 0.004 0.006 0.008 0.01 0.012 0.014 Fig Continuing the example, for the three models different test sets gives different test error as indicated by the black dots The generalization error is simply the average over all possible test sets according to their probability of occurring test error for three different (random) test sets To alleviate this problem we introduce a new, third error namely the generalization error The generalization error is an idealized quantity indicating how well our model performs on average assuming we had an infinite amount of data to test it on, i.e',\n",
              " 'The generalization error is what we truly wish to estimate and the best model is the model with the lowest generalization error If we assume the test observations (xi , yi ) come from a distribution p(x, y) then the generalization error is defined as follows: \\x88 Train the model M on the full dataset available D to give a prediction rule fM \\x88 The generalization error of model M is1 E gen M = E(x,y) [L(y, fM(x))] (10.3) = Z L(y, fM(x))p(x, y)dxdy (10.4) The generalization error is the fairest estimate of how well our model can perform because it assumes we train our model on all data we have available and then computes the average loss on all future data 1 Another popular definition is to consider the training set random as well which we will later call the averaged generalization error',\n",
              " 'Cross-validation applied to the model M2 using 3-fold cross-validation Errors are estimated from the test data points and is indicated by the gray bars Averaging all errors produce the estimate of the generalization error Eˆgen M2 10.1.3 Cross-validation for quantifying generalization The obvious problem with the generalization error is that we cannot compute it since we don’t know the true distribution of the data Cross-validation, is thus a framework to estimate a model’s generalization error typically based on one of the following three approaches: Hold-out method In the hold-out method, the full dataset D is split into a train and a testing set D = D train ∪ Dtest  Then, we train a model on Dtrain and compute the test error Etest M using the test data set Dtest and formula eq (10.2) and simply use the approximation: E gen M ≈ E test M  Why does this work The test error is different in two ways from the generalization error',\n",
              " 'However, if the training data set is large, we can expect (or rather, hope!) there will be little difference in using Dtrain instead of D and secondly, if we have a lot of test data in Dtest, and each element in the test data set is drawn from the true distribution p(x, y), we can expect the empirical average in eq (10.2) to be quite close to the true average for the generalization error eq By recognizing these limitations we can provide two alternative methods which generally does better but are also computationally more demanding: K-fold cross-validation Ideally, we want each data point to be used in the test set, and one way to accomplish this is with K-fold cross-validation',\n",
              " 'Cross-validation applied to model-selection for the linear regression models Each row corre\\ufffesponds to one of the three models, and each column to the estimate of the test error on that particular fold each containing N K observations We then produce K splits into training and test sets by, for each k, treating Dk as the test set and the other K − 1 pieces as the training set Computing the test error on each of these K splits gives K estimates of the error Etest M,1 ,  , Etest M,K and we now approximate: E gen M ≈ X K k=1 Ntest k N E test M,k, i.e., as the weighted average of the test errors, weighted by the number of test observations in each fold Ntest k relative to the total number of observations used for testing N Since each data point is used once in the test set this method is generally more precise than the hold-out method, however, it requires K times more training and testing of models than the hold-out method',\n",
              " 'This can be accomplished by using K-fold cross-validation with K = N,174 10 Overfitting and cross-validation the total number of observations in the full data set In this way, we train N models and each model is trained on the full data set except a single observation and then tested on that single observation The benefit of this method is that it uses as much data as possible for training such that each trained model is less prone to overfitting than when larger parts of the data are taking out for testing at a time which is especially a concern when having very limited data However, the drawback is that it requires N models to be trained which can be very wasteful While leave-one-out cross-validation gives an almost unbiased estimate of the generalization error, in some cases it can have a larger variance compared with, say, 10-fold cross-validation Overall, it is recommended to use 10-fold cross-validation [Kohavi, 1995]',\n",
              " 'An illustration where 3-fold cross-validation is applied to the linear-regression example is given in fig Each figure corresponds to a fold and in each fold the test error is computed as the average of the error on the three datapoints that are left out Notice, all nine data-points are part of the test set exactly once 10.1.4 Cross-validation for model selection We will accept that the generalization error eq (10.4) is the optimal way to measure the performance of a model, and that cross-validation using any of the three techniques (hold-out, K-fold or leave\\ufffeone-out) is a faithful estimate of the generalization error Then, an obvious way to select between S models M1,  ,MS is to estimate the generalization error of each model using cross-validation and select the model with the lowest cross-validation error To summarize: \\x88 For each model, compute the estimate of the generalization error Eˆgen M1 ,  , Eˆgen MS using cross\\ufffevalidation',\n",
              " 'This technique is most often used in conjunction with K-fold cross-validation In this case it is strongly recommended that the same data splits (i.e choices of D1,  , DK) is used for all models Since the resulting method is so important it is provided as an explicit algorithm in algorithm 5 An illustration of 3-fold cross-validation for model selection in the linear-regression example is given in fig Each of the columns corresponds to a fold and each of the rows to a model 10.9 the estimated generalization and training errors (averaged over the cross-validation folds) is plotted As can be seen the training error drops for the more complicated model, however, the cross-validation estimate of the generalization error allows us to select the right model M2 10.1.5 Two-layer cross-validation Let’s turn to the following situation: We wish to select the optimal model Ms ∗ out of S models and estimate the generalization error for this optimal model Ms ∗',\n",
              " 'This is illustrated in10.1 Cross-validation 175 Algorithm 5: K-fold cross-validation for model selection Require: K, the number of folds in the cross-validation loop Require: M1,  The S different models to select between Ensure: Ms∗ the optimal model suggested by cross-validation for k = 1,  , K splits do Let D train k , D test k the k’th split of D for s = 1,  , S models do Train model Ms on the data D train k Let E test Ms,k be the test error of the model Ms when it is tested on D test k end for end for For each s compute: Eˆgen Ms = PK k=1 Ntest k N E test Ms,k Select the optimal model: s ∗ = arg mins Eˆgen Ms Ms∗ is now the optimal model suggested by cross-validation Training error Estimated generalization error Model index Ms Error 1 2 3 0 0.005 0.01 0.015 0.02 0.025 0.03 Fig Training error and the cross-validation estimate of the generalization error The estimate of the generalization error is simply the averages of the errors in fig',\n",
              " 'The model with the lowest estimated generalization error is M2 even though it does not have the lowest training error 10.10 where we consider 14 different models and for each model the true generalization error is indicated as the black line and the estimated generalization error as the small red dots The selected model is the model with the lowest (estimated) generalization error indicated with the red circle The estimates of the generalization error is imprecise due to the randomness in the test set which is why they are not all on the black line There is however a problem with this approach Suppose we had access to additional test sets and use these to estimate the generalization error (indicated in the 3 other panels of fig',\n",
              " 'Top right: The true generalization error of 14 models is indicated by the black line and estimates of the generalization error (computed using cross-validation) are indicated by red dots Standard cross-validation then selects the model with the lowest (estimated) cross-validation error (indicated by red circle) However, this estimate of the generalization error is not in general a fair estimate of how the model will generalize to future data because it is selected as a minimum In subplots 2-4 is shown the same procedure and as seen the estimated generalization error is too optimistic (below the black line) in all instances A better estimate can be obtained by using a completely new test set, blue dots, which provides a fairer estimate of the generalization error for the selected values This leads to two-layer cross-validation the red dots',\n",
              " 'After all, there are many roughly equally good models to choose from, so when we select the best of these we will due to the randomness often do exceedingly well In the figure, this is seen as the selected red point being far lower than the true generalization error in all instances Obviously, this is cheating To understand exactly what goes wrong we need to take a step back By including the step where we select the optimal model M∗ = Ms ∗ based on the data we have actually changed the underlying model being tested The model the above method produces, M∗ , is now composed of two things: \\x88 Use K2-fold cross-validation to estimates Eˆgen s  \\x88 Select M∗ as the optimal model Ms ∗ where s ∗ = arg mins Eˆgen s .10.2 Sequential feature selection 177 Algorithm 6: Two-level cross-validation Require: K1, K2, folds in outer, and inner cross-validation loop respectively Require: M1,  ,MS: The S different models to cross-validate Ensure: Eˆgen, the estimate of the generalization error for i = 1,',\n",
              " 'First make the outer split into K1 folds Let D par i , D test i be the i’th split of D for j = 1,  , K2 do Inner cross-validation loop Use cross-validation to select optimal model Let D train j , D val j be the j’th split of D par i for s = 1,  , S do Train Ms on D train j Let E val Ms,j be the validation error of the model Ms when it is tested on D val j end for end for For each s compute: Eˆgen s = PK2 j=1 |Dval j | |Dpar i | E val Ms,j Select the optimal model M∗ = Ms∗ where s ∗ = arg mins Eˆgen s Train M∗ on D par i Let E test i be the test error of the model M∗ when it is tested on D test i end for Compute the estimate of the generalization error: Eˆgen = PK1 i=1 |Dtest i | N E test i Thus, estimating the generalization error requires estimating the generalization error of the model obtained through this two-step procedure Fortunately, we know how to estimate the generalization error of a model: Cross-validation',\n",
              " 'The method can be sketched as follows: \\x88 For i = 1,  , K1 cross-validation iterations, split the data D into a training set D par i and a test set Dtest i \\x88 For each iteration, find the optimal value s ∗ using K2-fold cross-validation on D par i  (In the j th inner fold D par i is split into a training set Dtrain j and a test set (called a validation set) Dval j ) \\x88 Train the model M∗ using the selected model structure Ms ∗ trained on the full outer fold training set D par i \\x88 Let Etest M∗,i be the test error of M∗ computed on the i’th test set Dtest i \\x88 Estimate the generalization error as Eˆgen = PK1 i=1 |Dtest i | N Etest M∗,i Again, since this method is so important it is worth providing it in pseudo code as algorithm 6 10.2 Sequential feature selection Consider a dataset where observations xi correspond to patients and we wish to predict a patient’s survival time after an operation yi using linear regression',\n",
              " 'Clearly, only the first and last attribute is relevant to our purpose, so rather than considering178 10 Overfitting and cross-validation x f(x, w) 0 0.5 1 0.2 0.4 0.6 x f(x, w) 0 0.5 1 0.2 0.4 0.6 x f(x, w) 0 0.5 1 0.2 0.4 0.6 Fig A regularized linear regression model is fitted to the dataset of nine observations and six test observations The different plots correspond to adding more “junk” attributes, i.e attributes where the values are just random As more random attributes are added, the model better fit the training set but does worse on the test set the attribute x =  x1 x2 x3 T we could just as well consider the smaller dataset: x =  x1 x3 T  So does it matter that we include the room number x2 in our dataset Well in general irrelevant attributes matter for three reasons: \\x88 If the number of attributes (in particular the irrelevant ones) is large compared to the total number of observations our model performance will degrade',\n",
              " '\\x88 A hospital will often wish to know which attributes are important and which are irrelevant A model with many irrelevant attributes will not tell them that directly Let’s examine the first claim first Suppose we have the simple, linear regression problem which can be fitted well with a second-order polynomial That is, optimally we should consider: x =  x1 x 2 1  (10.5) However, we now add “junk” attributes to the dataset and considers x =  x1 x 2 1 x3 x4  xS+2 where S is the number of junk attributes added to the dataset Thus S = 0 will correspond to eq (10.5) and S = 3 will correspond to adding 3 junk attributes The junk attributes are simply generated as random numbers in the unit interval Examples of the predictions on training and test set for S = 0, 3, 6 added junk attributes can be seen in fig As can be seen, when more junk attributes are added, the model will begin to overfit the training set',\n",
              " '10.12 for S = 0,  , 7 and the three specific values shown in fig 10.11 are indicated by the circles In a way, we already know how to solve this problem: Each selection of which features to use corresponds to a particular model, so in for instance the hospital example we can consider all eight possible models M123 =  x1 x2 x3  M12 =  x1 x2  M13 =  x1 x3  M23 =  x2 x3  M1 =  x1  M2 =  x2  M3 =  x3  M· =  •  ,\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0010.2 Sequential feature selection 179 Training Error Test Error Junk attributes S Error 0 1 2 3 4 5 6 7 0 0.05 0.1 0.15 0.2 0.25 0.3 Fig The training and test error for different number of junk attributes in the example of fig The circles indicate the particular values shown in fig and select the optimal model by the use of cross-validation for model selection as already described In many ways this is the best we can do from a theoretical perspective, however, the problem is that this procedure quickly becomes very costly',\n",
              " 'Clearly this won’t do Sequential feature selection overcomes this problem by not considering all possible models but only a subset Sequential feature selecting comes in two variation, forward and backward selection, but they are very similar 10.2.1 Forward Selection In forward selection, we first consider a model with no features M· =  •  That is, it predicts yi as just being constant Then it considers the models obtained by adding each attribute to the existing (empty) set of selected attributes thereby testing all the models: M• =  •  , M1 =  x1  , M2 =  x2  ,  ,MK =  xM   Each of these M + 1 models are evaluated by cross-validation for model selection and the optimal model, say Mi , is selected If M• is selected the process terminates Else, this procedure is now repeated by evaluating the M models corresponding to Mi =  xi  , M1i =  x1 xi  ,  .Mi−1,i =  xi−1 xi',\n",
              " 'The estimated generalization error Eˆgen as estimated by cross-validation for models trained on different subsets of the features x1, x2, x3 and x4 Again, if Mi is the optimal model the process terminates, else an optimal model (say model Mij ) is selected and then all M − 1 models corresponding to Mij and the M − 2 models obtained by adding all other attributes than xi , xj to the set evaluated by cross-validation If it is found that for instance Mij is the optimal model, the process terminates, else it continues possibly terminating with the full model: M12...M Example of forward selection Let’s illustrate this procedure with a concrete example Suppose we have a dataset of M = 4 attributes giving 16 possible models with generalization errors (as estimated by cross-validation) shown in table 10.1 Forward selection now proceeds as follows \\x88 Start with model M• with an error of 0.91 \\x88 Compare models M• and M1,M2,M3,M4 \\x88 Optimal model is M4 with error of 0.83',\n",
              " '\\x88 Optimal model is M24 with error of 0.72 \\x88 Compare models M24 and M124,M234 \\x88 Optimal model is M124 with error of 0.68 \\x88 Compare models M124 and M1234 \\x88 Since M124 has lowest error, forward selection terminates and select features 1, 2, 4 Notice the procedure is completely mechanical, however, it is not guaranteed to select the model with the lowest overall generalization error The benefit of forward selection is naturally that we don’t have to compute all the generalization errors beforehand but can compute them as they are required.10.3 Cross validation of time-series data⋆ 181 10.2.2 Backward Selection Backward selection builds upon the same idea as forward selection, but instead of starting with the empty model M•, we start with the full model M12...M and instead of adding features, features are now removed one at a time To continue the example from before: \\x88 Start with model M1234 with an error of 0.79 \\x88 Compare models M1234 and M123,M124,M134,M234',\n",
              " '\\x88 Compare models M123 and M12,M13,M23 \\x88 Optimal model is M13 with error of 0.62 \\x88 Compare models M13 and M1,M3 \\x88 Since M13 has lowest error, backward selection terminates and select features 1, 3 Notice forward selecting selected model M124 and backward selection selected model M13 We are thus not guaranteed that these two methods will select the same set of features or that forward selection will select less features than backward selection (or the reverse) In general, compare both methods and see which has the lowest estimated generalization error The disadvantage of sequential feature selection is that we are not comparing all models and thus we might miss the model with the lowest generalization error The advantage is runtime',\n",
              " 'As a final note, it is strongly recommended to use the same cross-validation splits when estimating the generalization error of the models to reduce variance in the estimates of the generalization error In fact, in the calculation above we have used that M• does not need to be recalculated if using the same cross-validation splits 10.3 Cross validation of time-series data⋆ Our discussion so far has assumed data is atemporal This choice does not reflect the methods we have considered are irrelevant for time-series data, but rather that we wished to avoid unnecessary complications or caveats when discussing the particular methods For completeness, we have nevertheless decided to include a section about validation of time series data',\n",
              " '10.3.1 The setup Time-series data is data which contains a feature corresponding to time, and where the temporal dependency between observations may be considered vital for the prediction task In other words,182 10 Overfitting and cross-validation Table 10.2 The seven entries of the traffic data set ID Time t xrain xtemperature xstation xcars y 1 13:20, Sep 6th, 2019 1 23.7 120 236 164 2 13:40, Sep 6th, 2019 1 22.9 141 249 163 3 14:00, Sep 6th, 2019 1 24.6 168 243 186 4 14:20, Sep 6th, 2019 0 25 179 250 184 5 14:40, Sep 6th, 2019 0 26.4 189 254 196 6 15:00, Sep 6th, 2019 0 26.1 215 271 197 7 15:20, Sep 6th, 2019 1 25.3 227 278 211 if we scrambled the time-coordinate, the machine-learning task should seem difficult or impossible Examples could be the exchange rate of currencies, temperature as recorded throughout a day or a persons future decisions based on recordings of her brain',\n",
              " 'We denote the value at a particular time by: x(t) =  x1(t) x2(t) · · · xM(t) T , y(t) Then, our goal can be described as predicting the value of y at a future time t + ∆t based on whatever data we have recorded, or otherwise have available, up to time t Concretely, assume measurements are taken of x(t) and y(t) at N discrete time steps t = t1, t2,  As an example, suppose we use a security camera to estimate the number of people at a specific train station, and it is this quantity we are interested in predicting based on 4 features All in all: y(t): Estimated number of people at the station of interest xrain(t): Whether it rains or not xtemperature(t): Temperature in Celsius xstation(t): Estimated number of people at (another) station xcars(t): Car velocity at a major intersection km/hour We have shown an (unrealistically small) example of this dataset in table 10.2 comprised of just N = 7 observations',\n",
              " 'To simplify the presentation, we will make the assumption that all sensors (values of features x(t)) are recorded simultaneously and at equidistant time points (i.e., that the interval between when observations are taken is the same) If the later assumption is violated one can do one of three things: \\x88 Ignore the problem; this may lead to useful results if the data is nearly uniformly sampled or the relative spacing between observations is not that important \\x88 If the data is super-sampled, that is, the intervals between each observation is very small, we can consider subsampling the dataset at regularly spaced intervals.\\x00\\x0010.3 Cross validation of time-series data⋆ 183 Table 10.3',\n",
              " 'When the data is divided into equidistant time points we can (linearly) index them by the time point ti at which the observations was recorded which we call time steps or simply steps In the traffic example table 10.2 all observations are made at the same time points and with regular intervals of 20 minutes and the step corresponds to the ID column In addition, we will make the assumption the dataset is stationary, which we will here loosely de\\ufffefine as not being affected by long-running trends (for instance that the number of people at the train station is increasing over time as the train service becomes more popular) If the dataset appears to be obviously non-stationary, one should attempt to standardize it, for instance by regressing out a linear trend It is at this point tempting to turn the prediction problem into simply predicting y at step i based on features corresponding to step i − 1 and so on',\n",
              " 'It is therefore (in this particular example) appropriate to introduce an xhour-feature In a similar vein, weekends implies that the day of the week is probably also important (as commuters are likely to change habits during the weekend) and we introduce an xday-feature Note these new observations are special, as we can pre-compute them for the future time y(t) which we wish to predict It makes sense to separate these features from the remaining features which cannot be predicted; simply put, if we know we are predicting y(t) for a Monday, we are not provided with additional information to know that at earlier times it was Sunday, Saturday, etc In the following, we assume that such special variables are separated from those that cannot be pre-computed, and we will focus on the non-pre-computed variables in the following',\n",
              " 'At any rate, after dropping the irrelevant ID feature, the dataset table 10.2 will now be assumed to look like table 10.3 Embedding size and horizon The horizon h ≥ 1 is an integer denoting how far into the future we are trying to make predictions whereas the embedding size p ≥ 1 refers to how many past observations are relevant to make predictions about the future.184 10 Overfitting and cross-validation Fig Illustration of different choices of embedding size and horizons A dataset (left) consisting of two feature-attributes (green, blue) and prediction targets (red) in the format defined in eq (10.6) is converted into the (standard) (X, y) format used elsewhere in the book for three different choices of embedding size (number of past time steps) and horizons (number of steps to predict into the future), see eq (10.7) To make this concrete, suppose the (non-instantaneous) part of the dataset, i.e',\n",
              " 'x˜ T N \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fb = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8f0 x˜11 x˜12 · · · x˜1M x˜21 x˜22 · · · x˜2M  x˜N1 x˜N2 · · · x˜NM \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fb , y˜ = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8f0 y˜ T 1 y˜ T 1  y˜ T N \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fb  (10.6) For an embedding of size p and horizon h, we will therefore predict ˜yi+h−1 based on data available at steps i − p to i − 1, i.e.: predict ˜yi+h−1 based on  x˜i−p x˜i−p+1 · · · x˜i−2 x˜i−1 y˜i−p y˜i−p+1 · · · y˜i−2 y˜i−1   (10.7) Naturally, if we had access to additional, instantaneous features such as xhour and xday these would be added to the vector of attributes in eq This construction likely seem a bit abstract and we have illustrated it in fig 10.13 for three different choices of horizons and embedding sizes In a concrete application, the embedding size should be selected based on a consideration of how far into the past observations remain predictive of the presence, whereas the horizon should be selected based on what our modeling goal is',\n",
              " 'It is difficult to judge how large the embedding size should be in this example; one could argue an embedding size of 1 (i.e just the preceding time step) is relevant, or a large embedding size because commuters who took the train in the morning are likely to also use it at the end of their work day The recommendation is to begin with a small embedding size for simplicity, and use cross-validation to make informed decisions What about multiple time series In the case of multiple time series what should be done depends slightly on the specifics of the dataset If for instance the time series represents instances of the same process, but recorded in sequences with breaks in between, we recommend each section is simply processed using the pro\\ufffecedure in this section and the data is pooled at the end',\n",
              " 'Examples of different cross-validation approaches Notice each square corresponds to both (xi, yi) values transformed using the approach outlined in section 10.3.1, see fig For each approach, we only show the first 4 of the cross-validation folds If on the other hand the different time series represent the same basic phenomena, but can nevertheless be grouped into a fixed number of groups representing a (systematical) difference in the recording procedure, one could consider introducing a categorical variable such that the machine-learning method understands which type of recording is currently under consideration An example of this in the traffic-example could be if in some weeks we record the number of people at the train station using one method, and in other weeks with another, and we think these may yield systematically different estimates',\n",
              " 'The temporal dependency makes it difficult to provide a single, unique recommendation for doing cross-validation, and we will therefore suggest different approaches and their possible strengths/weaknesses An interested reader can consult Bergmeir et al [2018] and references therein for a more comprehensive discussion Consider the schemes indicated in fig In the figures, each of the N squares correspond to a training observation and label information (xi , yi), and it will be assumed these have been converted using the procedure outlines in the previous section (see fig',\n",
              " 'This means the training and test sets will overlap which in turn means we are likely to under-estimate the generalization error For that reason, it is often desirable to pad the test set by removing a set of observations on each side corresponding to the correlation length in the data, here assumed to be roughly the embedding size This is shown in the right-column of fig 10.14.186 10 Overfitting and cross-validation A few remarks are at this point in order for (possible) advantages and disadvantages of the different methods: The random and consecutive splits are likely to behave quite similar without padding, however with padding, and in particular if the dataset is very small, padding will remove proportionally more of the data for random splits (biasing the generalization error estimate up\\ufffewards)',\n",
              " 'For both the random and consecutive selections, a problem is we include the future in the training set, whereas in the real world we will train on past data and test on future The rolling method removes the future data from the splits, however, this (in turn) means we have access to less training data and will possibly bias the generalization error estimate slightly upwards 10.3.3 Two-layer cross-validation The extension to two-layer cross-validation is technically straight-forward: Simply choose one of the approaches indicated in fig 10.14 for the outer fold, and another for the inner fold Note, however, that the various biases, advantages and disadvantages of the outlined approaches might interact in undesirable ways and degree of appropriateness of a given approach is likely going to be highly problem-dependent and the estimates of the generalization error is likely to differ, especially for datasets of limited size',\n",
              " 'In the case of the traffic example, even assuming we had access to a non-trivial number of observations, it is not immediately clear that past number of passengers during a day improves predictions of the present beyond knowing the day of week and time of day 10.4 Visualizing learning curves⋆ The generalization error is such an important quantity it can be used as a qualitative pointer to model problems, here illustrated using learning curves A learning curve refers to how the perfor\\ufffemance of a given method change as a function of a key quantity or parameter We have already encountered examples of learning curves, for instance in fig 7.15 we considered a schematic illus\\ufffetration of learning as a function of computation time and in fig 1.11 we considered performance as a function of training set size In this chapter, we will try to provide an intuitive feeling for how different shapes of learning curves may point to different problems (or lack therefore) with a given method',\n",
              " 'For this reason the section is marked with a ⋆ 10.4.1 The setup We will consider a setting where we are trying to solve a supervised learning problem using a somewhat advanced method Using the techniques considered in this chapter, we can compute the10.4 Visualizing learning curves⋆ 187 Fig Illustration of good and bad learning outcomes the left-hand pane shows stereotypical be\\ufffehaviour of a good learning outcome: The training/generalization error is well below baseline performance (dotted blue line), and as more data is added the generalization error drops towards the target performance That the generalization error is higher than the training error is to be expected in a complex model and should drop with more data The right-hand pane shows a model which overfit badly The training error remains very low, but the generalization error does not budge when more data is added This is probably due to a poor model choice',\n",
              " 'In addition to these two quantities, we assume (this may be realistic or not) we have some target performance in mind (i.e the point where the method is considered useful, good enough or equivalent to state-of-the-art), as well as a baseline of some kind, for instance a linear/logistic regression Within this setup, we will plot the (estimate of) the generalization and training error as a function of the amount of training data Consider the learning curves shown in fig In the left-hand pane we see an example of a learning curve where the training error is fairly low, the generalization error is low (and falling rapidly when more data is available) This is the expected outcome for a well-applied method: The training error will, within statistical uncertainty, be lower than the generalization error, however the gab should close with more data and the error should approach target performance On the other hand, the right-hand pane of fig',\n",
              " 'The generalization error is very high (nearly corresponding to random guessing), whereas the training error is extremely low Moreover, none of these appears to budge This is because the method is overfitting the training set: The method extracts information specific to each training observation, while learning nearly nothing about the general (true) relationship in the test data This corresponds to a method which learns to identify cars by observing images of cars contain blue sky and therefore learn this relationship Moreover the curves are nearly flat, indicating adding more data will not change the situation When one encounters this behavior, the go-to suggestion is to switch to a simpler model where training does not fail These two examples provides extremes, however learning curves can, with some care, be used to diagnose other more complex problems We should here stress our warning from the introduction,188 10 Overfitting and cross-validation Fig Examples of learning curves',\n",
              " 'Middle: A bad method which is too inflexible to learn the correct relationship in the data (high training error), however the generalization error remains much higher than the training error indicating it is simultaneously overfitting Right: Example where learning seems to be converging; consider more data/tweaking and see if the generalization error sustains the drop namely that the cartoonish examples of learning curves encountered in the happy world of pedagogy, and the ones a reader will likely encounter in practice, will only be approximately similar For instance, the learning curve in fig 10.15 (left) should be compared to the (comparable) learning curve in fig 7.14 (right) obtained using logistic regression Method is too weak or misapplied In the left-hand pane of fig 10.16 we see another example of a bad outcome: the generalization error seems to have plateaued, but moreover the training error is very high',\n",
              " 'In this case one should consider if the method is applied correctly (perhaps it is not learning anything?), or consider a more flexible method Wrong method Next consider the center-pane of fig This is another bad outcome where the method is both too weak to capture the true relationship in the data (And thus, as in the previous case, we cannot expect more data will fix our problems), but the generalization error is higher than the training error, indicating some degree of overfitting The method is therefore learning too little and the little it is learning is the wrong thing Something is seriously wrong; either with the method, or with the way the training/test set is selected, and more data is unlikely to fix the problems More data and tweaking Finally consider the right-hand pane of fig In this case the training curve seems to have plateaued around the expected level of performance, whereas the generalization error seems to drop as more data is added',\n",
              " 'Question 1: Alice is considering a linear regres\\ufffesion model for a dataset comprised of N = 1000 observa\\ufffetions She wishes to both select the optimal regulariza\\ufffetion strength as well as estimate the generalization error of the model at the optimal regularization strength To simplify the problem, she only considers the following 6 possible values of the regularization strength λ: λ = 10−2 , 10−1 , 100 , 101 , 102 , 103  Alice opts for a two-level strategy in which she uses the hold-out method to estimate the generalization error and cross-validation is used to select the optimal regulariza\\ufffetion strength, i.e the dataset is first divided into a valida\\ufffetion set Dvalidation, comprised of 20% of the full dataset, and the remainder DCV is used for cross-validation',\n",
              " 'Suppose for any fixed value of the regularization strength, the time taken to train the weights of the linear regression model on a dataset of size Ntrain is N2 train units of time and the time taken to test a trained model on a dataset of size Ntest is 1 2N2 test units of time Suppose the duration of all other tasks is neglible, what is the total time taken for the entire procedure A 12.78 · 106 units of time B 15.98 · 106 units of time C 31.30 · 106 units of time D 31.96 · 106 units of time E Don’t know Question 2: We would like to fit an artificial neu\\uffferal network to the PM10 dataset shown in Table 10.5 It is decided that DAY should not be included in the model as this cannot be influenced by decision makers We therefore only consider x1, x2, x3 and x4 correspond\\ufffeing to logCAR, TEMP, WIND and TEMPDIF respec\\ufffetively An artificial neural network is applied to the data with these four attributes',\n",
              " 'Table 10.4 gives the training and test performance of the artificial neural network for different combinations of the four attributes Which one of the following statements is correct Feature(s) Training Test rmse rmse x1 0.71 0.75 x2 0.58 0.64 x3 0.60 0.62 x4 0.92 0.94 x1 and x2 0.60 0.69 x1 and x3 0.35 0.44 x1 and x4 0.52 0.66 x2 and x3 0.56 0.69 x2 and x4 0.45 0.52 x3 and x4 0.62 0.64 x1 and x2 and x3 0.36 0.34 x1 and x2 and x4 0.28 0.33 x1 and x3 and x4 0.27 0.45 x2 and x3 and x4 0.20 0.43 x1 and x2 and x3 and x4 0.10 0.35 Table 10.4 Root mean square error (rmse) for the training and test set when using an artificial neural network with three hidden units to predict the level of pollution (logPM10) based only on the first four attributes (x1–x4) using the hold-out method with 50 % of the observations hold-out for testing Attribute description Abbrev',\n",
              " '2001 y Logarithm of PM10 logPM10 concentration Table 10.5 The attributes of the PM10 data The output is given by the hourly values of the logarithm of the concentra\\ufffetion of PM10 particles (logPM10) A Neither forward nor backward selection will identify the optimal feature combination for this problem B Backward selection will result in a better model be\\ufffeing selected than using forward selection C Backward selection will use a model that include all the features x1, x2, x3, and x4 D Forward selection will select the features x1, x2 and x4 E Don’t know Question 3: Which one of the following state\\ufffements is incorrect?190 10 Overfitting and cross-validation A Cross-validation can be used to quantify a models generalization error B K-fold cross-validation requires the fitting of K mod\\ufffeels such that for K=N where N is the total number of observations K-fold cross-validation is the same as leave-one-out cross-validation',\n",
              " 'D For least squares linear regression the test error will always decrease as we include more attributes in the model E Don’t know Question 4: We would like to fit an artificial neural network (ANN) model to the Galagapos dataset shown in Table 10.7 To reduce the computational cost of fitting the models it was decided to not include Elev, i.e x4, and AreaNI, i.e x7 in the ANN models We there\\ufffefore only consider x1, x2, x5 and x6 in order to predict Area, i.e x3 An artificial neural network with three hid\\ufffeden units is applied to the data with these four attributes and trained using different combinations of the four at\\ufffetributes x1, x2, x5 and x6 Table 10.6 gives the training and test performance in terms of root mean squared error (rmse) of the ANN for different combinations of the con\\ufffesidered attributes Which one of the following statements is correct',\n",
              " 'Root mean square error (rmse) for the train\\ufffeing and test set when using an artificial neural network with three hidden units to predict the Area of an island based only on the four attributes x1, x2, x5 and x6 using the hold-out method with 40 % of the observations hold-out for testing Attribute description Abbrev x1 Number of plant species Plants x2 Number of endemic plant species E-Plants x3 Area of island (in km2 ) Area x4 Max elevation above sea-level (in m) Elev x5 Distance to nearest island (in km) DistNI x6 Distance to Santa Cruz Island (in km) StCruz x7 Area of adjacent island (in km2 ) AreaNI Table 10.7 The seven attributes of the data on a selection of 29 of the Gal´apagos islands A Neither forward nor backward selection will identify the optimal feature combination for this problem B Forward selection will result in a better model being selected than using backward selection C Backward selection will terminate at the model that includes the features x1, x2, and x6',\n",
              " 'E Don’t know Question 5: A logistic regression model was trained on Haberman’s data shown in Table 10.8 using leave-one-out cross-validation and the confusion matri\\ufffeces given in Figure 10.17 were obtained Which one of the following statements is correct Attribute description Abbrev x1 Young (< 60 years), x1 = 0 or Age Old (≥ 60 years), x1 = 1 x2 Operated before, x2 = 0 or OpT after 1960, x2 = 1 x3 Positive axillary nodes detected PAN No, x3 = 0 or Yes, x3 = 1 y Lived after 5 years Surv No, y = 0 or Yes, y = 1 Table 10.8 A modified version of Haberman’s Survival Data taken from http://archive.ics.uci.edu/ml/machine-learning\\ufffedatabases/haberman/haberman.names The attributes x1-x3 denoting the age, operation time and cancer size as well as the output denoting survival after five years are binary The data contains a total of N = 306 observations.10.4 Visualizing learning curves⋆ 191 Fig',\n",
              " 'A The error rate of the logistic regression classifier is larger than the error rate of the decision tree classi\\ufffefier B Predicting every observation to be in the died class would give a better accuracy than the accuracy ob\\ufffetained by the decision tree classifier C The classification problem does not have any issues of imbalanced classes D Using leave-one-out cross validation a total of 306 − 1 = 305 logistic regression models are trained E Don’t know Question 6: Suppose a neural network is trained on input/output pairs (xi , yi) on a dataset of N = 5 observations The response of the neural network for in\\ufffeput xi is denoted as ˆyi and the values can be seen in table 10.9 i yi yˆi 1 1 0.6 2 0 0.4 3 1 0.5 4 1 0.1 5 0 0.1 Table 10.9',\n",
              " 'A θ = 0.35 B θ = 0.45 C θ = 0.55 D θ = 0.65 E Don’t know Question 7: Which one of the following state\\ufffements pertaining to cross-validation is correct A 2-fold cross-validation is the same as the hold-out method when 50% is hold out B For datasets with very few observations it is in general better to use leave-one-out cross-validation rather than 10-fold cross-validation C Two levels of cross-validation is necessary in order to determine the optimal set of parameters for a model D Leave-one-out cross validation is the most computa\\ufffetional efficient procedure as only one observation is in the test set at a time E Don’t know Question 8: Consider a system which attempts to classify observations based on the value of four ob\\ufffeserved features x1, x2, x3, x4 Suppose we wish to exam\\ufffeine which subset of features gives the least misclassified observations on test data',\n",
              " 'Which of the following statements is true Feature(s) Ctrain Ctest None 30 69 x1 43 70 x2 14 50 x3 41 76 x4 18 81 x1, x2 59 73 x1, x3 34 59 x1, x4 15 32 x2, x3 18 58 x2, x4 23 36 x3, x4 26 33 x1, x2, x3 17 40 x1, x2, x4 37 54 x1, x3, x4 7 15 x2, x3, x4 27 34 x1, x2, x3, x4 17 25 Table 10.10 Number of misclassified training observations Ctrain and test observations Ctest for a neural network model trained on different sets of features Lower is better.192 10 Overfitting and cross-validation A Forward and backward selection will select the same set of features B Forward selection will select a model with higher mis\\ufffeclassification rate on the test set than backward se\\ufffelection C Forward selection will select a model with lower mis\\ufffeclassification rate on the test set than backward se\\ufffelection D Forward selection will select the features x1, x3, x4 E Don’t know.11 Performance evaluation In the past sections, we have seen several methods for making predictions on data',\n",
              " 'Statistical tests provides such a method, and this chapter will supply the reader with tools for solving most common model comparison problems The main source of difficulty as a user of statistics is how to match a particular problem to a statistical test The main distinction is whether we are willing to accept our conclusions are conditional on our particular dataset (this will be called setup I) or we want our conclusions to remain valid when using another dataset generated by the same mechanism (this will be called setup II) We have devoted section 11.1 to clarifying this distinction and providing an overview of the tests as well as concrete advice on when to use which We will assume the reader is familiar with basic statistical concepts such as p-values and confi\\ufffedence intervals, and our brief recap in section 11.2 is only intended to introduce our notation The chapter, along with the choice of tests and approach, is inspired by Dietterich [1998]',\n",
              " '11.1 Statistical testing for machine learning Consider the simplest setup in which we are given two models MA and MB and we wish to know if one of the models is better than the other As we learned in chapter 10, the preferable model is the one which is better at predicting future data, which we measure by the generalization error It is at this point necessary to make an important distinction, namely whether our conclusions should be valid for models trained only on the training data we have available, or if our conclusions should generalize to a new training data we might encounter in the future (from the same data population) To illustrate this distinction, consider a classification problem where the goal is to determine the chance a person will experience post-surgical complications, and we must accomplish this with our available dataset D consisting of N observations',\n",
              " 'Accordingly, we train our models on our available datasets D194 11 Performance evaluation and obtain two prediction rules: fD,A, and fD,B The subscript is used to clarify that these rules depend on the data they are trained on The problem of determining which model is better is therefore simply to examine the difference in their generalization error zD defined as zD = E gen D,A − E gen D,B (11.1) where: E gen D,A = Z p(x, y)L(fD,A(x), y)dxdy, Egen D,B = Z p(x, y)L(fD,B(x), y)dxdy (11.2) In practice, we cannot compute the generalization errors exactly, but can only hope to estimate them using cross validation as described in chapter 10 To avoid complicating things, let’s assume we have a test set Dtest available, in which case we can estimate the difference in generalization errors as: zˆD = 1 Ntest N Xtest i=1 [L(fD,A(xi), yi) − L(fD,B(xi), yi)] = 1 Ntest N Xtest i=1 zi , where: zi = L(fD,A(xi), yi) − L(fD,B(xi), yi) (11.3) Statistics allow us to use the numbers z1,',\n",
              " 'Crucially, since zD depends on the specific dataset D, so will our statistical conclusions We will denote this general problem, where we consider the training set D as fixed and condition our conclusions on this dataset, by setup I in the following: Setup I Statistical tests of performance considering the specific training set D Returning to the post-surgical example, the conclusions we might arrive at under setup I therefore have to be stated conditional on D We might (for instance) find model MA is significantly better than MB, but our conclusion can only be said to have been tested (and therefore, be valid) in the case the models are trained on D Section 11.3 addresses typical questions under this heading for both classification and regression: Section 11.3.2: Estimate plausible values of the generalization error E gen D defined in eq',\n",
              " 'For instance, if a research group at another hospital tried to independently replicate our results, then even though they followed our exact protocols and collected data from the same population of patients, they would end up with another dataset D′ , and they might not reach the same conclusion as us.11.2 Statistical primer⋆ 195 Obviously, in many cases we want to know if our conclusions can actually be independently reproduced by other researchers We can give this a technical formulation by saying that assuming our dataset D came from some distribution D ∼ p0(·) Then we want our conclusions to be valid for a comparable dataset D′ of the same size generated according to the same distribution D′ ∼ p0(·): Setup II Statistical tests of performance considering a dataset of size N We will outline statistical methods that attempts to address this problem for both classification and regression models in section 11.4 Which setup should I choose',\n",
              " 'On the other hand, since setup II is more general it is also more difficult to confirm What this means is that it will typically requires more computations, a bigger performance gap between the models, and more data in order for us to demonstrate an effect, assuming there is a difference between the model Our overall recommendation is therefore that a reader has a preference towards setup II and considers setup I in the following cases: \\x88 It might be the case the problem has a clearly defined training/test set other researchers are testing on as well In this case the training set is fixed and the methods in setup I are applicable \\x88 There is so little data the methods for setup II are unfeasible \\x88 A company could argue they only care about performance on their specific training set \\x88 It is too computationally expensive to train multiple models 11.2 Statistical primer⋆ To avoid confusion with machine-learning concepts, we will write the data that enters into our statistical test as D',\n",
              " '(11.3) from the previous section we estimated the difference in model performance as: ˆθ = 1 n Xn i=1 zi  (11.4) In this case the data is simply the n numbers: D = (z1,  (11.5) Generally speaking, the problem statistics is concerned with is how we can use the n numbers in D to draw conclusions about the true value of the difference in generalization error θ = E gen A,D − E gen B,D There are two major categories of statistical inference:196 11 Performance evaluation Hypothesis testing How to use a finite sample D to answer a binary question such as whether θ = 0 We will use hypothesis testing and p-values for this task Estimation How to use a finite sample D to find a plausible range of values the true value of the generalization error is likely to fall within We will use confidence intervals for this task',\n",
              " 'We therefore recommend the emphasis is placed on computing (and discussing) confidence intervals in a results section, and that p-values are used secondarily Parameter In statistics, the dataset D is assumed to be a random sample from a population Specifically, we assume each observation zi in D is a realization of a random variable Zi , which follows a distribution that depends on the parameter θ and has density p(Zi = zi |θ) = pθ(zi) The goal of statistics is to use a concrete, observed dataset D = (z1,  , zn) to draw conclusions about θ, which is why we use the abbreviation pθ to signify the special role of θ Note that by the product rule the density of the full dataset is simply pθ(D) = Yn i=1 pθ(zi) (11.6) Statistics makes the assumption the dataset was generated from this distribution using a specific value of θ, and the goal of statics is to make reasonable statements about this value using the dataset D',\n",
              " 'What distribution we use in place of pθ is a crucial choice, and using the wrong distribution is guaranteed to lead to troubles In other words, statistics assume we know enough about our data to make this choice Statistic A statistic is a function of the data D and will be denoted t For instance, the mean and variance are both statistics: t0(D) = 1 n Xn i=1 Zi , or t1(D) = 1 n Xn i=1 (Zi − t0(D))2  Estimator Estimation is concerned with finding a statistic t of D such that t(D) is close to θ, and in this case t is called an estimator of θ In the examples we will consider the mean t0(D) = 1 n Xn i=1 Zi will be a good estimator for θ If n is low the estimator is relatively unreliable, whereas if n is large it will converge to the true value.11.2 Statistical primer⋆ 197 Confidence interval An estimator t(D) of the parameter θ is just a single number and provides no information about the relative accuracy',\n",
              " 'Obviously, such an interval has to be a function of the data D, in other words, θL and θU are two statistics and for a concrete dataset the interval is computed to be [θL(D), θU (D)] (11.7) Specifically, the main property of a confidence interval is that with a probability of 1 − α, the true value θ should fall within the confidence interval [θL(D), θU (D)] as we randomize over different datasets generated from our distributional assumption pθ(D) in eq Symbolically, this is written as Pθ(θ ∈ [θL, θU ]) = 1 − α (11.8) The number α denotes a margin of error we are willing to tolerate: If α is close to 0, the CI will be very wide and very likely to contain the true value θ On the other hand if α is larger, the CI is more narrow and more likely to not contain θ Therefore, the functions θL and θU have to depend on both D and α Since this definition is quite technical, we have provided a mechanical description in Box 11.2.1',\n",
              " ', DS distributed as pθ=θ0 \\x88 For each dataset Dk , we compute the confidence interval [θL(Dk ), θU (Dk )] \\x88 Of all these S intervals, a fraction 1 − α will contain θ0 Hypothesis The other category of statistical inference is hypothesis testing Hypothesis testing is concerned with whether a specific hypothesis H0 about the true parameter θ is true or false Examples could be testing whether θ takes a particular value such as 0 H0 : θ = 0 For a given hypothesis H0, we denote by H1 the negation of H0 In our example, H1 corresponds to θ ̸= 0 Insofar as the mathematics concerned, we could just as well let H0 be θ ̸= 0 and H1 be θ = 0, however, it is customary to let H0 correspond to the case of no difference or no effect, i.e what we as scientists would typically want to disprove in order to confirm some hypothesis under question',\n",
              " 'One intuition is that if the data seems implausible under our hypothesis H0, we should doubt it Let’s make this concrete Suppose once more we consider a hypothesis of the form H0 : θ = θ0 for some particular value of θ0 For our concrete, observed dataset D define t0 = t(D) where t is some statistic In the cases we will consider, the statistic of interest is an estimator of θ and accordingly: t0 = t(D) = 1 n Xn i=1 zi If H0 is true, we know θ = θ0, and so we know the distribution pθ(D) From this, we can work out the probability t(D) takes a particular value to be: p(t(D) = t|H0) = pθ=θ0 (t(D) = t) Although the details will require some algebra The statistics t(D), when used for null hypothesis testing, is known as the test statistic We can now formalize the notation of observing a more extreme value of t(D) to be the chance t(D) ≥ |t0| – the absolute value takes into account extreme can both mean extremely small or extremely large',\n",
              " '(11.9) Example 11.2.1: p-value in the simplest case⋆ Suppose the distribution of our dataset in eq (11.6) is simply a normal distribution with unknown mean θ and known variance σ 2 0 : pθ(zi) = N (zi |µ = θ, σ2 = σ 2 0 ) (11.10) In this case, assuming H0 is true such that θ = 0, it is possible to show that the mean t(D) = 1 n Pn i=1 zi is distributed as pθ(t(D) = t|H0) = N \\x12 t|µ = 0, σ2 = σ 2 0 n \\x13  (11.11) (c.f Petersen et al [2008, section 8.1.4]) We can now compute the p-value using the cumu\\ufffelative density function of a normal distribution as: Pθ(t(D) > |t0||H0) = Z −|t0| −∞ p(t(D) = t|H0)dt + Z ∞ |t0| p(t(D) = t|H0)dt = 2cdfN \\x12 −|t0|         µ = 0, σ2 = σ 2 0 n \\x13 .11.2 Statistical primer⋆ 199 In other words, the p-value captures how unlikely it is to observe a value at least as extreme as the concrete value t0 given H0 is true, with the intuition that the more unlikely our observed obser\\ufffevations are, the more reason we have to doubt H0',\n",
              " 'Statistical significance Since the lower the p-value is the more reason there is to doubt H0, it is customary to specify a significance level α, such as α = 0.05, and say that if p falls below this threshold we reject H0 (and say our test showed a significant result), and otherwise we fail to reject H0 (and our test did not show a significant result) The technical language (reject and fail to reject) is used to emphasize a significant result, or a low p-value in general, is not the same as demonstrating a research hypothesis is true When we obtain a p-value, what we strictly speaking can conclude is our data is rare or surprising assuming H0 is true There can be different reasons for this, for instance that H0 is actually false, or it could be our data simply violates our statistical assumptions Technical note 11.2.2: Understanding p-values Suppose we consider the hypothesis H0 : θ = 0 (versus H1 : θ ̸= 0) and assume our concrete, observed dataset is D = (z1,',\n",
              " 'If we find this value t0 has a p-value of p = 0.03 it means that: \\x88 If we generate a large number S of datasets D1 ,  , DS generated under the assumption H0 is true, i.e., distributed as pθ=0(D) \\x88 For each dataset Ds , we compute the static t(Ds ) t s 0 = 1 n Xn i=1 t(Ds ) = 1 n Xn i=1 z s i \\x88 Then out of these S numbers, only a fraction of p = 0.03 will be more extreme than t0, i.e satisfy t s 0 ≥ |t0| or t s 0 ≤ −|t0| In other words, the p-value expresses the relative rarity of our observed statistic t0 under the assumption H0 is true 11.2.1 Baselines When assessing the results of a particular machine-learning method, it is often useful to compare it against a very simple model which can be implemented at a minimum of effort to demonstrate the200 11 Performance evaluation model is doing something useful at all Such a model is commonly denoted a baseline model',\n",
              " '(11.12) And for classification, a reasonable baseline is one which computes the number of observations nc = PNtrain i=1 δy train i ,c assigned to class c for c = 1,  , C and then always outputs the class with the most members: fbaseline(x) = c ∗ , c∗ = arg max c {n1,  (11.13) As the notation indicate, it is important the baseline models are treated as regular models they are trained on the training sets, and later they are evaluated on the test sets Note the baseline model does not use any of the features x Therefore, if your model is unable to outperform the baseline, it means it does not make meaningful use of the features This can either be because your model is implemented wrong, it is unsuited for the task, or because there is a serious data quality issue 11.3 Setup I: the training set is fixed Recall once more D is our full dataset of N observations',\n",
              " '(11.3), we will approximate the generalization error using a test set This can be done using one of the three forms of cross-validation from chapter 10 Since we do not want to confuse this choice with the test, we will first introduce general notation which will allow us to apply our tests to any form of cross-validation 11.3.1 Translating to a statistical test Both leave-one-out, K-fold and hold out cross validation can be seen as splitting the dataset D into training/test pairs: (D train 1 , D test 1 ),  ,(D train K , D test K ) (11.15) where D = Dtrain k ∪ Dtest k  In case of leave-one-out cross-validation K = N, and in case of hold-out K = 1 (as there is only one training and test set) The next step is to train the model on each of the K training sets and produce predictions on the K test sets If we denote the predictions of model k on Dtest k with yˆk , we obtain the prediction vector:11.3 Setup I: the training set is fixed 201 yˆ = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8f0 yˆ1 yˆ2  yˆK \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fb',\n",
              " 'Finally, we define: zi = L(ˆyi , yi), for i = 1,  (11.17) These n numbers will be the input to our statistical test The loss L depends on the application In case we are evaluating a regression model, we might choose either the squared loss or the L1 loss, i.e select: L(ˆyi , yi) = (ˆyi − yi) 2 or L(ˆyi , yi) = |yˆi − yi | (11.18) In case the model is a classifier, the loss L will correspond to the error rate L(ˆyi , yi) = ( 0 if ˆyi = yi 1 if otherwise (11.19) Using eq (11.17), we can estimate the generalization error eq (11.14) as E gen = Z p(x, y)L(fD(x), y)dxdy ≈ 1 n Xn i=1 zi  (11.20) Technical note 11.3.1: What happened to fD The observant reader will note a slight point of irritation The generalization error relevant for setup I, see eq',\n",
              " ', fDtrain K  This is annoying but not critical Under normal circumstances, we would expect our model to perform a little poorer when trained on less data and therefore, that our estimates of Egen to overshoot a little Insofar this has an effect we are erring on the side of caution This consideration suggests an optimal choice of cross-validation for setup I: leave-one-out, as in this case the models we are averaging should be as similar to fD as possible Note this conclusion does not hold for setup II 11.3.2 First task: Evaluation of a single classifier For classifiers, we are interested in estimating the accuracy Therefore, in this section and sec\\ufffetion 11.3.3 assume yˆ = ˆy1,  , yˆn has been computed using a form of cross-validation as in eq (11.16), and then define ci as whether the prediction for observation i was correct or not: ci = ( 1 if ˆyi = yi 0 if otherwise (11.21)202 11 Performance evaluation 0 0.2 0.4 0.6 0.8 1 0 0.5 1 1.5 2 2.5 0 0.2 0.4 0.6 0.8 1 0 2 4 6 8 Fig',\n",
              " 'The confidence interval corresponds to the area where (under the model assumptions) we can expect θ to be with probability 1 − α = 95% (note this is closely related to the loss since zi = 1 − ci) How good a classifier is only depends on n and the number of times it made the correct prediction which can be computed as m = Xn i=1 ci  Assuming θ is the (unknown) probability the model correctly classifies each observation, what we are trying to learn is p(θ|m, n) This problem is exactly equal to the Bernoulli coin we encountered in section 6.4 where θ is the chance a coin comes up heads, m the number of times it came up head and N the number of flips For technical reasons1 , we will choose a Beta(θ|α = 1 2 , β = 1 2 ) distribution as prior for θ This prior is known as the Jeffrey prior If we simply accept this choice, we can re-use the derivation in Technical Note 6.4.1 Using α = β = 1 2 in eq',\n",
              " '(11.22) Returning to our problem of interest, deriving the confidence interval, we can at this point simply observe that eq (11.22) provides a formula for the posterior distribution Using the definition in section 6.3.4 the cdf defined in eq (6.20) is simply 1 The motivation for this prior has to do with invariance under re-parameterization, somewhat similar to how a Gaussian with identity covariance matrix looks the same if the coordinate system is rotated An interested reader can consult Jeffreys [1946] or Jaynes [1968] for further details An intuitive interpretation of the difference is if we recall our interpretation of α and β as pseudo-counts, we may say this prior is less informed than α = β = 1 as it corresponds to one less pseudo-observation.11.3 Setup I: the training set is fixed 203 Table 11.1 Intermediate computation and credibility interval for the example in fig',\n",
              " '(6.26), can be computed as: θL = cdf−1 B \\x10α 2       a, b\\x11 (11.23) θU = cdf−1 B \\x10 1 − α 2       a, b\\x11 where: a = m + 1 2 and b = n − m + 1 2  (11.24) The method is summarized in Box 11.3.1 and the reader is referred to Example 11.3.1 for an illustration Method 11.3.1: Jeffreys interval \\x88 Select a form of cross-validation \\x88 Obtain n predictions ˆy1,  , yˆn using eq (11.16) \\x88 Let m = Pn i=1 ci be the number of times the classifiers prediction is correct \\x88 The 1−α confidence interval [θL, θU ] is now obtained by first computing a = m + 1 2 and b = N − m + 1 2 and then: θL = cdf−1 B \\x10α 2 |a, b\\x11 if m > 0 otherwise θL = 0 (11.25a) θU = cdf−1 B \\x10 1 − α 2 |a, b\\x11 if m < n otherwise θU = 1 (11.25b) Report results as follows: A point estimate of the accuracy of the classifier is ˆθ = a a+b , and an α = 0.95 Jeffreys interval is given as [θL, θU ] 2 Special functions to evaluate cdf−1 B are build into all popular mathematical environments',\n",
              " 'Illustration of the reproducibility of statistical results We fix the true accuracy of a classifier to θ = 0.7, and then test it on 100 datasets where on each dataset we compute the α = 0.95 confidence interval Therefore, each of these 100 results are independent examples of what we could actually measure for a classifier with an error rate 0.7 Example 11.3.1: Credibility interval of a single classifier Let’s turn to how this looks in practice Suppose the true accuracy of a classifier is θ = 0.7 and we consider two situations: In one we observe n = 8 and m = Pn i=1 zi = 6, and in the other n = 100 and m = 67 In both cases we compute the 95% Jeffreys interval using eq The intermediate calculations can be found in table 11.1 and the posterior curve of θ is illustrated in fig We see the true value of θ = 0.7 lies within both intervals, as we would expect 95% of the time',\n",
              " 'Suppose we keep the true accuracy of the classifier at θ = 0.7, generate 100 random test datasets of size n = 100, and then test it on 100 datasets where on each dataset we compute the α = 0.95 confidence interval The result of this procedure is shown in fig In other words, each of these 100 results are an example of what we could actually measure for a classifier with accuracy rate 0.7 Importantly, note about 5% exclude the true value as we would expect, and there is a significant variability in these results Note this variability reflect the “best case” scenario because there is no variability in the true error rate θ, and illustrates why a great deal of care must be taken to conclude one model is better than another when using a small test set 11.3.3 Comparing two classifiers In this example, we have two classifiers MA and MB, and we want to know if one is better than another',\n",
              " '(11.15), then train (and test) both models on the same splits (why will be apparent in a moment) and thereby obtain, for each of the models, n predictions as well as the true class labels y: yˆ A = ˆy A 1 ,  , yˆ A n , yˆ B = ˆy B 1 ,  Given these, define c A i and c B i as in eq (11.21)11.3 Setup I: the training set is fixed 205 c A i = ( 1 if ˆy A i = yi 0 if otherwise and c B i = ( 1 if ˆy B i = yi 0 if otherwise (11.26) The first step is to form the 2 × 2 matched-pair matrix with entries: n11 = Xn i=1 c A i c B i = {Both classifiers are correct} (11.27a) n12 = Xn k=1 c A i (1 − c B i ) = {A is correct, B is wrong} (11.27b) n21 = Xn k=1 (1 − c A i )c B i = {A is wrong, B is correct} (11.27c) n22 = Xn k=1 (1 − c A i )(1 − c B i ) = {Both classifiers are wrong} (11.27d) What matters when comparing two classifiers is not the case where both classifiers are either both correct or incorrect as this might simply indicate an observation is either trivial to classify or impossibly hard',\n",
              " 'Therefore, we should take it as evidence that A is better than B when n12 > n21 To test this statistically, we will use what is known as McNemars test [Altham, 1971] Note that if n12 > n21, this is equivalent to whether rˆ = n12 n12 + n21 > 1 2  This inspired the following idea: First, we let pij be the probability that a random pair of observa\\ufffetions z A k , zB k will count towards nij  Note that X 2 i=1 X 2 j=1 pij = 1 What we want to test the null hypothesis which is if p12 = p21 or equivalently if r = p12 p12 + p21 = 1 2  (11.28) A p-value from McNemar’s test To turn this into a p-value, we first need an expression for the probability of our data given our parameter of interest r Letting s = n12 + n21 this can be shown to be [Altham, 1971]: p(n12, n21|s) = \\x12 s n12\\x13 r n12 (1 − r) n21 = pBinom(n12|θ = r, N = s) (11.29) where we have used the binomial distribution from eq',\n",
              " '(11.30b) Recall the definition of p-value from eq (11.9) is defined as the probability of observing a value of n12 and n21 more extreme, i.e unlikely, than the one actually observed assuming H0 is true, that is, r = 1 2  In this case, since pBinom \\ufffe n12     θ = 1 2 , N = n12 + n21\\x01 = pBinom \\ufffe n21     θ = 1 2 , N = n12 + n21\\x01 , we can consider m = min{n12, n21} as the more extreme value and find the p-value to be: p = P(N12 ≤ m|H0) + P(N21 ≤ m|H0) = 2cdfbinom(m|θ = 1 2 , N = n12 + n21) (11.31) Where we have used the binomial cumulative distribution function: cdfbinom(m|θ, N) = Xm k=0 pbinom(k|θ, N) (11.32) A confidence interval for McNemar’s test While p-value are useful to get an indication if one classifier is better than another they are less useful for determining a plausible interval of their performance difference In other words, let θA denote the (true) chance classifier MA is correct and θB the (true) chance classifier MB is correct',\n",
              " 'One idea for creating a confidence interval is to derive a (reasonable) expression for the posterior similar to the Jeffreys interval An exact expression is given by Bloch et al [1967], however this expression is rather complicated and a reasonably accurate approximation is p(θ|n) = 1 2 Beta \\x12 θ + 1 2         α = f, β = g \\x13 (11.33a) f = Eθ + 1 2 (Q − 1) (11.33b) g = 1 − Eθ 2 (Q − 1) (11.33c) Eθ = n12 − n21 n , Q = n 2 (n + 1)(Eθ + 1)(1 − Eθ) n(n12 + n21) − (n12 − n21) 2  (11.33d) For this approximation to be sensible we recommend that n12 + n21 ≥ 5 From this, we can obtain a 1 − α confidence interval for θ ′ = θ+1 2 using cdf−1 B \\ufffe α 2     f, g\\x01 , and transform this into a 1 − α confidence interval for θ by observing θ = 2θ ′ − 1 The test i summarized in Box 11.3\\x00\\x00\\x0011.3 Setup I: the training set is fixed 207 Method 11.3.2: The McNemar test for comparing classifiers Our goal is to compare two classifiers A and B',\n",
              " ', yˆ A n and ˆy B 1 ,  , yˆ B n from the classifiers by evaluating them on the same cross-validation splits \\x88 Compute the matrix n using eq (11.27) To estimate the performance difference: \\x88 The estimated difference in accuracy of A and B, θ = θA − θB, is given as ˆθ = n12 − n21 n (11.34) \\x88 An approximate 1 − α confidence interval [θL, θU ] for θ can be obtained as θL = 2cdf−1 B \\x10α 2       α = f, β = g \\x11 − 1 (11.35a) θU = 2cdf−1 B \\x10 1 − α 2       α = f, β = g \\x11 − 1 (11.35b) where f, g are computed using eq For this interval to be useful we require n12 + n21 ≥ 5 To test if they have different performance: \\x88 Let H0 be the null hypothesis they have the same performance \\x88 Compute the p-value using the cumulative distribution function of the binomial distri\\ufffebution as in eq',\n",
              " '11.3.4 McNemars test and small datasets⋆ In this section we investigate the McNemar test on small datasets similar to Example 11.3.1 Recall H0 corresponds to no-effect, i.e that the two classifiers have the same performance We simulate 10 000 datasets where the classifiers have the same performance3 and, for different values of α, we check if the 1−α CI (eq (11.35)) does not contain 0 (which would usually signify an effect) as well 3 For those curious, a dataset of size N was obtained by generating θ0,  from a uniform distribution, then letting the true value be yi belong to the positive class if θi < 1 2 and the predictions of classifier ˆy A i (and ˆy B i ) be a random Bernoulli variable with parameter θi208 11 Performance evaluation as whether the p-values (eq (11.36)) is less than α (which would also indicate an effect) In other words, we plot the number of false positives (false rejections of H0) The result is shown in fig 11.3 for N = 20, 60, 120, and 1000',\n",
              " 'False rejections of H0, i.e false claims of a difference in classifier performance, as computed using the 1 − α McNemar CI as well as the fraction of times p < α The McNemar CI is generally more accurate but also more prone to false positives We would expect (or rather hope) that these follow the diagonal straight line y = x since the 1−α confidence interval should exactly falsely reject H0 a fraction α of the time Observations above the diagonal therefore indicates the test is too lenient, and below the diagonal it is conservative From the figure we conclude the CI is generally quite accurate when N is modestly large but somewhat11.3 Setup I: the training set is fixed 209 prone to a higher number of false positives than expected relative to the p-value We also see the somewhat paradoxical situation where the 1 − α CI excludes 0 but the p-value is less than α is not that unusual for low N This can occur because the CI and the p-value are based on slightly different assumptions',\n",
              " 'Generally this highlights that different tests give different results and, when N is fairly low, indicates the McNemar CI is perhaps best suited for determining a (potential) effect size while the p-value is better suited for determining an effect, as one should expect to err on the side of caution (but nevertheless err a fraction α of the times!) 11.3.5 Estimating the generalization error of a regression model For a regression model, we once more use cross-validation to compute n predictions yˆ as in eq (11.16), and then use either the L1 or squared loss to compute z1,  , zn as in eq (11.18): zi = |yˆi − yi | or zi = (ˆyi − yi) 2 (11.37) As usual, we are interested in a confidence interval of the estimated generalization error zˆ = 1 n Xn i=1 zi  (11.38) To accomplish this, we treat the true value of the mean of the observations Z = 1 n Pn i=1 Zi as a random quantity',\n",
              " 'Hence: p(zi |Z = u, σ2 ) = N (zi |µ = u, σ2 ) (11.39) It follows the distribution of the entire dataset is: p(D|u, σ2 ) = Yn i=1 N (zi |u, σ2 ) We will at this point omit some steps, but it is possible to show under natural assumptions that u is distributed as a student-t distribution: p(u|D) = pT (u|ν = n − 1, µ = ˆz, σ = ˜σ) (11.40) with parameters ˆz = 1 n Pn i=1 zi and ˜σ = qPn i=1 (zi−zˆ) 2 n(n−1)  The Student’s t-distribution has density Student t-distribution pT (x|ν, µ, σ) = Γ \\ufffe ν+1 2 \\x01 Γ \\ufffe ν 2 \\x01 √ πνσ2   1 + 1 ν \\x14 x − µ σ \\x152 !− ν+1 2  (11.41) Since we have found an expression for p(u|D), we can use the cumulative distribution function of the student’s t-distribution to obtain a confidence interval If we denote this by cdf −1 st (A|ν, z, ˆ σ˜) 4 we can write up the confidence interval corresponding to eq (6.26) as [zL, zU ] where 4 Special functions to evaluate cdf−1 st (A|ν, z, ˆ σ˜) are build into all popular mathematical environments',\n",
              " '(11.42) Obviously, we should at this point be quite worried about the normality assumption in eq What happens if this assumption is violated In this case, the test is inaccurate for small values of n, but will in general hold when n is appreciably large, see comments in Technical Note 11.3.2 The full procedure is described is summarized in Box 11.3.3 Method 11.3.3: A central limit theorem-based interval for a regression model \\x88 Select a form of cross-validation \\x88 Compute z1,  , zn as in eq (11.37) \\x88 The 1 − α confidence interval [zL, zU ] for Egen is now obtained as zL = cdf−1 T \\x10α 2       ν = n − 1, µ = ˆz, σ = ˜σ \\x11 (11.43a) zU = cdf−1 T \\x10 1 − α 2       ν = n − 1, µ = ˆz, σ = ˜σ \\x11 (11.43b) zˆ = 1 n Xn i=1 zi , σ˜ 2 = 1 n(n − 1) Xn i=1 (zi − zˆ) 2  (11.43c) \\x88 Unless it is known the errors zi are normally distributed (and this cannot be assumed), this approach depends on the central limit theorem',\n",
              " 'We recommend n ≥ 30 If these conditions are satisfied report the results as follows: The estimated generalization error, computed using the L1 (or L2) loss, is given as ˆz and since n is large we computed a confidence interval based on the student-t distribution with parameters µ = ˆz and variance σ 2 = ˜σ 2  Based on this approximation, a 1 − α confidence interval is [zL, zU ].11.3 Setup I: the training set is fixed 211 Technical note 11.3.2: Comment on normality assumption If the values zi in eq (11.38) are not normally distributed as assumed in eq (11.39), we can still use that Z = 1 n Xn i=1 Zi  (11.44) is an average of n independent random variables We therefore know according to the central limit theorem (see eq (6.30)) that for high n, the mean Z = u is approximately normally distributed with parameters defined from the mean, variance of any one of the Zi ’s : u ∼ N \\x12 µ = E[Zi ], σ2 = 1 n Var[Zi ] \\x13',\n",
              " 'Therefore u ∼ N \\x12 µ = ˆz, σ2 = sˆ 2 0 n \\x13 , sˆ 2 0 = 1 n − 1 Xn i=1 (zi − zˆ) 2  (11.46) This result might appear different from the student-t distribution we obtained in eq (11.40), but note that when ν is large, the student-t distribution converge to the normal distribution: limν→∞ pT (x|ν, µ, σ) = N (x|µ, σ2 ) Hence, if n is appreciably large (and usually n ≥ 30 is sufficient) the student-t result will be a accurate even when the observations are not normally distributed 11.3.6 Comparing two regression models To compare two regression models MA and MB, we once more assume a form of cross-validation has been applied to obtain K train/test splits, and the two regression models are trained on the same splits to produce n paired predictions as in eq (11.16) yˆ A 1 ,  , yˆ A n , and ˆy B 1 ,  (11.47) Given these, and the true values y1,  , yn, we once more select a loss-function to compute the per-observation losses as in eq (11.18) z A 1 ,  , zA n , and z B 1 ,',\n",
              " '−   1 n Xn i=1 z B i  = 1 n Xn i=1 zi , where zi = z A i − z B i (11.48) Therefore, with z1,  , zn defined as above, we can re-use the derivations from eq (11.38) to eq (11.40) to find that the distribution of the mean Z = 1 n Pn i=1 Zi has density given by a student-t distribution p(Z = u|D) = pT (u|ν = n − 1, µ = ˆz, σ = ˜σ) (11.49a) zˆ = 1 n Xn i=1 zi , σ˜ 2 = Xn i=1 (zi − zˆ) 2 n(n − 1) (11.49b) The credibility interval of the performance difference is therefore simply eq (11.42), and a p-value of the null-hypothesis versus the alternative hypothesis H0 : Model MA and MB have the same performance, Z = 0 (11.50a) H1 : Model MA and MB have different performance, Z ̸= 0 (11.50b) can be computed as an integral of eq (11.49a) p = P (Z ≥ |zˆ| | H0) = 2 Z −|zˆ| −∞ pT (z | ν = n − 1, µ = 0, σ = ˜σ) dz = 2cdfT (−|zˆ| | ν = n − 1, µ = 0, σ = ˜σ)',\n",
              " ', n as computed using either absolute or squared loss \\x88 Define zi = z A i − z B i \\x88 The 1 − α confidence interval [zL, zU ] for Egen is now obtained as zL = cdf−1 T \\x10α 2       ν = n − 1, µ = ˆz, σ = ˜σ \\x11 (11.52a) zU = cdf−1 T \\x10 1 − α 2       ν = n − 1, µ = ˆz, σ = ˜σ \\x11 (11.52b) zˆ = 1 n Xn i=1 zi , σ˜ 2 = 1 n(n − 1) Xn i=1 (zi − zˆ) 2  (11.52c) \\x88 A p-value for the null hypothesis the two models have the same performance, Z = 0, is obtained as p = 2cdfT (−|zˆ| | ν = n − 1, µ = 0, σ = ˜σ) (11.53) \\x88 Unless the zi ’s are known to be normally distributed, and they usually are not, this approach depends on the central limit theorem and should only be applied when n is appreciably large We recommend n ≥ 30',\n",
              " 'Based on this approximation, a 1 − α confidence interval is [zL, zU ] 11.4 Setup II: The training set is random⋆ The previous methods have all been concerned with estimating the generalization error of a model when trained on a specific training set This is most notably true with the hold-out method, in which we split our data into Dtrain and Dtest and then evaluate the model trained on Dtrain on the n = Ntest observations in Dtest Note however that even if we could evaluate the models performance exactly, for instance if we had an unlimited amount of test-data, we would still fail to capture a significant source of variability, namely what happens when we train a model on a different training set In other words, we now consider the generalization error E gen = Z \\x14Z L(fDtrain (x), y)dxdy\\x15 dD train (11.54) Where the outer integral should be understood as integrating over training sets of size N and fDtrain is the prediction rule obtained when training M on Dtrain',\n",
              " 'However, in many appli\\ufffecations we want to know how well our method can be re-produced by another group who have their214 11 Performance evaluation own training set In other words, we are in setup II, where we also wish to include the variability in model performance from different training sets in our statistical estimates 11.4.1 A problem This is in a sense quite simple: Suppose we have a large number J of independent training/test splits (D train 1 , D test 1 ),  ,(D train J , D test J ) (11.55) If we train J models on these training sets, we can estimate each of the models generalization error as usual E gen j = Z L(fDtrain j (x), y)dxdy ≈ 1 nj Xnj i=1 L(fDtrain j (x j i ), y j i ), nj = |Dtrain j | (11.56) and finally obtain an estimate of eq (11.54) by averaging these over training sets: E gen ≈ 1 J X J j=1 E gen j',\n",
              " '(11.57) of the generalization error eq (11.54) is therefore a simple average of normally distributed variables There is, however, an important problem as pointed out by Bengio and Grandvalet [2004] Normally, we would obtain the training/test datasets eq (11.55) using a cross-validation procedure, however if we do so the training set Dtrain j will in general overlap, and by a sizable fraction K−2 K , with any other training set Dtrain i , i ̸= j Therefore, the trained models will not be independent, and we do not have J independent estimates of eq To re-iterate what the issue is: There are three sources of variance/covariance in the problem: 1 The variance on a prediction on a single observation when we randomize over the observation and the training set The covariance between losses of two observations due to being trained on the same set, and the final is the covariance induced by 3',\n",
              " 'While this result might preclude us from choosing an optimal solution, it does not prevent us from choosing a solution better than simply ignoring the problem One such approach was given by Nadeau and Bengio [2000] but our presentation will follow Benavoli et al 11.4.2 The correlation heuristic We are still going to estimate the generalization error using an average of cross-validation predictions as in eq (11.57), and obviously this estimate will be better the more estimates we average Therefore,11.4 Setup II: The training set is random⋆ 215 while we will still obtain the train/test splits using cross-validation, but we will assume the K-fold cross-validation procedure is repeated one or more times (randomizing the assignment to folds each time) to obtain J = K, J = 2K,  splits into training/test sets as shown in eq For each of these J pairs of training/test data, train the model on the training set and test on the test set Denoting: D test j = ((x j 1 , y j 1 ),',\n",
              " '(11.58) We then assume these error estimates have a mean value ¯z, which is what we hope to estimate, and errors vj which are correlated Specifically we assume: rj = ¯z + vj (11.59a) v ∼ N (0, Σ) (11.59b) here v is the J × 1 vector of noise terms and, crucially, we assume they have a covariance Σii = σ 2 , Σij = ρσ2  (11.60) It is this covariance matrix which allows us to account for the (unknown) correlation which arises due to overlap between training sets: The scale term σ 2 is the true variance due to natural variation that arises from the use of finite training and test sets, and ρ is the (unknown) correlation which arises from overlapping training sets',\n",
              " 'This is in some sense quite natural, since if ρ = 0, implying no correlation, the assumed model eq (11.59) corresponds to the normal model that lead to the student t distribution in eq Inspecting the above, it should be clear that all terms are at this point computable except for ρ which accounts for the correlation induced due to overlapping training sets and, as previously discussed, cannot be estimated from data The suggestion by Nadeau and Bengio [2000] is to select: ρ = |Dtest j | |Dtrain j | + |Dtest j | = 1 K (11.62) which is known as the correlation heuristic To understand this choice, note the variance term in the test eq (11.61) becomes: σ˜ 2 = \\x12 1 J + 1 K − 1 \\x13 σˆ 2 .216 11 Performance evaluation So if K becomes large, the term 1 J + 1 K−1 will generally tend towards zero, however, in this case the variance ˆs 2 on the test data should be expected to be larger as we are estimating the rj ’s with fewer observations',\n",
              " '(11.61) will have diminishing returns All in all, it suggest we should select a moderate value of K, for instance K = 5 or K = 10, and repeat the procedure one or more times to increase J, as our computation budget allows Given this, we can compute an approximate confidence interval using the inverse of the cum\\ufffemulative density function of the student-t distribution and similarly obtain a p-value exactly as in Box 11.3.3 The method is summarized in Box 11.4.1 Method 11.4.1: Correlated t-test for cross-validation Our goal is to compare two models MA and MB by estimating the difference in general\\ufffeization error, where we are interested in the more general form of the generalization error described in setup II where the randomness of the training sets are also taken into account \\x88 Select as many cross-validation splits as your computational budget allows We recom\\ufffemend as minimum K = 5 and J = K, and better K = 10 repeated a few times to get J = 20 or 30',\n",
              " '(11.55) \\x88 For each of the J splits (Dtrain j , Dtest j ), train both models on Dtrain j and obtain two sets of nj predictions on Dtest j , yˆ A,j and yˆ B,j \\x88 Estimate the difference in generalization error for split j rj = 1 nj Xnj i=1 h L(ˆy A,j i , y j i ) − L(ˆy B,j i , y j i ) i (11.63) where y j i are the true y-values and the loss can either be L1 or squared loss (in case of regression) or the error rate loss in case of classification Do this for each j = 1,  , J \\x88 A 1 − α confidence interval for the difference in generalization error is zL = cdf−1 T \\x10α 2       ν, r, ˆ σ˜ \\x11 , zU = cdf−1 T \\x10 1 − α 2       ν, r, ˆ σ˜ \\x11  (11.64) \\x88 A p-value for the null hypothesis the two models have the same performance can be computed as p = 2cdfT \\ufffe −|tˆ|     ν = J − 1, µ = 0, σ = 1\\x01 (11.65) tˆ= rˆ σˆ q 1 J + ρ 1−ρ  Note that since we have to assume each rj are normally distributed, the CLM has to apply',\n",
              " 'Question 1: We will consider the Palmer Pen\\ufffeguins dataset and two models for predicting the class label y Specifically, let M1 be a K = 1 nearest neighbor classification model and M2 a K = 5 nearest neighbor classification model To compare them statistically, we perform K = 3 fold cross-validation, and for each fold we record the number of observations where both mod\\ufffeels are correct (as M1/M2), M1 is correct and M2 wrong (as M1/M2), and so on The outcome can be found in table 11.2 We want to test if the two classifiers perform differ\\ufffeently The null hypothesis is that the models have the same performance Given the values of the binomial cu\\ufffemulative distribution function in table 11.3 and assuming that the null hypothesis is true, what is the p-value from McNemar’s test (rounded to two decimals) Fold M1/M2 M1/M2 M1/M2 M1/M2 1 86 8 7 10 2 65 15 11 20 3 79 5 17 10 Table 11.2 Outcome of cross-validation Rows are combi\\ufffenation of outcomes of the two models',\n",
              " 'Values of the binomial cumulative distribution function cdfbinom(m|N, θ = 1 2 ) for different values of the num\\ufffeber of successes m and the number of trials N A 0.23 B 0.45 C 0.84 D 0.90 E Don’t know.12 Nearest neighbor methods Classifying observations based on the labels of their nearest neighbours is a simple idea and has been re-invented several times, however the first discussion of a nearest-neighbour classification rule was by statisticians Evelyn Fix and Joseph Hodges in an (unpublished!) technical report in 1951 [Fix and Hodges, 1951] 12.1 K-nearest neighbour classification We will introduce the K-nearest neighbour classifier with an example 12.1 is shown a subset of the Fisher Iris data where only the two first attributes are plotted Suppose we ask a human to guess the name of a flower at the black square Most humans would properly say Setosa (the blue class) because the nearby flowers are predominantly blue',\n",
              " 'Two things seem to play a role \\x88 The closeness of the nearby points \\x88 How many there are of a particular color This intuition is the idea behind the K-nearest neighbour method Consider again the data in fig 12.1 but focus on a test point at the black cross Imagine we draw a circle around the black cross and slowly increases its radius At some point the circle will contain one point which (as it happens) is yellow in our case, see the upper-left pane of fig 12.2 where the selected point is highlighted with red If we increases the radius of the circle it will at some point contain two and then three points, see the upper-right pane of fig 12.2 where these correspond to a yellow and two green points In general, we can define the K-neighbourhood of a point x as: 1 NX(x, K) = {The K observations in X which are nearest to x}',\n",
              " 'The lower-row of fig 12.2 shows NX(x, K = 5) and NX(x, K = 7) respectively A simple classification method 1 What if several points have the same distance to x This borderline case might appear in the case where there are duplicate observations in the dataset and can be handled in several ways, for instance by (randomly) selecting between the tied points We will assume such a scheme exist and therefore the K-neighbourhood always consist of K observations.220 12 Nearest neighbor methods setosa versicolor virginica x y 4.5 5 5.5 2 2.5 3 3.5 Fig A subset of the Fisher Iris dataset where we only consider two features Which class and why would you assign the test points at the black square and cross if you were to just make a qualified guess is then to fix K (for instance K = 5) and just assign x to the class which has the most elements in NX(x, K) In the case where two classes has equally many members (we say they are tied), for instance the lower-right pane of fig',\n",
              " 'This is simply the KNN classification rule for an observation x: \\x88 Compute NX(x, K) \\x88 Classify x to the class k which has the most members in NX(x, K) \\x88 In the case of ties, simply classify x to the class which has a member nearest to x An alternative tie-breaking rule is simply to select a random of the tied classes Notice in particular the case where K = 1, here we simply assign x to the class of the nearest observation in the training set This is known as the nearest neighbour classification rule 12.3 is shown the classification boundary for the full problem, i.e the colors indicate what class a point at that given location will be classified to for K = 1, 3, 5, 7 12.1.1 A Bayesian view of the KNN classifier⋆ As presented, the KNN classifier is simply a heuristic However, it is possible to give the KNN classifier a Bayesian interpretation [Bishop, 2013]',\n",
              " '(12.2) Nc = Number of observations xi where yi = c (12.3)12.1 K-nearest neighbour classification 221 K = 1 4.5 5 5.5 2 2.5 3 3.5 K = 3 4.5 5 5.5 2 2.5 3 3.5 K = 5 4.5 5 5.5 2 2.5 3 3.5 K = 7 4.5 5 5.5 2 2.5 3 3.5 Fig Illustration of the K-nearest neighbourhood NX(x, K) of the black cross x for K = 1, 3, 5, 7, observations within the neighbourhood is highlighted with the red circles The KNN classifier simply assigns the observation x to the class with the most observations within the circle Then clearly K = PC c=1 Kc and N = PC c=1 Nc If we select a random observation, the probability it belongs to class c is: p(y = c) = Nc N Then, notice for any volume V by the definition of probability: Z V p(x|y = c)dx = {Probability an observation of class c is in V } If we now consider the volume V to be the size of the K-nearest neighbourhood of x, i.e the area of the discs in fig',\n",
              " 'KNN classification boundary for the problem in fig 12.1 for K = 1, 3, 5, 7 Notice as K increases, the boundary becomes more smooth For K = 3 (upper-right corner), the blue point in the lower left corner is able to induce a small blue area due to the tie-breaking rule {lhs.} = Z V p(x|y = c)dx ≈ V p(x|y = c) {rhs.} = Number of observations of class y = c in Vx Total number of observations of class c ≈ Kc Nc If we put this together we obtain p(x|y = c) = Kc NcV',\n",
              " '1D example dataset (upper-right pane) generated as noisy observations of the sinusoidal signal KNN regression for an observation x indicated by the vertical dotted line first finds the K-nearest neigh\\ufffebourhood of x, NX(x, K), and then simply outputs the mean of the observations yi in NX(x, K) The three panes illustrates K = 1, 2, 3 12.2 K-nearest neighbour regression The K-nearest neighbour classification rule is easily modified for regression Suppose we have the dataset shown in fig 12.4 (top left pane) which consists of N = 16 noisy observations of a sinusoidal signal If we wish to make predictions around x = 4 (the vertical bar), this can be accomplished finding the K closest elements to x in the dataset, NX(x, K), (shown as the circles) and simply predicting the mean value of the elements in NX(x, K) (shown as the horizontal bar) The prediction at x = 4 is then just the red square In general, the prediction rule is: f(x, K) = 1 K X i∈NX(x,K) yi',\n",
              " 'Notice in particular the K = 1 prediction rule simply corresponds to finding the observation xi closest to a test point x and predicting f(x, K = 1) = yi  12.5 the prediction rule is visualized for K = 1, 2, 3, 4 Notice, as K increases the rule becomes less driven by an error in any single value (less variation), however, it also becomes more biased towards predictions near the mean.224 12 Nearest neighbor methods f(x, K = 1), d = 0 0 2 4 6 8 10 −1 −0.5 0 0.5 1 f(x, K = 2), d = 0 0 2 4 6 8 10 −1 −0.5 0 0.5 1 f(x, K = 3), d = 0 0 2 4 6 8 10 −1 −0.5 0 0.5 1 f(x, K = 4), d = 0 0 2 4 6 8 10 −1 −0.5 0 0.5 1 Fig Illustration of the prediction rule for KNN regression from fig 12.4 (red line) when computed over the entire dataset for K = 1, 2, 3, 4 Notice the prediction rule is piece-wise linear corresponding to different neighbourhoods 12.2.1 Higher-order KNN regression⋆ If we return to the KNN regression dataset in fig 12.4 and the prediction curves in fig',\n",
              " 'It might be better if the curve within each neighbourhood is fitted to the dataset with a more powerful model A simple way to obtain this is to rather than predicting the mean within each local neighbourhood, fitting a polynomial of degree d The piece-wise linear model then corresponds to d = 0 (the constant polynomial) This is illustrated in fig 12.6 for K = 3, 5 and d = 1, 2 The corresponding prediction curve is shown in fig Compared to the piece-wise linear case in fig 12.5, the high-order polynomials allow much smoother interpolation of the underlying curve, however, in general they also require higher values of K in order not to overfit locally 12.3 Cross-validation and nearest-neighbour methods Selecting K in nearest neighbour methods can easily be accomplished using cross-validation',\n",
              " 'KNN regression can be extended by instead of computing the mean within each region, we carry out a polynomial regression (similar to the example encountered in the previous section on linear regression) for the observations in each neighbourhood NX(x, K) For different degree d = 2, 3 this allows smoother regression curves, but higher d also requires a larger neighbourhood sum of square error One-layer cross-validation for model selection can be used to select K and two-layer cross-validation used for selecting K and estimating the generalization error A particu\\ufffelarly useful simplification is when we apply leave-one-out cross-validation Recall in leave-one-out cross-validation we have to iterate over all observations in our data set, train a model on N − 1 observations and test on the left-out observation',\n",
              " 'The generalization error for a given value of K can then be estimated as: E˜gen K = 1 N \"X N i=1 Error of observation xi when predicted using NX\\\\i (xi , K) # Where the error in question could be either classification error or the sum-of-square error in case of regression As usual the generalization error is estimated for each K and the K with the lowest generalization error is selected.\\x00\\x00226 12 Nearest neighbor methods f(x, K = 3), d = 1 0 2 4 6 8 10 −1 −0.5 0 0.5 1 f(x, K = 3), d = 2 0 2 4 6 8 10 −1 −0.5 0 0.5 1 f(x, K = 5), d = 1 0 2 4 6 8 10 −1 −0.5 0 0.5 1 f(x, K = 5), d = 2 0 2 4 6 8 10 −1 −0.5 0 0.5 1 Fig The prediction curves for KNN regression with polynomials introduced in fig 12.6, here shown for linear polynomials and second-degree polynomials for different neighborhood sizes.12.3 Cross-validation and nearest-neighbour methods 227 Problems 12.1',\n",
              " 'We will use leave-one-out cross-validation for the KNN in order to classify whether the eight consid\\ufffeered observations constitute small islands (given in red, i.e observation O1, O2, O3, O4) or large island (given in blue, i.e observation O5, O6, O7, O8) using a three\\ufffenearest neighbor classifier, i.e The analysis will be based only on the data given in Table 12.1 Which one of the following statements is correct O1 O2 O3 O4 O5 O6 O7 O8 O1 0 2.39 1.73 0.96 3.46 4.07 4.27 5.11 O2 2.39 0 1.15 1.76 2.66 5.36 3.54 4.79 O3 1.73 1.15 0 1.52 3.01 4.66 3.77 4.90 O4 0.96 1.76 1.52 0 2.84 4.25 3.80 4.74 O5 3.46 2.66 3.01 2.84 0 4.88 1.41 2.96 O6 4.07 5.36 4.66 4.25 4.88 0 5.47 5.16 O7 4.27 3.54 3.77 3.80 1.41 5.47 0 2.88 O8 5.11 4.79 4.90 4.74 2.96 5.16 2.88 0 Table 12.1 Pairwise Euclidean distance, i.e d(Oa, Ob) = ||xa − xb||2 = pP m(xam − xbm) 2, between eight observa\\ufffetions of the Gal´apagos data',\n",
              " 'A The error rate of the classifier will be 1/8 B The error rate of the classifier will be 1/4 C The error rate of the classifier will be 3/8 D The error rate of the classifier will be 1/2 E Don’t know Question 2: Consider a two-dimensional data set consisting of N = 7 observations as shown in fig The dataset consist of two classes indicated by the black crosses (class 1) and red circles (class 2) In the figure, the decision boundary for four K-nearest neighbor clas\\ufffesifier (KNN) is shown such that the lighter brown color indicates Class 2 (red circles) and the darker brown color indicates Class 1 (black crosses) Suppose K is restricted to the values 1, 3, 5, 7, which of the following statements are true about values of k1, k2, k3 and k4 K = k2 K = k4 Class 2 Class 1 K = k1 K = k3 −1 −0.5 0 0.5 1 −1 −0.5 0 0.5 1 −1 −0.5 0 0.5 1 −1 −0.5 0 0.5 1 −0.1 0 0.1 −0.1 0 0.1 −0.1 0 0.1 −0.1 0 0.1 Fig Decision boundaries for four KNN classifiers',\n",
              " 'Question 3: Consider again the distances in ta\\ufffeble 12.2 We will predict the label indicated by the blue color, i.e observations o1,  , o4 belong to class C1 and observations o5,  , o8 to class C2 This will be done us\\ufffeing a k-nearest neighbor (KNN) classifier based on the cityblock distance measure indicated in table 12.2 We will use leave-one-out cross validation (i.e the observa\\ufffetion that is being predicted is left out) using one-nearest classifier, i.e What is the accuracy if all N = 8 observations are classified o1 o2 o3 o4 o5 o6 o7 o8 o1 0 4 7 9 5 5 5 6 o2 4 0 7 7 7 3 7 8 o3 7 7 0 10 6 6 4 9 o4 9 7 10 0 8 6 10 9 o5 5 7 6 8 0 8 6 7 o6 5 3 6 6 8 0 8 11 o7 5 7 4 10 6 8 0 7 o8 6 8 9 9 7 11 7 0 Table 12.2 Pairwise Cityblock distance, i.e d(oi, oi) = ∥xi − xj∥1 = PM k=1 |xik − xjk|, between 8 observations Each observation oi corresponds to a M = 15 dimensional binary vector, xik ∈ {0, 1}',\n",
              " 'A accuracy = 1 8 B accuracy = 1 4 C accuracy = 1 2228 12 Nearest neighbor methods D accuracy = 5 8 E Don’t know.13 Bayesian Classifiers and Bayesian Networks Bayes’ theorem is the application of the basic rules of probability, p(y|x) = p(x|y)p(y) PC y′=1 p(x|y ′)p(y ′) and it is widely used in machine learning We have already seen several applications of Bayes’ theo\\uffferem, for instance in the analysis of the coin in section 6.4 and as an element of the credibility intervals in chapter 10 However, in this chapter we will consider the problem more heads on and discuss additional terminology in particular with respect to Bayesian classifiers and Bayesian networks also called Bayesian belief networks which defines a probabilistic graphical model representing condi\\ufffetional dependencies among variables However, before this we will consider the distinction between discriminative and generative models',\n",
              " 'For instance, consider trying to learn to distinguish between cats (yi = 0) and dogs (yi = 1) based on features xi of each animal Logistic regression essentially tries to fit a straight line – a decision boundary– that separates the cats from the dogs A new instance xi is then classified by observing which side of the decision boundary it lies on This can be seen as directly coming up with a mapping of p(y|x, w) (13.1) This is known as discriminative analysis Bayesian inference also tries to determine this mapping, but considers a very different approach First, we look at all instances of cats, and then we build a model of what cats look like Then we look at all instances of dogs, and we build a model of what dogs look like Then to classify a new instance, we consider how well it corresponds to what we expect a cat or a dog will look like according to respectively the cat model and the dog model, and we make our decision accordingly',\n",
              " 'Example of a Bayes classifier fitted to a two-class example dataset The contours indicate the multivariate Gaussians fitted to each of the two classes separately 13.1.1 Bayes classifier Continuing the above discussion, consider Bayes’ theorem in the two-class setting: p(y|x) = p(x|y)p(y) p(x|y = 0)p(y = 0) + p(x|y = 1)p(y = 1) (13.2) So when this model considers if a new animal should be classified as a cat, y = 0, it considers how much the animal looks like a cat p(x|y = 0), multiply by the prior probability the animal is a cat p(y = 0) and divide this by the same quantity including the similar expression for dogs, p(x|y = 1) and p(y = 1) To make this more concrete, let’s suppose we observe n0 instances of cats, XCats, and n1 instances of dogs, XDogs, each observation consisting of two features The labelled dataset is plotted in fig',\n",
              " 'Decision rule, i.e the probability p(y = 0|x), of the Bayes classifier when trained on the two-class dataset from fig Notice, the decision rule is quite steep at the boundary corresponding to the two contour plots in fig Using this together with the priors p(y = 0) = n0 n0+n1 , p(y = 1) = n1 n0+n1 allows us to compute the probability the animal belongs to either of the two classes as: p(y = c|x) = p(x|y = c)p(y = c) p(x|y = 0)p(y = 0) + p(x|y = 1)p(y = 1) (13.6) The decision boundary, i.e p(y = 0|x), is plotted in fig 13.2 as the gray surface 13.2 Na¨ıve-Bayes classifier Na¨ıve-Bayes is simply the standard Bayesian approach with a particular simplification Consider the Bayes classifier for C classes using a dataset with M features: p(y|x1, x2,  , xM) = p(x1, x2,  , xM|y)p(y) PC c=1 p(x1,  , xM|y = c)p(y = c) (13.7)232 13 Bayesian Classifiers and Bayesian Networks y x1 x2 1 1 0 1 0 1 1 1 1 2 1 1 2 1 0 2 0 0 3 1 1 3 0 1 Table 13.1',\n",
              " 'The first column y = 1, 2, 3 correspond to the grade of the student, where y = 1 means a low grade, y = 2 a medium grade and y = 3 a high grade A problem with the Bayes classifier is if M is very large, representing the conditional distribution p(x1, x2,  , xM|y), may be very expensive For instance, for the multivariate normal distribution this requires storing a symmetric covariance matrix Σ and the mean vector µ, in total M + 1 2M(M + 1) numbers This is not only costly, but if we do not have much data, estimating this many parameters may not be possible to do reliably The Na¨ıve-Bayes assumption is simply that we assume that the conditional distribution factorizes: p(x1, x2,  , xM|y) = p(x1|y)p(x2|y) If we still represent each factor as a 1D normal distribution this only requires 2M numbers (i.e., the mean value and variance for each of the attributes x1, x2,  Plugging this into eq (13.7) we obtain the Na¨ıve Bayes approximation: p(y|x1, x2,',\n",
              " '(13.8) Example: To illustrate the basics of the procedure, we will consider a simple example based on the data shown in table 13.1 The dataset consists of N = 8 students and for each student we record two binary features x1 and x2 corresponding to the sex of the student and if the student is typically going out in the evening or not The first column y = 1, 2, 3 corresponds to the grade of the student, where y = 1 means a low grade, y = 2 means a medium grade and y = 3 a high grade Suppose we want to train a na¨ıve-Bayes classifier on the dataset and use it to determine the probability a new observation x1 = 0 and x2 = 1 belong to any of the three classes We first compute the class-priors to be p(y = 1) = p(y = 2) = 3 8 and p(y = 3) = 2 8 = 1 4 Then we can compute the probability of p(xj = 0|y = c) as:13.2 Na¨ıve-Bayes classifier 233 p(xj = 0|y = c) = {Number of times where xj = 0 and y = c} {Total number of times where y = c}',\n",
              " 'Using that p(x2 = 1|y = c) = 1 − p(x2 = 0|y) we then compute the probability of the new observation as p(x1 = 0, x2 = 1|y = 1) = p(x1 = 0|y = 1)p(x2 = 1|y = 1) = 1 3 × (1 − 1 3 ) = 2 9 , p(x1 = 0, x2 = 1|y = 2) = p(x1 = 0|y = 2)p(x2 = 1|y = 2) = 1 3 × (1 − 2 3 ) = 1 9 , p(x1 = 0, x2 = 1|y = 3) = p(x1 = 0|y = 3)p(x2 = 1|y = 3) = 1 2 × (1 − 0) = 1 2  In our case p(y=c|x1 = 0, x2 = 1) can then be computed using eq (13.8) to be: p(x1 = 0, x2 = 1|y=c)p(y=c) p(x1 = 0, x2 = 1|y= 1)p(y= 1) + p(x1 = 0, x2 = 1|y= 2)p(y= 2) + p(x1 = 0, x2 = 1|y= 3)p(y= 3) and simply plugging in the above numbers we obtain: p(y = 1|x1 = 0, x2 = 1) = 2 9 × 3 8 2 9 × 3 8 + 1 9 × 3 8 + 1 2 × 1 4 = 1 3 , p(y = 2|x1 = 0, x2 = 1) = 1 9 × 3 8 2 9 × 3 8 + 1 9 × 3 8 + 1 2 × 1 4 = 1 6 , p(y = 3|x1 = 0, x2 = 1) = 1 2 × 1 4 2 9 × 3 8 + 1 9 × 3 8 + 1 2 × 1 4 = 1 2',\n",
              " '13.2.1 Na¨ıve-Bayes for non-binary data and robust estimation The Na¨ıve-Bayes method, as introduced in the above example, has two shortcomings The first shortcoming is that in most applications, the attributes x1,  , xM will be of mixed types (binary, categorical, continuous, etc.) This is relatively simple to overcome as it simply amounts to selecting appropriate densities for the terms p(xj = x|y = c) in eq The second shortcoming is that when we estimate the individual probabilities directly p(x1|y),  , p(xM|y) from the data as in eq (13.9), one of these probabilities may easily be zero for a new test point which will cause the entire expression eq (13.8) to be zero, and the method will be overly confident on new input (in fact, we can easily end up dividing by zero in eq',\n",
              " 'n the binary case, the parameter α arises by treating the probability θ = p(xj = 1|y) as an unknown quantity which we estimate from data using the Beta-Bernoulli calculation section 6.4, but using a symmetric Beta(θ|α, α) prior Doing this we obtain the posterior distribution using eq (6.38) as: Beta(θ|n1 + α, Nc − n1 + α) This is the distribution of the unknown probability, and a reasonable estimate is simply the mean value: E[θ] = n1+α Nc+2α , which is exactly our probability estimate in eq Robust estimation, binary case If we let Nc = PN i=1 δyi,c be the number of observations belonging to class c, we can then count the number of these observations for which feature j was k, i.e were Xij = k, as nk = X N i=1 δXij ,kδy,c, (13.10) Using this, our new robust estimate of the marginal probabilities in the case xj is binary is: Binary case: p(xj = 1|y = c) = n1 + α Nc + 2α  (13.11) Where α ≥ 0 denotes the amount of robustness',\n",
              " 'For instance, we would get p(x2 = 0|y = 1) = 1+α 3+2α in our example In other words, if α = 0 we have no robustness, and if α is very large the probabilities will all be near 1 2  This might seem familiar, and there is a connection to the robustness parameter and the priors in the Beta-Bernoulli derivation from section 6.4, see Technical Note 13.2.1 Robust estimation, categorical case The above trick generalizes to the categorical case with nearly no modifications Assume attribute j can take K different values, and denote the number of observations in class y = c such that attribute j takes a value of xj = k as nk, k = 1,  , K just as in eq (13.10) and note that PK k=1 = Nc We can then define the robust estimate as simply: Categorical case: p(xj = k|y = c) = nk + α Nc + Kα',\n",
              " 'We can obtain a robust estimate by adding a factor α to the estimate of the standard deviations to ensure they do not collapse to singular values Specifically: Continious case: p(xj = x|y = c) = N (x|µ = µc, σ2 = (σc + α) 2 ) (13.13) µc = Ey=c[xj ] = 1 Nc X N i=1 δy,cXij , and σc = ˆstdy=c[xj ] = vuut 1 Nc − 1 X N i=1 δy,c(Xij − µc) 2 Selecting the parameters The robust estimation parameter α should be selected by using cross-validation for parameter selection (algorithm 5) to choose between a handful of reasonable values of α Include α = 0 if it does not cause underflow Note different computational environments might implement different strategies for parameter estimation and robust estimation than described above For instance, it is also customary to robustly estimate the standard deviation in the normal case by adding a value corresponding to a fraction of the maximal per-class standard deviation rather than an absolute numerical value as above',\n",
              " 'Consider the following example adapted from Pearl [2014], MacKay [2003] Fred lives in Los Angeles and commutes 60 miles to work Whilst at work, he receives a phone-call from his neighbour saying that Fred’s burglar alarm is ringing What is the probability that there was a burglar in his house today While driving home to investigate, Fred hears on the radio that there was a small earthquake that day near his home ‘Oh’, he says, feeling relieved, ‘it was probably the earthquake that set off the alarm’ What is the probability that there was a burglar in his house To analyse this story we first introduce the variables: a : The alarm is ringing b : A burglar was in Fred’s house c : Fred received a phone-call reporting the alarm e : A small earthquake took place today near Fred’s house r : The radio report of the earthquake is heard by Fred In a case like this, we know (from our experience) that some of these events must be independent',\n",
              " 'In general, the probability of these variables will factorize as follows:236 13 Bayesian Classifiers and Bayesian Networks Earthquake Burglar Radio Alarm Phonecall Fig Bayesian network of the burglar example Each vertex corresponds to a variable, and incident edges corresponds to conditional dependence p(a, b, c, e, r) = p(b)p(e)p(a|b, e)p(c|a)p(r|e) (13.14) This factorization of the probability has important consequences Firstly, as for the na¨ıve-Bayes assumption, it makes the probability density much less costly to store on a computer and reliable to estimate as there are fewer parameters than the full (un-factorized) joint distribution Secondly, it allows faster computation by exploiting the factorization structure and finally it allows us easier to see what quantities are independent of each other It is common to represent the factorization as a network where the vertices correspond to the variables and the edges correspond to statistical dependence, see fig',\n",
              " 'So for instance, if there is an edge from B to A, that means that in the joint distribution, then A must be conditional on B and possible other variables connected to A To solve the Burglar problem, assume the probability of there being a burglar is p(b = 1) = 0.1%, earthquake p(e = 1) = 0.1% (corresponding to roughly one burglar and earthquake every four years) and that the alarm is triggered either by (1) false alarms (very low probability), (2) if an earthquake takes place (low probability) and finally if a burglar enters the home (high probability) In our example these probabilities are:1 1 For instance, suppose we let f = 0.1% denote the chance a false alarm triggers a, αe = 1% the chance an earthquake triggers a and finally αb = 99% the chance a burglar triggers a',\n",
              " 'Finally assume the neighbour would never phone if the alarm is not ringing (p(c = 1|a = 0) = 0) and that the radio reported is also trustworthy (p(r = 1|e = 0) = 0) and let’s return to the problem: Suppose first the phone calls c = 1; then we know the alarm is ringing a = 1 and so the posterior probability of b, e (burglary and earthquake) becomes: p(b, e|a = 1) = p(a = 1|b, e)p(b, e) p(a = 1)  We can use the Bayes network to compute these probabilities',\n",
              " '13.3 we see that to determine what variables remain in the sum when computing p(a), we look at all other vertices in a network where we can move to a by going in the direction of the edges 13.4 where we have illustrated the two nodes that remain, e, b, with red Using the above numbers we obtain: p(a = 1|b = 0, e = 0)p(b = 0)p(e = 0) = 0.000998, p(a = 1|b = 1, e = 0)p(b = 1)p(e = 0) = 0.0000989, p(a = 1|b = 0, e = 1)p(b = 0)p(e = 1) = 0.000010979, p(a = 1|b = 1, e = 1)p(b = 1)p(e = 1) = 9.9 × 10−7  By inserting these four numbers into eq (13.16) and summing we obtain p(a = 1) = 0.002 and so from eq (13.15) p(b = 0, e = 0|a = 1) = 0.4993, (13.17) p(b = 1, e = 0|a = 1) = 0.4947, (13.18) p(b = 0, e = 1|a = 1) = 0.0055, (13.19) p(b = 1, e = 1|a = 1) = 0.0005 (13.20)238 13 Bayesian Classifiers and Bayesian Networks Earthquake Burglar Radio Alarm Phonecall Fig',\n",
              " 'This gives p(a, e, b) So returning to the initial question, when we determine if there was a burglar at the house we must compute p(b = 1|a = 1) which can be accomplished by marginalizing over the burglar-variable: p(b = 0|a = 1) = p(b = 0, e = 0|a = 1) + p(b = 0, e = 1|a = 1) = 0.505 p(b = 1|a = 1) = p(b = 1, e = 0|a = 1) + p(b = 1, e = 1|a = 1) = 0.494 so after receiving the call, we believe there to be a 50% chance there was a burglar in the house An important point to take away from this example is that b and e, which were initially independent: p(e, b) = p(e)p(b), are made dependent by the information a Now consider the final part of the example Suppose we also learn that e = 1 (i.e there was an earthquake) The probability there was a burglar can now be computed as: p(b|e, a) = p(b, e|a) p(e|a) = p(b, e|a) p(e, b = 0|a) + p(e, b = 1|a)',\n",
              " 'This is in according to everyday intuition: when we learn about the earthquake, we consider that to be the more plausible explanation of the alarm 13.3.1 A brief comment on causality Using the implied rules any factorization of a joint distribution is easily translated into a network: Vertices implies variables and there is an edge from variable x to y if there is a term p(y|x, · · ·) in13.3 Bayesian networks⋆ 239 z x y p(x|z)p(y|x, z)p(z) p(y|z)p(x|y, z)p(z) z x y Fig Two bayesian networks which both represent the same distribution p(x, y, z) Since the two networks are not similar this shows a Bayesian network cannot be interpreted as a causal graph the factorization of the joint distribution A point that is sometimes confused is to interpret the Bayesian network as having a causal meaning Consider a general distribution p(x, y, z)',\n",
              " '13.5, this shows we cannot interpret a Bayesian network as a causal graph.240 13 Bayesian Classifiers and Bayesian Networks Problems 13.1 Question 1: Nine of the fifteen observations in Ta\\ufffeble 13.2 have chronic kidney disease (i.e., O1–O9 given in red) whereas six of the observations do not have chronic kidney disease (i.e., O10–O15) given in black) We would like to predict whether a subject has chronic kidney dis\\ufffeease or not using the data in Table 13.2 and the attributes RBC, P C, DM, and CAD We will apply a Na¨ıve Bayes classifier that assumes independence between the four at\\ufffetributes Given that a subject has these four attributes (i.e., RBC = 1, P C = 1, DM = 1, and CAD = 1) what is the probability that the person has chronic kidney dis\\ufffeease, i.e., what is P(CKD = 1|RBC = 1, P C = 1, DM = 1, CAD = 1) according to the Na¨ıve Bayes classifier',\n",
              " 'For each observation there are M = 7 binary features and N = 15 observations O1,  , O15 belonging to two categories (i.e., CKD=1 for O1,  , O9 and CKD=0 for O10,  A 2.56 % B 96.14 % C 98.03 % D 100 % E Don’t know Question 2: We will consider a Bayes classifier using the attributes RBC, P C, and DM in Table 13.2 (i.e., we no longer consider the attribute CAD) What is P(CKD = 1|RBC = 1, P C = 1, DM = 1) accord\\ufffeing to a Bayes classifier (i.e we are no longer imposing independence as in the Na¨ıve Bayes classifier) A 26.67 % B 97.07 % C 98.03 % D 100 % E Don’t know Question 3: Five of the ten considered subjects in Table 13.3 survived after five years (S1 − S5) given in black whereas five subjects died within five years (NS1 − NS5) given in red We would like to predict whether a subject survived using the data in Table 13.3 and the attributes Y AY , OAY , P AY  We will apply a Na¨ıve Bayes classifier that assumes independence be\\ufffetween the three attributes',\n",
              " 'I.e., what is P(S|Y AY = 1, OAY = 1, P AY = 1) according to the Na¨ıve Bayes classifier Y AY Y AN OAY OAN P AY P AN S1 1 0 1 0 1 0 S2 1 0 1 0 0 1 S3 0 1 0 1 1 0 S4 0 1 1 0 1 0 S5 0 1 1 0 1 0 NS1 0 1 1 0 1 0 NS2 0 1 0 1 1 0 NS3 1 0 0 1 0 1 NS4 0 1 1 0 1 0 NS5 0 1 1 0 1 0 Table 13.3 Given are five subjects that survived in Haber\\ufffeman’s study (denoted S1, S2,  ., S5) as well as the five sub\\ufffejects that did not survive in Haberman’s study (denoted NS1, NS2,  ., NS5) including whether these subjects are young or old (Y AY , Y AN ), were operated after 1960 or not (OAY , OAN ), and had positive axillary nodes or not (P AY , P AN ) A 16 125 B 3 11 C 1 2 D 8 11 E Don’t know Question 4: Consider the observations in ta\\ufffeble 13.4 Suppose we only consider the first two fea\\ufffetures f1, f2 and train a Naive-Bayes classifier to clas\\ufffesify between class C1 (black) and C2 (blue) based on these two features alone',\n",
              " 'N = 10 observations s1,  , s10 belonging to two categories The black category C1 (observations s1,  , s5) and the blue category C2 (observations s6,  For each observation there are M = 6 binary features f1,  A pNB(C1|f1 = 0, f2 = 1) = 0.83 B pNB(C1|f1 = 0, f2 = 1) = 0.70 C pNB(C1|f1 = 0, f2 = 1) = 0.67 D pNB(C1|f1 = 0, f2 = 1) = 0.75 E Don’t know.14 Regularization and the bias-variance decomposition As we already saw in chapter 10, “Overfitting and cross-validation”, a too flexible model can easily overfit the dataset leading to a high generalization error In this chapter we will consider a general technique for controlling model complexity known as regularization, which is useful in many supervised learning settings but it is particulary apt for linear and logistic regression as well as neural network modelling',\n",
              " 'Regularization has been re-invented many times, but was first considered by Andrey Nikolayevich Tikhonov in 1943 [Tikhonov, 1943], meanwhile a good introduction to the tradeoff between bias and variance can be found in the discussion by James et al 14.1 Least squares regularization In this section, we will look at a general approach for managing model complexity known as regu\\ufffelarization Just as in the polynomial example, regularization allows us to make different models (by adding different degrees of regularization), and the most appropriate choice of regularization is then made using cross-validation for model selection We illustrate the technique using least-squares re\\ufffegression Consider the simple linear regression model we previously encountered in with prediction rule: yi = f(xi , w) = x˜ T i w, as the reader may recall from section 8.1.1, the linear regression model was trained by minimizing the sum-of-squares error term: E(w) =      y − Xw˜       2',\n",
              " '(14.2)244 14 Regularization and the bias-variance decomposition 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 Fig A regularized linear regression model is fitted to the dataset of 9 observations and 10 test observations The solutions, corresponding to three different values of λ, are shown in the three panes Notice for larger values of λ, the solution is dragged towards the x-axis because the solution for the weights w ∗ becomes smaller according to eq The left-most pane has high variance but low bias, the right\\ufffemost pane has high bias but low variance The way we arrived at this formulation was a simple application of the general likelihood frame\\ufffework discussed in section 6.5, see in particular eq There are two potential issues in linear regression',\n",
              " 'Regularization attempt to solve these problems, by simply altering the cost function to have a stronger preference small weights However, note the magnitude of the weights are affected by the relative scaling of the columns of X, and we therefore transform X by subtracting the mean and dividing by the standard deviation of the columns: Xˆ ij = Xij − µj sˆj , µj = 1 N X N i=1 Xkj , sˆj = vuut 1 N − 1 X N i=1 (Xij − µj ) 2 Next, we don’t want the constant term in the regression to be affected by regularization, and we therefore consider a cost function of the form: Eλ(w, w0) =      y − w01 − Xwˆ       2 + λ∥w∥ 2 , λ ≥ 0 (14.3) The last term, λ∥w∥ 2 , is called the regularization term, and the constant λ is called the regularization constant The regularization constant influence the relative importance of the regularization term, starting with λ = 0 which correspond to the ordinary least-squares cost function eq (14.1) asides the standardization',\n",
              " '(14.3)) is commonly called ridge regression Solving regularized linear regression⋆ Note our new objective still only depends on terms which are linear or quadratic in w, and can therefore still be solved To do so, first note that for any w, the minimal value of the intercept term w0 is14.1 Least squares regularization 245 dEλ(w, w0) dw0 = X N i=1 −2(yi − w01 − xˆi ⊤w) = −2NE[y] − 2Nw0 − N   1 N X N i=1 xˆi ⊤  w Since we have subtracted the column-wise mean from Xˆ, the term involving w disappears Setting the derivative equal to zero and solving gives: w0 = E[y] = 1 N X N i=1 yi which, retrospectively, might seem fairly obvious Therefore, suppose we define ˆyi = yi − E[y], we can then re-write the objective as: Eλ =      yˆ − Xwˆ       2 + λ∥w∥ 2 , λ ≥ 0 This objective can be solved by computing the derivative and setting it equal to zero',\n",
              " 'To make a prediction, we have to be careful to apply the right feature transformations Specifically, to make predictions for a test observation x compute:  x1−µ1 σ1 x2−µ2 σ2 · · · xM−µM σM  w∗ + E[y] where µi , σi , and E[y] are all computed on the training data Note that asides analytical convenience, the L2 regularization can be motivated using Bayes’ theorem, see Technical Note 14.1.1 14.1.1 The effect of regularization If we simply look at the expression for Eλ(w) in eq (14.3) then if λ = 0 we get ordinary linear regression If on the other hand λ is large, the error term prefers each coordinate of w, wi , to be as small as possible This is also evident from the expression for the solution eq (14.4): If we for a moment na¨ıvely ignore the standardization and assume X and y are scalars we get: w ∗ = Xy X2 + λ , so the larger λ is, the smaller w∗ becomes and in the limit λ → ∞ then w∗ = 0',\n",
              " 'The linear regression model is in this case a 6’th degree polynomial We see that for the larger λ, since w∗ is smaller the fitted polynomial is dragged (biased) towards the x-axis If on the other hand λ is very small, the polynomial wiggles quite a lot (high variance) as can be expected for a 6-degree polynomial on such a small dataset The full evolution of the size of each coordinate of the weights w∗ i for many values of λ is shown in fig 14.2.\\x00\\x00246 14 Regularization and the bias-variance decomposition 10-6 10-4 10-2 100 -3 -2 -1 0 1 2 3 Fig A regularized linear regression model is fitted to the dataset shown in fig 14.1 and the coordinates of the optimal weights are plotted When λ is small, the weights are large indicating high variance but low bias When λ is larger, the weights become smaller indicating lower variance but higher bias in the solutions This also holds in general: When the regularization λ is small, the models have high variance and low bias',\n",
              " 'As a rule, varying λ to search for an optimal value of the generalization error will therefore lead to better models 14.3 the variable λ is tweaked from a very small value of λ = 10−6 to a higher value λ = 100 and the training and test error (normalized by the number of observations) of the small dataset in fig 14.1 displayed The three particular values plotted in fig 14.1 are plotted as circles We see that the training error generally increases as λ increases (after all, for small λ the model will overfit the training data set), however, the test error has an optimum when λ ≈ 10−2  In practice when we search for the optimal value of λ, we test S different values of λ, λ1,  , λS selected beforehand and then compare each of the corresponding linear regression models using cross-validation for model selection Other choices of regularization⋆ A reader may wonder why we chose the particular L2 square-loss regularization',\n",
              " 'The advantage of the L1 regularization term is that it prefers sparse solutions where many of the coordinates of wi becomes equal to zero, as opposed to L2 regularization where they in general only become approximately equal to 0 This is useful when the data set is known to contain many irrelevant attributes we wish to disregard A disadvantage of pure L1 regularization is small changes in regularization may mean very different weights are selected.14.1 Least squares regularization 247 10-6 10-4 10-2 100 102 0 2 4 6 8 10-3 Fig Effect of varying the regularization parameter λ on the training and test error The colored dots indicate three models shown in fig Technical note 14.1.1: Why use L2 regularization Regularization, as explained here, is simply adding a factor λwT w to our error which may appear rather arbitrary It is however possible to give regularization a natural Bayesian interpretation using our general likelihood learning framework discussed in section 6.5',\n",
              " 'Our discussion then proceeded by assuming the prior term p(w) could be ignored However, let’s make the assumption the prior term cannot be ignored The simplest case is to assume the prior is normally distributed with diagonal covariance matrix δI: p(w) = N (w|0, δ2 I) The maximum-likelihood formulation (see eq (6.46) in summary box 6.5.1) consist of max\\ufffeimizing: p(w) +X N i=1 log p(yi |xi , w) = − 1 2σ 2 X N i=1 ∥y − Xw∥ 2 − N 2 log(2πσ2 ) − 1 2δ 2 wT w − M 2 log(2πδ2 ) If we drop constant terms and re-scale the expression by a factor −2σ 2 X N i=1 ∥Xw − y∥ 2 + σ 2 δ 2 wT w Therefore, if we define λ = σ 2 δ 2 , we nearly recover eq (14.3) asides the standardization and difference in how the bias is treated (this discrepancy can be solved by assuming a flat prior for w0)',\n",
              " 'Illustration of bias and variance 14.2 Bias-variance decomposition In this section, we will analyse the generalization error from a more theoretical perspective using what is known as the bias-variance decomposition Recall bias is how far away from the true mean we are on average and variance measures how spread out our observations are, see fig 14.4 for an intuitive illustration It turns out that the generalization error can in general be decomposed into a systematic error known as the bias term and a term depending on how much our trained models vary known as the variance term Showing this is not too difficult but requires some math We will therefore first illustrate the result with a linear regression example and leave the proof as optional reading Suppose we are in a standard, supervised situation with a square loss where we predict y from observations x If D denotes our training data, a given model learns a function f on the training data to accomplish this task',\n",
              " 'Notice the learned function f depends on the training sets and to keep track of this dependency we will write it as fD Suppose we want to know how the generalization error behaves on average Recall from chap\\ufffeter 10 the generalization error was defined as how well our model performed on a test set on average when trained on the training set D (see eq (10.4)) E gen M = E(x,y) [L(y, fM(x))] = Z L(y, fM(x))p(x, y)dxdy (14.5) Since the generalization error Egen depends on the training data set D, we will indicate this by the notation Egen(D), and we will in this section consider the expectation of the generalization error over all training data set: ED [E gen] = Z E gen(D)p(D)dD The above, i.e., the averaged generalization error, is what we in this section consider our true objective estimate of how well our model performs: How well it generalizes based on averaging over all training data sets',\n",
              " '14.6 the three14.2 Bias-variance decomposition 249 0 0.2 0.4 0.6 0.8 1 0.3 0.4 0.5 0.6 0 0.2 0.4 0.6 0.8 1 0.2 0.3 0.4 0.5 0.6 Fig A linear regression model corresponding to a second-order polynomial trained on two different training data sets The learned model (red line) depends on the training sets The training set is distributed around the black line linear regression models are each trained on 10 different training sets and the prediction curves, fD, are plotted as the thin red lines Of particular importance will be the average of all these curves shown as the thick red line in fig Formally, this is written as ¯f(x) = ED [fD(x)] The black line is the true average of the training sets, i.e the training points (which are not shown in fig 14.6) are distributed around this curve Formally, it is defined as the average value of y given x, i.e.: y¯(x) = Ey|x [y]  Considering fig 14.6 we can make some general observations',\n",
              " 'Meanwhile, in the third plot the curves are spread out quite a lot because the model is too flexible and we say this model has a high variance If we turn to the average behaviour of the curves (the thick red line), in the second and third plot the average of all the models is quite similar to the thick black line (the true average of the training data) and we say the curves have a low bias Meanwhile, the first model, which is too inflexible, has a high bias because the average of the model ¯f(x) and the average of the data ¯y(x) is quite different In the following, we will show these two effects –bias and variance– is all we need to describe the average generalization error for any model',\n",
              " 'A linear regression model corresponding to a second-order polynomial trained on two different training data sets The learned models (the thinner red lines) depends on the training sets The training set is distributed around the black line The average of all models is shown as the thicker red line where the expectation can be written out as ED,(x,y) [ · ] = R [ · ] p(x, y, D)dxdydD We first assume x to be fixed and consider the average: ED,y|x h (y − fD(x))2 i = ED,y|x h (y − y¯(x) + ¯y(x) − fD(x))2 i = Ey|x h (y − y¯(x))2 i + ED h (¯y(x) − fD(x))2 i + 2ED,y|x [(y − y¯(x)) (¯y(x) − fD(x))]  The last term is zero since ED,y|x [(y − y¯(x)) (¯y(x) − fD(x))] = Ey|x [y − y¯(x)] ED [¯y(x) − fD(x)] , and Ey|x [y − y¯(x)] = 0 If we look at the second term we can do the same trick once again: ED h (¯y(x) − fD(x))2 i = ED h\\ufffe y¯(x) − ¯f(x) + ¯f(x) − fD(x) \\x012 i = ED h\\ufffe y¯(x) − ¯f(x) \\x012 i + ED h\\ufffe ¯f(x) − fD(x) \\x012 i + 2ED \\ufffey¯(x) − ¯f(x) \\x01 \\ufffe ¯f(x) − fD(x) \\x01',\n",
              " 'Putting all these things together, we obtain: ED,y|x h (y − fD(x))2 i (14.6) = Ey|x h (y − y¯(x))2 i + \\ufffe y¯(x) − ¯f(x) \\x012 + ED h\\ufffe ¯f(x) − fD(x) \\x012 i  (14.7) The last term is simply the variance of fD(x) computed with respect to x and the first term too is just the variance of y conditional on x Using this the above can be written as: ED,y|x h (y − fD(x))2 i = Vary|x [y] + VarD [fD(x)] + \\ufffe y¯(x) − ¯f(x) \\x012 \\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0014.2 Bias-variance decomposition 251 0 0.5 1 0.1 0.2 0.3 0.4 0.5 0 0.5 1 0.1 0.2 0.3 0.4 0.5 0 0.5 1 0.1 0.2 0.3 0.4 0.5 0 0.5 1 0.1 0.2 0.3 0.4 0.5 0 0.5 1 0.1 0.2 0.3 0.4 0.5 0 0.5 1 0.1 0.2 0.3 0.4 0.5 Fig Bias-variance decomposition for the three linear regression models In the top row is shown the bias term Namely, how much the average values of the models trained on different random data sets (illustrated with the thick red line) differ from the true mean values of the data illustrated by the black line In the bottom row is shown the variance term',\n",
              " 'Taking the expectation with respect to x and rearranging we finally obtain the result: ED [E gen] = Ex h Vary|x [y] + \\ufffe y¯(x) − ¯f(x) \\x012 + VarD [fD(x)]i  (14.9) Interpreting the bias-variance decomposition The last equation in the previous section is known as the bias-variance decomposition The term on the left-hand side of the equality sign is how well we expect the model to generalize to new data: This is the objective measure for how well our model performs The terms on the right-hand side of the equality sign tells us that the error of any model is decomposed into the following three parts \\x88 The first term Vary|x [y] is just a constant It does not depend at all upon our choice of model but simply represents the intrinsic difficulty of the problem We cannot make this term any larger or smaller by selecting one model over another \\x88 The second term \\ufffe y¯(x) − ¯f(x) \\x012 is the bias term',\n",
              " '\\x88 The third term VarD [fD(x)] is the variance term It tells us how much the model wiggles when trained on different sets of training data That is, when you train the models on N different (random) sets of training data and the models (the prediction curves) are nearly the same this term is small To illustrate the variance and bias terms for the linear regression example, in fig 14.7 we have shown what contributes to the two terms In the top-row are given the bias terms (the difference betwe\\x00\\x00252 14 Regularization and the bias-variance decomposition the models mean values and the data mean values) and in the bottom row are given the variance terms (the spread of the models) The generalization error is the sum of these two contributions, plus the third contribution we cannot do anything about',\n",
              " 'When we think about how well different models perform, each model has different values of the bias and variance terms which explains their generalization error Often it is possible to construct models such that e.g the bias or variance term is low, but at the expense of a larger value of the other term This is known as the bias-variance tradeoff The purpose of regularization in the context of this bias-variance tradeoff is to substantially reduce the variance without introducing too much bias.14.2 Bias-variance decomposition 253 Problems 14.1 Question 1: Which one of the following state\\ufffements pertaining to regression is incorrect A In regularized least squares regression the aim is to reduce the model’s variance without introducing too much bias B Linear regression where the inputs are transformed can only model linear relations between the original untransformed inputs and the outputs',\n",
              " 'D Forward selection can be used both for regression and classification problems E Don’t know Question 2: Three of the following actions will typically reduce the amount of over-fitting, and one of them will typically increase it Which option will typi\\ufffecally increase the amount of over-fitting A Reduce the number of attributes B Reduce the amount of training data C Select a less complex model D Add model regularisation E Don’t know.15 Neural Networks Artificial neural networks (ANNs) were originally invented as mathematical models of the infor\\ufffemation processing by neurons McCulloch and Pitts [1943] Today it is clear there are important differences between ANNs and biological neurons, however, the basic structure is very similar In this chapter, we will consider the most simple forms of ANNs, the feedforward network, which is nevertheless an extremely powerful approach to both classification and regression',\n",
              " 'Each neuron (a neuron is simply a special type of cell) is connected to up to 10 000 other neurons by synapses Each neuron has an electric activity (for simplicity this can be considered as a real number) which depends on how many of the neurons connected to the neuron are active That is, if sufficiently many of the neurons connected to a given neuron becomes active, the neuron itself becomes active and may then in turn excite other neurons connected to it It is surprising how such a simple mechanism can give rise to interesting information processing and how intelligence arise from neuronal activity remains the greatest open problem in neuroscience 15.1.1 Artificial neural networks In ANNs we consider a set of information processing units also called neurons and each neuron is connected to other neurons by weighted connections The neurons are organized in layers with connections from one layer feeding into the next',\n",
              " ', xM)) is presented to the input layer such that neuron i in the input layer is given an activation equal to xi  The activation is then propagated to one or several hidden layers and finally to the output layer consisting of one or more neurons corresponding to the coordinates of the output vector This process is known as a forward pass through the network 15.11 is illustrated a simple neural network with one hidden layer The input layer consists of three neurons, the hidden layer of four neurons and the output of a single neuron 1 By Glosser.ca [CC BY-SA 3.0 (http://creativecommons.org/licenses/by-sa/3.0)], via Wikimedia Com\\ufffemons256 15 Neural Networks Fig Simple artificial neural network (ANN) consisting of three input units in the input layer, a single hidden layer with four hidden units and two output units in the output layer This neural network would implement a mapping f : R 3 → R 2 and would be suitable for regression or classification in the case of two output variables',\n",
              " '15.1.2 The forward pass in details Recall the basic linear regression model in which the output y is predicted from the rule f(x, w) = X M i=1 xiwi + w0 If we let x˜ =  1 x1 x2  xM T we can write this in a more condensed form f(x, w) = x˜ T w The forward pass in a neural network now proceeds as follows for vector x: \\x88 Each neuron i in the input layer is initialized to have activity xi .\\x00\\x0015.1 The feedforward neural network 257 x h(x) −2 0 2 −1 −0.5 0 0.5 1 x h(x) −2 0 2 0 0.5 1 x h(x) −2 0 2 −2 0 2 Fig Different choices of activation function (Left:) hyperbolic tangent: h(x) = tanh(x) = e x−e−x ex+e−x , (middle:) logistic sigmoid h(x) = (1 + e −x ) −1 and (right:) rectified linear unit: h(x) = 0 if x < 0 and otherwise h(x) = x The basic information-processing ability is similar for all activation functions, but during training the choice may be important as the gradients will differ in magnitude',\n",
              " '\\x88 Neuron j in the hidden layer is given activity a (1) j = x˜ T w (1) j  Notice this is just a real number \\x88 Each of the H hidden unit are transformed using a nonlinear activation function h to give z (1) j = h(a (1) j ) We then define z (1) = h z (1) 1 z (1) 2  z (1) H iT \\x88 Output neuron k is given an activation of a (2) k = \\ufffe z˜ (1)\\x01T w (2) k \\x88 The output neurons are transformed using a function h (2) to give z (2) j = h (2)(a (2) k ) \\x88 The value of the neural network (output) is simply f(x) = h z (2) 1 z (2) 2  z (2) D iT  These steps may look daunting and it is perhaps useful to consider what they concretely mean Suppose we collect the various weight-terms into matrices and define W(1) = h w (1) 1 w (1) 2  w (1) H i and W(2) = h w (2) 1 w (2) 2  The activation of the kth output neuron is simply: fk(x, w) = h (2) \\uf8eb \\uf8ed X H j=1 W (2) kj z (1) j \\uf8f6 \\uf8f8 (15.1) = h (2) \\uf8eb \\uf8ed X H j=1 W (2) kj h (1) \\x10 x˜ T w (1) j \\x11 \\uf8f6 \\uf8f8',\n",
              " 'Simple neural network of 6 weights and with one hidden layer with 2 neurons Many choices of activation function can be found in the literature all with roughly the same basic information-processing abilities but with different characteristics under training A few common examples can be found in fig Example 15.1.1: Forward pass of a neural network Consider the feedforward neural network shown in fig The network has no bias weights Suppose the weights of the neural network after training are w31 = 0.05, w41 = 0, w32 = 0.1, w42 = −0.05, w53 = 0.1, w54 = −10 and the activation functions of the neurons in the hidden layer and output layer, i.e., n3, n4, and n5 all are given by the following leaky rectified linear unit h(x) = \\x1a x if x > 0 1 10x otherwise Suppose the network is evaluated on input x1 = 0.5, x2 = 1, the output is then computed by first evaluating the hidden layer: x3 = h(x10.05 + x20.1) =h(1/8) =1 8 , x4 = h(x10 + x2(−0.05))=h(−1/20)= −1 200',\n",
              " 'The construction can be immediately generalized to L layers by simply repeating the two steps in the hidden layer Written in a more condensed fashion we proceed as follow: \\x88 We define z (0) = x as the input activation \\x88 For each layer l = 1,  , L set z (l) = h (l) \\x10 (W(l) ) T z˜ (l−1)\\x11  \\x88 Return as output f(x, w) = z (L)  In general each hidden unit also contains a bias term corresponding to an additional input to each neuron of 1 with the corresponding weight term accounting for the bias (i.e., just as we appended a column of 1 to our input data x in regression to form x˜ we add a bias term as input to the neuron of the l’th layer using as input to the neuron z˜ (l−1) = [1 z (l−1)]) 15.2 Training neural networks Regardless if one choose a two-layer neural network with a single hidden layer, or a general L layer neural network, one simply obtains a parametric function f(x, w)',\n",
              " 'We are thus faced with a standard supervised learning problem where we are given instances of observations x1, x2,  , xN and corresponding targets y1 , y2 ,  , yN , and our solution will be very similar to what we already considered for linear and logistic regression: Since the neural network cannot be expected to perfectly map from xi to the corresponding yi , we will assume yi is normally distributed around the prediction of the neural network If y has dimension K, the probability density of observation yi is then: p(yi |xi , w) = N (yi |f(xi , w), Iσ2 ) = 1 (2πσ2) K 2 e − ∥yi−f(xi ,w)∥ 2 2σ2  (15.3) Applying the maximum likelihood framework from section 6.5, and for generality including a reg\\ufffeularization term as in chapter 14, we see once more that the value of w that maximize p(w|X, y) can be found by minimizing the cost function E defined as w∗ = arg min w Eλ(w) (15.4) Eλ(w) = 1 N X N i=1 ∥f(xi , w) − yi∥ 2 + λwT w where λ is the regularization strength we have to specify',\n",
              " 'In arriving at this formulation we considered the simple feed-forward neural network for regression, however, we stress that in nearly all appli\\ufffecations of neural networks, whether they are used to translate from French to English, recognize images or play Atari videogames, depend on specifying an appropriate function E and searching for the minimizing w∗  Thus, headway on solving the problem eq (15.4) can be used in a variety of contexts.260 15 Neural Networks w ′ → ← w ′′ ← w∗ w E(w) ← w∗ ← w (3) ← w (0) w E(w) Fig (left:) Value of error function in a one-dimensional example Weights at w ′ should move right and weights at w ′′ should move left in order to approach the minimum point w∗ of E(w) (right:) Gradient descent algorithm applied for three steps starting at w (0) 15.2.1 Gradient Descent⋆ The problem is that it is impossible to analytically solve for w∗  Instead, the following iterative algorithm is proposed: \\x88 Start from an initial guess at w∗ , w(0)',\n",
              " '\\x88 Do this for a large number T of iterations to produce (hopefully!) better and better guesses, i.e., w(0) , w(1) ,  After T iterations w(T) is then used as the “best” available guess of w∗  This algorithm is very simple if not for the unspecified step 2 To solve this we will use gradient descent which only requires E to be differentiable The one-dimensional case To introduce gradient descent, suppose w is one dimensional (the neural network only contains a single “weight”) and suppose E as a function of w looks like fig',\n",
              " 'Notice, if we compute the gradient of E at w ′ or w ′′ we have: dE dw (w ′ ) < 0 and dE dw (w ′′) > 0 Thus, if we let dw = −ϵ dE dw (w (t−1 )) be the gradient of E evaluated at w (t−1) multiplied by ϵ > 0 which is called the learning rate of the method (usually set somewhere in the interval [0, 1] for instance ϵ = 1/5), we can consider the simple update rule: θ (t) = θ (t−1) + dw It is easy to check this indeed works – in fig 15.4 is plotted w (t) and E(w (t) as a function of t when this rule is applied for 3 steps Notice that the method “slows down” when w (t) is closer to w ∗ as the magnitude of the gradient dE dw (w (t−1 )) becomes smaller; this is useful to prevent overshooting the target, however, it also potentially slows down the algorithm So why does this work We can formalize the above argument as follows Suppose for simplicity we define w ′ = w (t)',\n",
              " '(15.7) Thus, if we select dw = −ϵg in the above we get: E(w ′ + dw) = E(w ′ ) + dwg = E(w ′ ) − ϵg2  In other words we are guaranteed that if we let w (t) be equal to w ′ + dw = w (t−1) − ϵg then E(w (t) ) ≤ E(w (t−1)) This decreases the error with roughly an amount ϵg2 (this also explains why the error changes less and less in fig In this view, it is surprising why we don’t select ϵ to be very large – perhaps ϵ = 1000 The reason is that the Taylor expansion is only accurate for small values of dw, thus we can’t trust the above result when ϵ is very large Multiple dimensions We have spent some time on the one-dimensional case, however, the multi-dimensional case can be treated very similar In this case we can consider a small, perturbation dw of w ′',\n",
              " '(left:) Value of error function in a two dimensional example as a contour plot along with three steps of the gradient descent algorithm Notice the step size slows down when moving towards the minimum (right:) An example with two local minima If the gradient descent method is initialized at w ′ it will converge to the global minima w ∗ , whereas if it is initialized at w ′′ it will converge to a local minima at the bottom of the right-most valley The multi-dimensional Taylor expansion is briefly reviewed in appendix A Thus, if we select dw = −ϵg we again get E(w(t) ) = E(w(t−1) + dw) ≈ E(w(t−1)) − ϵ∥g∥ 2 ≤ E(w(t−1)), which again is seen to decrease the error assuming the Taylor expansion is fairly accurate This allows us to define the Gradient-descent algorithm as: \\x88 Start from an initial guess at w∗ , w(0) \\x88 For each t = 1,  , T, compute the divergence g (t−1) = ∇E(w(t−1)) \\x88 Compute w(t) = w(t−1) − ϵg',\n",
              " '15.5 we have illustrated how w is updated for three iterations in an example where w is two-dimensional Training neural networks in practice Gradient descent is the prototypical training algorithm for neural networks Most advanced appli\\ufffecations of neural networks use either plain gradient descent, or gradient descent with very simple modifications A serious omission of the preceding discussion is how to compute the gradient g efficiently If we consider the i’th coordinate of g, gi , this can be computed as:15.3 Neural networks for classification 263 gi = ∂E(w) ∂wi (15.11) = ∂ ∂wi   1 2 X N i=1 ∥f(xi , w) − yi∥ 2 + 1 2 λwT w  (15.12) = X N i=1 \"X D k=1 (fk(xi , w) − yik) ∂fk(xi , w) ∂wi # + λwi  (15.13) It should be stressed these computations are in principle just simply algebra: computing the derivative of a function with respect to a single variable wi',\n",
              " 'A further issue which should be mentioned is when E has different local minima 15.5 is shown a function E with two local minima If w (0) is initially selected to be at either w ′ or w ′′ it will find different solutions as indicated by the arrows and no amount of training will cause a move from the suboptimal solution (the first valley) to the optimal solution (the second valley) This is a difficulty of considerable practical interest as in higher dimensions there will typically be many local minima and so the solution w(T) , as well as the training error E(w(T) ), will depend on how the model is initialized w(0) as well as other parameters of the training 15.3 Neural networks for classification Making a neural network suitable for regression useful for classification is very similar to how we changed linear regression into logistic regression by the use of the Bernoulli distribution',\n",
              " '15.3.1 Neural networks for binary classification In the case of a binary classification problem, where y = 0 and y = 1, the procedure is entirely similar to how we derived the logistic regression model using the re-parameterization trick in section 5.4.3 Specifically, we assume: p(y|x, w) = Bernouilli(y|yˆ) = ˆy y (1 − yˆ) 1−t , yˆ = σ(f(x, w)) (15.14) Using this probability density in place of eq (15.3), the cost function to be minimized becomes: Eλ(w) = − 1 N X N i=1 [yi log ˆyi + (1 − yi) log(1 − yˆi)] + λw⊤w, yˆi = f(xi , w) (15.15) As usual, the minimization is done using gradient descend Note the particular case where the neural network network is linear (i.e., the activation function is just the identity function), we have f(x, w) = x˜ ⊤w and the neural network is simply implementing standard logistic regression.264 15 Neural Networks 15.3.2 Neural networks for multi-class classification Suppose y corresponds to a classification problem with C classes 1, 2,',\n",
              " 'We will assume y is one-of-K encoded in the usual manner: y = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8f0 0 1 0 1 0 0 1 0 0 0 0 1  \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fb , implying that the first observation is in class 2 (a cat), the second and third observations are in class 1 (a dog) and the fourth observation is in class 3, a cow As indicated, this is one-of-K encoded in the matrix P y such that yik = 1 if observation i is in class k and otherwise yik = 0 Notice C k=1 yik = 1 because each observation is in exactly one class What we need in order to apply the familiar maximum-likelihood machinery of section 6.5 is a way to express the probability p(yi =  yi1 yi2 · · · yiC  |xi , w) To do this, we will use the parameter transformation trick previously discussed in section 5.4.3 applied to the categorical distribution eq',\n",
              " 'For an example of how the softmax function works, see Example 15.3.1 The probability of a given observation can then be expressed using the categorical distribution eq (5.28) p(yi |xi , w) = Catagorical(yi |yˆi ) = Y C k=1 yˆ yik ik (15.17) Applying the maximum-likelihood framework to this cost function, and including a regularization term, we obtain the multi-class equivalent of eq (15.15) Eλ(w) = − 1 N X N i=1 \"X C k=1 yik log ˆyik# + λw⊤w (15.18) where: ˆyik = e fk(xi,w) PC c=1 e fc(xi,w) As usual, the optimal weights should be found using gradient descend.\\x00\\x00\\x00\\x0015.3 Neural networks for classification 265 Example 15.3.1: Softmax function Let’s consider a concrete example Suppose the output of a neural network is f1 = 2, f2 = 1 and f3 = −1 We then have that e f1 ≈ 7.39, ef2 ≈ 2.72, ef3 ≈ 0.37 and so yˆ = softmax(f) ≈  7.39 10.5 2.72 10.5 0.37 10.5  =  0.7 0.26 0.04  Therefore, the neural network indicate this observation should be classified as belonging to class 1 with probability 0.7',\n",
              " 'One way to accomplish this is to simply replace f(x, w) in eq (15.18) with a linear function; while this is certainly a valid way to proceed, there is one slightly annoying side-effect Recall from section 15.3.1 that in the case where we applied neural networks to a two-class classification task, the neural network had a single output neuron However, in the multi-class setting considered in section 15.3.2, the neural network had as many outputs C as there was classes This means that this approach to multi-class regression would not directly generalize the binary classification case To get around this, it is customary to implement linear multi-class classification using the (modified) softmax with C −1 inputs which we encountered in eq Specifically, assume X˜ is our dataset transformed in the usual manner by pre-fixing it with 1, and X˜ has dimensions N × M We then have: f(xi ,W) = Wx˜i where W is a general C − 1 × M-dimensional matrix of the form W = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8f0 w⊤ 1 w⊤ 2',\n",
              " 'We then define the objective using the modified softmax eq (5.31) E(W) = − X N i=1 \"X C k=1 yik log ˜yik# + λw⊤w, where: ˜yik = \\uf8f1 \\uf8f2 \\uf8f3 e w⊤ k x˜i 1+PC−1 c=1 ew⊤c x˜i if k ≤ C − 1 1 1+PC−1 c=1 ew⊤c x˜i if k = C This raises the obvious question why we didn’t use this parameterization of the softmax (which, after all, contains fewer parameters) for the multi-class neural network One answer is that the alternative parameterization creates an asymmetry between the classes, in that class C = 1 is\\x00\\x00\\x00\\x00266 15 Neural Networks special This does not matter as much the simple multinomial regression model which provides more robust parameter estimates, and where it is often considered important to be able to interpret the parameters However, for neural networks, nobody expects to interpret the parameters anyway, and the asymmetry is considered to be undesirable 15.3.4 Flexibility and cross-validation The strength of neural networks derives from their great flexibility',\n",
              " 'However it is what happens at the subsequent layers that really sets neural networks aside from decision trees: A decision tree would use the output of a single question to ask further questions, however a neural network combines the output of many other questions It is this ability that allows neural networks, especially deep neural networks (i.e neural networks with several/many hidden layers), to be extremely flexible The downside of this flexibility is that neural networks are prone to overfitting the data and it is therefore important to use cross-validation in conjunction with neural network training Neural networks provide many knobs to limit overfitting, most importantly the regularization parameters λ which should be tuned in most settings In addition to λ, it is worth experimenting with other parameters in the neural network, for instance the number of hidden layers, the number of units in each hidden layer and the choice of activation function',\n",
              " '15.4 Advanced topics⋆ In this section we will briefly sketch upon some advanced topics of neural network training 15.4.1 Mini-batching Gradient descent requires computing the divergence of the error ∇E(w) which in turn requires iterating over all observations in the data set If the data set contains millions of images (or billions of words) this would be completely infeasible Mini-batching is a simple yet very widely used approach to overcome this problem In mini-batching with a batch size of B the observations in the data set is divided into m = N B smaller data sets D1,  , Dm each containing B observations Instead of using the gradient: g = ∇E(w) = ∇  X N i=1 ∥f(xi , w) − yi∥ 2  we use the approximate gradients computed for the observations in each batch k:15.4 Advanced topics⋆ 267 gk = ∇E˜(w) = N B ∇  X i∈Dk ∥f(xi , w) − yi∥ 2  The gradient-descent method is thus simply \\x88 Start at w(0) \\x88 For each iteration t: \\x88 For each batch k = 1,',\n",
              " 'So why does this work From a theoretical point of view, we want the learning rate ϵ to be as high as possible However the neural network function is highly non-linear meaning that when the weights are changed even just slightly by −ϵg the local Taylor expansion becomes inaccurate and we have to re-compute the gradients This implies we have to select ϵ fairly small for the gradient descent method to work In mini-batching, we replace the true gradient g at a point w(t) with an approximate gradient gk  Even though this (as a rule) introduces more uncertainty in the algorithm, this uncertainty is relatively small comparable to the uncertainty already present due to the Taylor expansion not being very exact And since computing the approximate gradient is extremely inexpensive (scales with B and not N) taking many smaller steps in mini-batching becomes better than taking one step in ordinary gradient descent which is only slightly more exact than the smaller steps in mini-batching',\n",
              " 'If we use 1000 neurons in the first hidden layer, the first layer of the neural network alone would contain 999 × 999 × 1000 ≈ 109 weights (here we haven’t included the bias term for each neuron, which would add 1000 additional parameters) Not only is this a considerable computational burden, it is doubtful we have enough images to tune this many parameters in a meaningful manner A way to significantly cut down on the computational cost is using convolutions which can be sketched as follows: Suppose we consider a very small neural network with no hidden layer which takes an 11 × 11 input image and maps it onto a single neuron We can then “translate” this small neural network over the entire image by moving it in strides of F = 4',\n",
              " 'If we keep track of the output of the small neural network over all these patches, this leads to a new “hidden layer” of dimensions 247 × 247 where 247 = 999−11 F , however only about 121 = 112 weights were used to produce this output Including D such convolutional filters we obtain a hidden layer of dimensions 247 × 247 × D using only about 121 × D = 112 × D weights The process can (and should) be made more elaborate by using several such convolutional layers to allow greater flexibility and the process is typically repeated on the second hidden layer to produce an even smaller set of neurons, however these details need not concern us at this stage: The important point is that the same set of weights is “re-used” over the entire image which both cuts down on the number of weights and allow each weight to be trained using much more data',\n",
              " 'This kind of architecture is known as a convolutional neural network and forms the basis of the best image-recognition systems 15.4.3 Autoencoders Neural networks can be used as a powerful dimensionality reduction method known as an autoen\\ufffecoder  Take the completely standard feed-forward neural network considered in this chapter and suppose we have access to MNIST handwritten digit dataset However instead of predicting the identity of the digits yi from xi , we simply predict xi from xi  That is we model xi = f(xi , w) + ϵ, where ϵ is noise Notice, this is entirely trivial when one has a working neural network implementa\\ufffetion – simply replace yi with xi  The benefit of this approach is if one of the hidden layers contains less dimensions than there are pixels in the image, for instance H = 100, then the neural network will effectively learn a 100-dimensional representation of handwritten digits',\n",
              " '15.4.4 Recurrent neural networks In the brain information clearly does not simply flow in one direction as in the feedforward neu\\uffferal network An attempt to create more realistic neural networks, where information is processed multiple times by the same neural network, is a recurrent neural network Suppose we wish to train a neural network to read parts of a DNA sequence (a DNA sequence is simply a sequence of four letters, ACGT, repeated a varying number of times) and determine if the sequence is coding for a protein or not We assume we have access to example sequences xi as well as if they express genes or not, yi = 0, 1 This is a standard classification problem were it not for the fact the DNA sequences can have varying length One attempt to overcome this is as follows: Suppose each gene x is a sequence of letters in a one-of-K coding i.e x = (b1, b2,  , bS) for an S-long sequence We then introduce a new vector h which is initially zero',\n",
              " '\\x14 y h ′ \\x15 = f \\x12\\x14b h \\x15 , w \\x13  This is just a standard feed-forward neural network We can then apply it to an arbitrary long sequence by first initializing h (0) = 0 and evaluating \\x14 y (1) h (1)\\x15 = f \\x12\\x14 b1 h (0)\\x15 , w \\x13 and again for the second digit \\x14 y (2) h (2)\\x15 = f \\x12\\x14 b2 h (1)\\x15 , w \\x1315.4 Advanced topics⋆ 269 and so on until for the nth digit: \\x14 y (n) h (n) \\x15 = f \\x12\\x14 bn h (n−1)\\x15 , w \\x13  Continuing in this manner for S iterations produces a output y (S) which can then be compared against the ground truth This model is quite complicated, but writing out the function evaluation one can see that the final output y (S) is simply a function of w and the input string x: y = F(x, w) = f1  \\x14 bS f \\x12h bS−1 f \\x10 bS−2 · · ·T , w \\x11iT , w \\x13\\x15T , w  Thus, we can train the neural network using gradient descent on the combined function F The network is called recurrent since it (recursively) updates the intermediate variable h which allows it to “remember” information found in the beginning of the gene',\n",
              " '15.4.5 Serious neural network modelling The recent success in neural network modelling is partly due to the creation of powerful com\\ufffeputational environments which can automate much of the construction of neural network algo\\uffferithms Two of the most popular frameworks are the open-source framework Theano http:// deeplearning.net/software/theano/ and Tensorflow https://www.tensorflow.org/ by google Both of these frameworks rely on python and powerful GPU-implementations of the underlying op\\ufffeerations Students who has a serious interest in neural networks should try to learn one of these frameworks and not try to build the neural networks from the ground up The benefits of the framework include \\x88 Automatic computation of derivations and building of inference code \\x88 Automatic tuning of relevant parameters \\x88 Automatic validation \\x88 Automatic GPU-implementations and (more recently) automatic parallelization of code to run on many CPUs and GPUs',\n",
              " 'It is highly recommended to keep a log book to track the performance of different neural architectures to see if progress is being made towards solving the problem.\\x00\\x00270 15 Neural Networks Problems 15.1 Question 1: Which one of the following state\\ufffements pertaining to regression is correct A In regularized least squares regression the aim is to introduce more variance by reducing substantially the model’s bias B In least squares regularized regression the regulariza\\ufffetion strength λ is chosen to be the value of λ that minimizes the term λw⊤w C An artificial neural network with linear transfer func\\ufffetions (q(t) = t) can be written in terms of a linear regression model D For regression problems backward or forward selec\\ufffetion can be used to define which part of the output that is relevant for modeling E Don’t know Question 2: Consider a feedforward neural net\\ufffework shown in fig The network has no bias weights',\n",
              " ', n5 nodes is the thresholded linear func\\ufffetion f(x) = \\x1a x if x > 0 0 otherwise Suppose the network is called evaluated on input x1 = 1, x2 = 2, what is the output Input Layer Hidden Layer Output Layer Fig Simple neural network of 6 weights A yˆ = 0.04 B yˆ = 0.0 C yˆ = 1.0 D yˆ = 0.16 E Don’t know Question 3: Consider the classification problem given in Figure 15.7 The problem is solved using a 1- nearest neighbor classifier, a decision tree, an artificial neural network with four hidden units and a logistic re\\ufffegression model All the classifiers are only using the at\\ufffetributes x1 and x2 The decision boundaries are indicated in gray and white We would like to know which classi\\ufffefier each of the four decision boundaries in Figure 15.7 correspond to Which one of the following statements is correct The decision boundaries given in white and gray of four different classifiers used to separate red crosses from black circles',\n",
              " 'B Classifier 1 is the artificial neural network , Classifier 2 is the 1-nearest neighbor, Classifier 3 is the decision tree, and classifier 4 is the logistic regression model C classifier 1 is the logistic regression model, Classifier 2 is the decision tree, Classifier 3 is the 1-nearest neigh\\ufffebor classifier, and classifier 4 is the artificial neural network classifier D Classifier 1 is the logistic regression model, Classifier 2 is the 1-nearest neighbor, Classifier 3 is the decision tree, and classifier 4 is the artificial neural network E Don’t know Question 4: Consider the classification problem given in fig Suppose the problem is solved using the following four classifiers (1NN) A 1-nearest neighbour classifier (TREE) A decision tree (LREG) Logistic regression15.4 Advanced topics⋆ 271 (NNET) An artificial neural network with four hidden units All classifiers are using only the two attributes x1, x2, corresponding to the position of each observation, as well as the class label',\n",
              " 'P3 P1 P4 P2 −1 −0.5 0 0.5 1 −1 −0.5 0 0.5 1 −1 −0.5 0 0.5 1 −1 −0.5 0 0.5 1 −1 −0.5 0 0.5 1 −1 −0.5 0 0.5 1 −1 −0.5 0 0.5 1 −1 −0.5 0 0.5 1 Fig Two-class classification problem Class 1 Class 0 x2 x1 −1 −0.5 0 0.5 1 −1 −0.8 −0.6 −0.4 −0.2 0 0.2 0.4 0.6 0.8 1 Fig Two-class classification problem A P1 is LREG, P2 is 1NN, P3 is TREE, P4 is NNET B P1 is LREG, P2 is TREE, P3 is NNET, P4 is 1NN C P1 is LREG, P2 is TREE, P3 is 1NN, P4 is NNET D P1 is TREE, P2 is LREG, P3 is NNET, P4 is 1NN E Don’t know.16 Class imbalance Class imbalance refers to the situation where the classes in a dataset are not represented equally The problem with class imbalance is that it confounds our ability to fairly assess the performance of our model using for instance accuracy Consider the following example: Suppose Ken is devising a test for Ebola',\n",
              " '(16.2) This is probably the worst Ebola test imaginable – but nobody is ever going to discover that by looking at the accuracy In this section, we will consider strategies for evaluating models in the presence of class imbalance for a binary classifier While class imbalance can certainly be present in the multiclass setting, the binary setting is simpler and many of the same comments apply Because class imbalance is a so frequently occurring feature of many datasets, it has a long history in a variety of fields, see Chawla [2005] for an overview The main measure we will consider in this chapter, the area under curve (AUC) of the receiver operating characteristic (ROC), was originally invented by British radar engineers around the beginning of the world war II to analyse radar signals [Collinson, 1998]',\n",
              " 'Furthermore, in many situations class imbalance is not just common but expected, for instance if we are trying to detect fraud in a set of credit card transactions or build a system to recognize obstacles on the road In this chapter, we will consider a few ways to combat class imbalance in increasing degree of sophistication: Resampling: where the dataset is changed.274 16 Class imbalance Positive class Negative class 0 0.2 0.4 0.6 0.1 0.2 0.3 TP = 5 TN = 2 FN = 1 FP = 2 N = 10 Actually Positive Actually Negative Predicted Positive Negative Predicted (False Positive) (True Negative) N + = 6 (True Positive) (False Negative) N − = 4 Fig (Left:) A small N = 10 observation binary classification problem and the classification boundary (Right:) The confusion matrix of the classifier in the left-hand pane The inserts (ticks on background) indicate which observations counts towards which numbers in the confusion matrix Penalization: where the relative importance of the classes are changed',\n",
              " '16.1.1 Resampling The simplest way to handle class imbalance is to change the dataset There are two variants: If the dataset is very large, we can consider under-sampling where we simply remove (by random) observations of the over-represented class until the two classes have the same size Alternatively, we can try over-sampling where we add copies from the under-sampled class until the two classes have the same size These approaches are very simple to implement and therefore provide an excellent starting point, however, they also have obvious drawbacks: In the first case we loose information, in the second case we must take into account some methods can be very influenced by duplicated observations 16.1.2 Penalization Penalization works by scaling the relative importance of the two classes Recall the definition of the confusion matrix which is reproduced for convenience in fig 16.1 and which we encountered earlier in section 8.2.1 of chapter 8',\n",
              " 'Let’s assume that it is the positive class which is over-represented We can then consider a “scaled” accuracy measure of the form: Accuracy-scaled = TP 2N + + TN 2N − .16.1 Dealing with class imbalance 275 Let’s assume we are in the imbalanced setting where N + = 1000 and N − = 10 A classifier that puts everything in the positive class would have an accuracy of 1000 1010 ≈ 99%, but a scaled accuracy of only 1000 2×1000 + 0 2×10 = 50% corresponding to random guessing (also notice the scaled and true accuracy are both 1 if the classifier is perfect) A disadvantage of the scaled accuracy is that it is also 50% if everything is classified as belonging to the negative class which might seem counterintuitive because all but 10 observations are then classified incorrectly In general, the errors of the classifier are not equally important',\n",
              " 'In this case labelling a few good transactions as fraud\\ufffeulent, FP, (transactions that are actually negative labelled positive) is not so bad, but labelling fraudulent transactions as good, FN, correspond to a loss of money We can therefore consider a general measure of the quality of the classifier of the form w1TP + w2FN + w3FP + w4TN, (16.3) where w1, · · · , w4 are constants As a crude example, in the credit-card system we could choose w1 = 2, w2 = −1000, w3 = −1 and w4 = 0.01 to signify that classifying non-fraudulent transactions as non-fraudulent (which happen very often) is good (weight 0.01), labelling fraudulent transactions as fraudulent is even better (weight 2; keep in mind this happens rarely) but incorrectly labelling a fraudulent transaction as non-fraudulent is very bad (weight −1000) The drawback of this method is that the user has to specify w1, w2, w3 and w4',\n",
              " 'The obvious answer is that it is bad because we loose customers and, ultimately, money A way around the problem could therefore be to figure out the expected loss of money for each classification outcome: How much do we expect to loose by (incorrectly) closing a credit card and annoy a customer and how much do we expect to loose by not closing a credit card in time This information could in turn be used to select w1,  , w4 in the penalization scheme eq Keep in mind that especially in medical applications this may lead to fairly uninviting utilitarianism when bad medical decisions are balanced against monetary concerns Precision and recall Two terms relating to the performance of a classifier which roughly falls within the above category is the precision and recall They are simply defined as: Recall: TP TP + FN = TP #{Observations in the positive class} , Precision: TP TP + FP = TP #{Observations predicted as positive}',\n",
              " 'The recall can trivially be improved by labelling all observations as positive, however the precision will suffer if all observations are labelled positive Both of these measures are different from for instance the accuracy in that they place more emphasis on the positive class For instance in a credit-card fraud detection system, where fraud corresponds to the positive class, high recall is the measure of how many actually cases of fraud are caught Meanwhile precision might be appropriate in a case where false positive comes at a significant cost, for instance medical screening The harmonic mean of the276 16 Class imbalance Negative, yi = 0 Positive, yi = 1 yˆi = f(x, w) −5 0 5 10 0 0.05 0.1 0.15 0.2 0.25 0.3 Negative, yi = 0 Positive, yi = 1 yˆi = f(x, w) Density of observations −5 0 5 10 0 0.05 0.1 0.15 0.2 0.25 0.3 Fig A dataset consisting of a positive yi = 1 class and a negative yi = 0 class The x-position indicates the predicted y-value by a classification model',\n",
              " 'precision and recall is a popular measure of performance defining the so-called F1 score (also known as the F-measure or F-score) given by F1 = \\ufffe 0.5(Precision−1 + Recall−1 ) \\x01−1 = 2Precision · Recall Precision + Recall Notably, F1 is zero if either the precision or recall is zero and one if both precision and recall are one 16.2 Area-under-curve (AUC) The final strategy we will consider for the class-imbalance problem is to change the performance measure to implicitly take class imbalance into account In order to do so we need to take a step back and consider what a classifier actually does Consider therefore a standard two-class classification problem with observations xi and output yi where yi = 0 means observations i belongs to the negative class and yi = 1 means observations i belongs to the positive class Suppose we build a classifier that assigns to each observation i a number ˆyi yˆi = f(xi , w)',\n",
              " 'For instance in logistic regression, ˆyi is a (continuous) probability in the interval [0, 1] such that the higher ˆyi is the more likely it is to belong to the positive class How do we evaluate such a classifier The first step is to translate the continuous numbers ˆyi into binary class-predictions The simplest way is to introduce a parameter θ and simply assign all i where ˆyi > θ to the positive class and all i where ˆyi ≤ θ to the negative class 16.3 is show\\x0016.2 Area-under-curve (AUC) 277 Negative, yi = 0 Positive, yi = 1 Labelled as positive Labelled as Negative ← θ yˆi = f(x, w) Density of observations −5 0 5 10 0 0.05 0.1 0.15 0.2 0.25 0.3 Negative, yi = 0 Positive, yi = 1 Labelled as positive Labelled as Negative ← θ yˆi = f(x, w) Density of observations −5 0 5 10 0 0.05 0.1 0.15 0.2 0.25 0.3 Fig The dataset considered in fig 16.2 with a positive yi = 1 class and a negative yi = 0 class and where the x-position indicates the predicted y-value by a classification model',\n",
              " 'two different thresholds Notice, the different thresholds have a large influence on the behaviour of the classifier: If we use the high (shown in the left plot) threshold, it is very unlikely to ever say an observation that in fact is negative (yi = 0) belongs to the positive class, whereas it will be slightly prone to falsely saying an observation which is in fact positive (yi = 1) is negative The other threshold has the opposing effect Since the threshold is chosen arbitrarily, when we wish to discuss the performance of a classifier f, we must take into account the different threshold values This requires some terminology 16.2.1 The confusion matrix and thresholding Each thresholding level θ produce a confusion matrix For convenience this is illustrated in fig 16.4 and are: True Positives, TPθ: Number of observations which are in fact positive yi = 1 which the clas\\ufffesifier correctly labels as positive ˆyi > θ',\n",
              " 'False Negatives, FNθ: Number of observations which are in fact positive yi = 1 which the classifier incorrectly labels as negative ˆyi < θ True Negatives, TNθ: Number of observations which are in fact negative yi = 0 which the classifier correctly labels as negative ˆyi < θ Notice, these numbers depend on θ Since the class sizes (the total number of positive examples and negative examples) may differ significantly it is common to normalize with the class sizes We thus define the true positive rate and false positive rate as:278 16 Class imbalance Labelled as Negative Labelled as positive ← θ T Pθ 0 0.2 0.4 0.6 0.8 1 Labelled as Negative Labelled as positive ← θ F Pθ 0 0.2 0.4 0.6 0.8 1 Labelled as Negative Labelled as positive ← θ F Nθ 0 0.2 0.4 0.6 0.8 1 Labelled as Negative Labelled as positive ← θ T Nθ 0 0.2 0.4 0.6 0.8 1 Fig',\n",
              " 'The areas then respectively indicate the number of true positives, false positives, false negatives and true negatives See text for details FPRθ = FPθ FPθ + TNθ , (16.4) TPRθ = TPθ TPθ + FNθ , (16.5) where by definition TPθ + FNθ is the total number of positive examples and FPθ + TNθ is the total number of negative examples An illustration of how these numbers depend on θ is probably in order 16.5 is illustrated three values of the threshold θ 16.6 we have plotted the TPR and FPR for each of these values as solid dots whereas the line indicate all other values of θ Notice, the colors agree with fig Let’s try to make some sense of why the curves look the way they look When θ is very low, everything is labelled as positive, and so the true positives has to be all the positives and therefore the true positive rate (TPR) is 1',\n",
              " 'Illustration of our two classifiers with three different threshold values TPR FPR Threshold θ Rate 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 False Positive Rate (FPR) True Positive Rate (TPR) 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fig (left:) Illustration of the TPR and FPR curves for different thresholds for the classifier indicated in fig The solid points corresponds to the three specific threshold values indicated (right:) Illustration of the receiver operating characteristic (ROC) curve The AUC is simply the area under this curve obtained by plotting TPRθ against FPRθ for different values of θ High AUC is good everything is labelled negative and so the TPR becomes 0 Roughly, the same goes for the false positives First, all elements in the negative class are (incorrectly) labelled as positive, and therefore the false positive rate is 1',\n",
              " 'Eventually, everything is labelled as negative and so there are no false positives This is why the curves start at 1 and ends at 0 and the TPR is normally above the FPR With these definitions, we can simply plot values of (FPRθ, TPRθ) for all conceivable values of θ forming the receiver operating charecteristic (ROC) curve given in the right-pane of fig Since the TPR is normally higher than the FPR, the curve will generally be above the diagonal indicated by the dotted line This allows us to define the Area Under Curve (AUC) as simply the area under the curve of the ROC curve shown in the right-hand side of fig 16.6 (which can be obtained by numerical integration)',\n",
              " 'Illustration of three different threshold values for an inferior classifier The classifier is inferior since the two predicted classes overlap such that no single threshold can tell them apart TPR FPR Threshold θ Rate 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 False Positive Rate (FPR) True Positive Rate (TPR) 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fig (left:) Illustration of the TPR and FPR curves for different thresholds for the inferior classifier indicated in fig The solid points corresponds to the three specific threshold values indicated (right:) Illustration of the AUC; the AUC is simply the area under the curve obtained by plotting TPRθ against FPRθ for different values of θ High AUC is good, i.e this classifier is worse than that indicated in fig 16.5 Let’s re-assure ourselves the AUC really behaves like a performance evaluator',\n",
              " 'the classifier works perfectly On the other hand, let’s suppose we have an inferior classifier as indicated in fig 16.7, again with three values of θ selected The corresponding plot of the TPR and FPR and AUC is given in fig This curve is much closer to the dotted line, indicating a lower value of the AUC Hopefully, these examples are sufficient persuasion the AUC evaluates the performance of the classifier, but the reader is encouraged to investigate what an AUC of 0.5 would correspond to In conclusion, the area under curve (AUC) is a performance measure for classifiers, which has two desirable properties: First, it allows us to get rid of the dependence of θ by integrating over all the conceivable values of θ Secondly, it accounts for imbalanced classes due to the normalization16.2 Area-under-curve (AUC) 281 of the TPR and FPR by the number of observations in the true and false class respectively',\n",
              " 'Question 1: Considering the data in Table 16.1, we will use x1 to classify whether a subject has inflam\\ufffemation of urinary bladder (y = 1) or not (y = 0) We will quantify how useful x1 is for this purpose by calculating the area under curve (AUC) of the receiver operator char\\ufffeacteristic (ROC) Which one of the ROC curves given in Figure 16.9 corresponds to using the feature x1 to deter\\ufffemine if a subject has inflammation of urinary bladder x1 x2 x3 x4 x5 y P1 1 1 1 1 0 1 P2 0 0 0 0 0 0 P3 1 1 0 1 0 0 P4 0 1 1 0 1 0 P5 1 1 1 1 1 1 P6 0 0 0 0 0 0 P7 1 1 0 1 0 0 P8 0 1 1 0 1 0 P9 1 1 1 1 0 1 P10 0 1 1 0 1 0 P11 0 0 0 0 0 0 P12 1 1 0 1 0 0 P13 0 1 1 0 1 0 P14 0 1 1 0 1 0 Table 16.1 Provided in the above table are the last 14 ob\\ufffeservations of the acute inflammation data Four different receiver operating characteristic (ROC) curves and their corresponding area under the curve (AUC) A The curve with AUC=0.636 B The curve with AUC=0.864 C The curve with AUC=0.909 D The curve with AUC=1.000',\n",
              " 'Question 2: Fig Proposed ROC curves for the logistic regression classifier in fig To evaluate the classifier fig 16.11, we will use the area under curve (AUC) of the reciever operator charac\\ufffeteristic (ROC) curve as computed on the 7 observations in fig 16.10 is given four proposed ROC curves, which one of the curves corresponds to the clas\\ufffesifier?16.2 Area-under-curve (AUC) 283 Fig Output of a logistic regression classifier trained on 7 observations from the dataset A ROC curve 1 B ROC curve 2 C ROC curve 3 D ROC curve 4 E Don’t know Question 3: Consider the true positive rate (TPR), and false positive rate (FPR) as a function of the threshold θ for the problem of N = 1000 observa\\ufffetions shown in fig Suppose we consider pre\\ufffedictions made at a threshold of θ = 0.3, and suppose we are told that the number of true negatives at θ = 0.3 is T N = 489, the TPR at this threshold is T P R = 0.412 and the FPR at this threshold is F P R = 0.164',\n",
              " 'False positive rate (FPR) True positive rate (TPR) TPR and FPR Threshold value 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 A TPR and FPR Threshold value 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 B TPR and FPR Threshold value 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 C TPR and FPR Threshold value 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 D Fig Proposed values of the TPR and FPR, as cal\\ufffeculated for N = 1000 predicted values, for different values of the threshold θ A T P = 93 B T P = 171 C T P = 275 D T P = 381 E Don’t know.17 Ensemble methods Ensemble methods are methods where multiple models are trained and their outputs are then combined to obtain better predictive performance than each of the methods on their own',\n",
              " 'The benefits of this procedure in machine learning is twofold: Firstly, averaging many classifiers produces a classifier with less variance than each of the individual classifiers This allows us to use classifiers with larger variance and therefore better ability to tell observations apart while being less sensitive to the occasional overfitting of each individual classifier, much like using an aggregate of several doctors opinion can be used to rule out the occasional crank doctor Secondly, while most classifiers may assign two hard-to-tell-apart observations to the same class, it may be that a few classifiers in the ensemble can tell the two observations apart, much as how many doctors may have difficulties telling two diagnosis apart where but a few specialist doctors can (The specialists may then not be able to tell other observations apart but hopefully other specialists in the ensemble can) In this chapter, we will consider two methods for ensemble methods, bagging and boosting',\n",
              " 'The idea behind bagging has roots going back to [Dasarathy and Sheela, 1979] and was applied to neural networks by [Hansen and Salamon, 1990] The most famous application of bagging, random forests where bagging is applied to decision trees, was initially developed by Ho [1995] and later developed into the method of random forest by Breiman [2001] Boosting was developed in the very early 90s by Schapire [1990] and the particular method we will consider here, AdaBoost, was developed about 10 years later by [Freund and Schapire, 1997] 17.1 Introduction to ensemble methods The basic idea of ensemble methods is very simple: train multiple models and combine their outputs into a single model as illustrated in fig Let’s consider how this combination takes place before we discuss how the ensemble of models is produced: Suppose M1,',\n",
              " 'Combining T models M1,  ,MT to a single classifier M∗ using majority voting (classification) or averaging (regression) is often a useful strategy to come up with a classifier which outperforms each individual model (Regression:) y = 1 T X T t=1 ft(x) (17.1) Alternatively, suppose M1,  ,MT are classifiers, i.e f(x) = y = 1,  We can then combine their outputs by letting each classifier “vote” for an output and then select the class which most classifiers agree is the correct one (Classification:) f(x) = arg max c=1,...,C {Number of classifiers which output ft(x) = c}, (17.2) this is known as majority voting In case of ties, the classifier can just select at random from the tied classes So why might ensemble methods work Suppose we consider a binary classification problem with T independent classifiers',\n",
              " 'The graph as a function of T is plotted in fig In reality we do not have access to independent classifiers even if we are using quite different methods, however, in practice combining different classifiers, especially when they rely on different assumptions, often performs better than simply using the best classifier, and for machine-learning competitions this is a strategy which is often used by the winner A problem with combining T classifiers is that it requires about T times as much work to create T classifiers as it takes to create one A strategy which is therefore often used is to use the same classifier, but train it on different training datasets, see fig There are essentially two strategies:17.2 Bagging 287 Number of classifiers T Chance combined classifier is correct 1 3 5 7 9 11 13 15 0.5 0.6 0.7 0.8 0.9 1 Fig If T independent classifiers is combined using majority voting, each with an accuracy of only p = 0.7, the accuracy of the resulting classifier quickly approaches 1',\n",
              " '\\x88 Apply different transformations to the training set, for instance images can be rotated or trans\\ufffelated \\x88 Select a subset of features \\x88 Re-sample subsets of the training set The first technique is specific to the application, however, it is very often used in Neural-network applications to images The second technique is very popular for decision trees and is used in random forests which we will consider in section 17.3 The third technique, resampling the dataset, and depending on how the dataset is resampled we either obtained bagging or boosting which we will consider in the following sections 17.2 Bagging Bagging begins with a dataset D of size N, and then randomly selects T new datasets D1,  , DT of size N′ ≤ N by randomly subsampling D The simplest strategy is to set N′ = N and sample each Dt by randomly selecting N points from D with replacement That is, the same points may occur many times in each Dt and some points may be omitted',\n",
              " '(17.1) or eq This procedure is illustrated in fig 17.3 and the number of classifiers T can either be selected as a high (but tractable) number or selected using cross-validation Typically, about 100-1000 classifiers are used.288 17 Ensemble methods D M∗ Create multiple datasets Create multiple classifiers Combine classifiers D1 D2 D3 DT M1 M2 M3 MT Fig A different strategy for obtaining multiple classifiers is to create T new datasets D1,  , DT from the training dataset D and train classifiers to each of the dataset The T obtained classifiers can then be combined as in fig Class 1 Class 2 Fig (left:) A simple 2D classification problem with two classes and two features (middle:) A logistic regression model is fitted to the data to give the class-probability indicated with the colors (right:) thresh\\ufffeolding the logistic regression output at 0.5 gives the classification boundary indicated by the colors This is the decision rule of the classifier',\n",
              " '17.4 (left) The dataset is fitted with a standard logistic regression model giving the linear decision boundary p(y|x, D) shown in the middle pane Since we are only interested in the class labels for the majority-voting scheme eq (17.2) we will assume the predictions of the logistic regression model is threshold at 0.5 to produce the decision boundary shown in the right pane 17.5 bagging is illustrated for T = 8 In each pane, a subset of the datasets are selected at random and the points not selected are shown as hollow circles As can be seen, there is quite a lot of variability in the decision surfaces since the datasets are random and consists of few observations.17.2 Bagging 289 Fig Example of bagging for the classification problem in fig In each pane, a new training set Dt is obtained by sampling N points with replacement from D and a logistic regression model is fitted Notice, not all observations are selected and some points may be selected multiple times',\n",
              " '17.6 the bagging classifiers are combined, i.e., for each point x we plot the bagged classifiers’ predictions: y = 1 T X T t=1 ft(x), (17.3) and the black line corresponds to y > 1 2 corresponding to majority voting eq As seen from the figure, each single classifier is worse than the classifier which used all data shown in fig 17.4 (middle and left pane), however, the errors average out and produce a decision boundary which follows the dataset slightly better than any single logistic regression model In the right-pane of fig 17.6 is shown the same bagging setup but using T = 100 classifiers Again, we see the use of many classifiers average out the errors and produces (some) non-linearity in the classification rule which (slightly) better follows the data',\n",
              " 'A diverse pool of classifiers can be obtained by for instance including extra features using feature transformations (for instance high-order Taylor expansions such as x 2 i ) or varying the parameters in each of the models in the bagging ensemble When we consider random forests in section 17.3 we will look at a technique for creating a diverse class of classifiers by manipulating the tree-learning method.290 17 Ensemble methods Fig (left:) By averaging the individual prediction boundaries from fig 17.5 using eq (17.3) we can define the majority voting rule The resulting classification boundary (i.e thresholding at 0.5) is indicated by the black line In the right pane the same construction is shown but for T = 100 datasets Notice, the resulting rule is smoother and still slightly non-linear 17.3 Random Forests Random forests is simply an application of bagging to decision or regression trees',\n",
              " 'In order to introduce random forests let’s first discuss the simple bagging procedure applied to decision or regression trees: Bagging first produces T datasets (by sampling with replacement) from the original dataset (X, y), then train the standard decision tree algorithm on each sampled dataset to produce a predictor ft(x) for t = 1,  , T and finally combine the predictors using either eq (17.1) (regression) or eq (17.2) (classification) As for the logistic regression example, a problem is that the decision trees will often select the same splits over and over again at the root and directly adjacent branches creating very correlated trees To overcome this, Breiman [2001] proposed that when generating tree Tt, at each step of Hunt’s algorithm, Hunt’s algorithm should only consider splits from m < M of the features selected at random from all M features (new sets are considered for each new node of the tree)',\n",
              " 'There are a few other ingredients to the method found in Breiman [2001], however, the random\\ufffeness at the feature-selecting step and bagging are the main ones Typically, T is taken to be of the order 100-1000 and m = √ M for classification and 1 3M for regression [Hastie et al., 2009, Chapter 15].17.4 Boosting 291 17.4 Boosting As we saw bagging produced some non-linearity in the decision surface of a linear classifier (i.e., logistic regression), however, at least for the considered problem it was quite slight and it still had difficulty with the island of orange points A message to take away from the problem is that most of the observations are easy to classify, however some are very hard An alternative strategy would therefore be to select the hard-to-classify observations more often than those which are easy to classify and thereby create classifiers which are better suited to solve the hard part of the classification problem This is basically the idea in boosting',\n",
              " 'wi is the probability of selecting this particular observation when creating the bagging data set, i.e wi > 0 and PN i=1 wi = 1 In the bagging algorithm wi = 1 N , however, in boosting the idea is to iteratively adjust wi depending on how difficult observation i is to classify The basic boosting algorithm is illustrated in fig 17.7 and consists of the following steps: \\x88 We first select a training set D1 by sampling N observations with replacement with probability wi of selecting an observation i; the dataset D1 with a fitted logistic regression model is shown in the left-most pane Notice, usually not all points are selected \\x88 In the next step the decision boundary is used to see which of all points in the training dataset are classified incorrectly marked with red in the second pane from the left',\n",
              " 'The weights still sum to 1; this is indicated by the size of the points in the third pane of fig \\x88 Finally, a new dataset D2 is selected by randomly sampling according to the new weights and the procedure is repeated for this new dataset, i.e a new classifier trained on D2, weights updated a new dataset sampled and so on Obviously, we still need to specify how the weights are updated One can try to come up with a reasonable scheme based on one’s intuition, however the weight-updating problem can be analyzed using decision theory which has led to the AdaBoost algorithm [Freund and Schapire, 1997] 17.4.1 AdaBoost Suppose we denote by w(t) the weight of the observations at step t which determines how likely that observation is to be included in the training set',\n",
              " '(17.4) 1 To get a feeling for this definition, recall the delta-function δa,b is defined as δa,b = ( 1 if a = b 0 if a ̸= b  The combined classifier f ∗ can therefore be understood to first compute the number of “votes” for the positive class: P i:yt(xi)=1 αi (and similarly for the negative class, a − = P i:yt(xi)=0 αi) and then output 1 if α + > α− and otherwise 0292 17 Ensemble methods Fig Illustration of a boosting sweep (Top left:) a dataset Dt is selected by random sampling from D with replacement but with probability wi of selecting observation i and a logistic regression model is fitted to the dataset Points not selected are hollow (Top right:) all points are classified using the trained classifier and the misclassified observations are shown in red (Bottom left:) the weights wi corresponding to the red misclassified points are increases and the rest are decreased (indicated by the size)',\n",
              " 'The AdaBoost algorithm updates w(t) and αt by first computing the weighted error: ϵt = X N i=1 wi(t) \\ufffe 1 − δft(xi),yi \\x01 (17.5) The importance of the classifier at step t is then computed as: αt = 1 2 log 1 − ϵt ϵt (17.6) and finally the new weights w(t + 1) are updated by computing\\x0017.4 Boosting 293 Fig The (importance-weighted) decision function eq (17.4) when Boosting is applied for T = 10 (left) and T = 500 (right) rounds, The decision boundary is indicated by the black line Notice, the decision boundary is highly non-linear and for T = 500 (right) perfectly fits the training data even though each classifier is linear wi(t + 1) = w˜i(t + 1) PN j=1 w˜j (t + 1) (17.7) where ˜wj (t + 1) = ( wj (t)e −αt if ft(xj ) = yj wj (t)e αt if ft(xj ) ̸= yj  Thus, this mechanism either up- or downscales the weights with a factor depending on the impor\\ufffetance parameter at the current round, αt',\n",
              " 'The full AdaBoost procedure can be seen in algorithm 7 and in fig 17.8 we have plotted importance\\ufffeweighted decision functions When AdaBoost is applied to the N = 16-observations example considered previously for T = 10 or T = 500 boosting rounds the individual AdaBoost classifiers are much more extreme since they are trained on fewer datapoints, however, when many AdaBoost classifiers are averaged the decision boundary becomes highly non-linear and is able to separate the two classes.294 17 Ensemble methods Algorithm 7: AdaBoost algorithm 1: Initialize wi(1) = 1 N for i = 1,  , N 2: for t = 1,  , T do 3: Create Dt by sampling (with replacement) from D according to w(t) 4: Let ft be the classifier trained on Dt 5: ϵt = PN i=1 wi(t) \\ufffe 1 − δft(xi),yi \\x01 (weighted error of ft on all data) 6: αt = 1 2 log 1−ϵt ϵt 7: For each i update weights using eq (17.7): wi(t + 1) = w˜i(t + 1) PN j=1 w˜j (t + 1) , w˜i(t + 1) = ( wi(t)e −αt if ft(xi) = yi wi(t)e αt if ft(xi) ̸= yi',\n",
              " 'It can be shown the training error of the ensemble classifier f ∗ is bounded by ϵ ∗ ≤ Y T t=1 2 p ϵt(1 − ϵt), where ϵt are the error rates of each of the classifiers as described in algorithm 7 Suppose each error rate is less than 50%, we can then write ϵt = 1 2 − γt Then γt measures how much better the classifier is than random guessing and by standard inequalities: ϵ ∗ ≤ Y T t=1 2 p ϵt(1 − ϵt) = Y T t=1 q 1 − 4γ 2 t ≤ e −2 PT t=1 γ 2 t  Consequently, if all γt ≥ γ0 then the training error of the ensemble is bounded as ϵ ∗ ≤ e −2γ 2 0 T and thus decreases exponentially in T This may sound like great news, however, recall from chapter 10 a low training error is not in itself a good sign Theoretical analysis of AdaBoost reveals that with high probability: [Freund and Schapire, 1997] Test error ≤ Train error + O  r dT N  , where d is a term dependent of the complexity of our classification model and O(·) means a term that scale no faster than what is in the parenthesis',\n",
              " 'In addition, we do not know the scaling factor of the second term so the above result should not be taken as predicting the test error is lower than the training error which it will almost certainly never be From an intuitive perspective, whe\\x0017.4 Boosting 295 we only select a very small subset of training points in each round t (the difficult points), each classifier is very prone to overfitting which is why the combined classifier can fit the training data perfectly When the classifiers are combined, this average out some of the overfitting, however, the combined classifier may still be overfitting the data which plausibly is already happening in fig In practice, AdaBoost often turns out to work very well and increases performance, however, as always it is important to test if that is actually the case using for instance cross-validation.296 17 Ensemble methods Problems 17.1',\n",
              " 'Training and applying the decicion tree to the full dataset X and y1,  , y4 gives predictions ˆy1,  , yˆ4 shown in table 17.1 y yˆ 1 1 1 0 0 0 0 0 Table 17.1 True values yj and predictions ˆyj for a decision tree classifier trained on the full data set with observed values y1,  To improve performance Jane decides to apply Ad\\ufffeaBoost, however Jane implements AdaBoost such that instead of sampling the N elements of the training sets Di with replacement, Jane samples the training sets with\\ufffeout replacement, i.e the training set Di is simply the full dataset Suppose Jane applies AdaBoost for k = 1 round of boosting, what is the resulting (approximate) value for the weights w A w =  0.123 0.630 0.123 0.123 B w =  0.167 0.5 0.167 0.167 C w =  0.081 0.756 0.081 0.081 D w =  0.077 0.769 0.077 0.077 E Don’t know Question 2: Which one of the following state\\ufffements pertaining to bagging or boosting is correct A In boosting miss-classified observations are given less importance in the next round',\n",
              " 'C Boosting uses leave-one-out cross-validation to learn which observations to sample in the next round D When combining multiple classifiers using bagging the classifier with the best performance is selected E Don’t know.\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00Part III Unsupervised learning18 Distance-based clustering techniques In this and the following chapters we will consider unsupervised learning techniques In the previous sections we considered the dataset as being composed of a data matrix X and a set of target values y In unsupervised learning we assume we only have X and our goal is to infer structure in X such as a clustering (which observations naturally group together), outlier detection (which observations are anomalous), density estimation (how typical is a given observation), and association mining (what are prominent patterns of binary feature co-occurrence)',\n",
              " 'In this chapter, we will consider the particular unsupervised learning problem of identifying groups, or clusters, of data points in a space of arbitrary dimension Recall a clustering of a set of observations is simply a division of the set of observations into non-overlapping sets, often illus\\ufffetrated as a coloring of the observations We will consider two methods, K-means and agglomerative hierarchical clustering Both of these methods are similar in that they are distance-based How\\ufffeever, they differ in that K-means attempts to identify K clusters, whereas hierarchical clustering identifies a nested clustering K-means clustering was first discovered by the polish mathematician Hugo Steinhaus in 1956 [Steinhaus, 1956] but given its name and popularized by MacQueen et al The ba\\ufffesic hierarchical clustering algorithm was discovered by Johnson [1967]',\n",
              " 'We will therefore begin by discussing some general categories of clustering described in Tan et al 18.1.1 The distance-based cluster types The simplest cluster types are the simple, distance-based types illustrated in fig 18.1 and which are all defined by the distance between observations and (possible) the center of clusters They are:300 18 Distance-based clustering techniques Well-Separated 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Center-Based 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Contiguity-Based 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fig Illustration of the three simple cluster types The colors indicate the clusters Well-separated Each point is closer to all points in its cluster than any point in another cluster As we will see, hierarchical clustering with max-linkage assumes clusters are well-separated when identifying clusters Center-based Each point is closer to the center of its cluster than to the center of any other cluster',\n",
              " 'Contiguity-based Each point is closer to at least one point in its cluster than to any point in another cluster Hierarchical clustering with min-linkage takes a contiguity-based approach to finding clusters 18.1.2 More elaborate cluster types The above three basic types of clustering are the simplest, but it is possible to consider methods that rely on more elaborate (or specific) definitions of what constitutes the clustering A particular important example are density-based clustering (where a cluster is a group of observations that lie unusually close to each other), however we have also included conceptual clusters as a separate category for cluster-definitions that does not fit any of the other descriptions, see fig Density-based Clusters are regions of high density separated by regions of low density The Gaus\\ufffesian mixture-model, which we will consider in chapter 19 takes a density-based approach to finding clusters',\n",
              " '18.2 K-means clustering The goal of K-means clustering is to take as input an arbitrary data set X comprised of N observa\\ufffetions x1,  , xN in a D-dimensional space and then partition (or cluster) the data observations into18.2 K-means clustering 301 Density-Based 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Conceptual 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fig Illustration of two more elaborate cluster types Note we do not have any general methods for finding conceptual clusters −1.5 −1 −0.5 0 0.5 1 1.5 −1.5 −1 −0.5 0 0.5 1 1.5 Fig 2D K-means example dataset Observations are indicated by gray points and the initial location of the K-means cluster locations are indicated as the colored squares In the example, the location of the clusters are initialized at random A natural way to represent such a partition is as a coloring, where each of the K groups corresponds to one of K colors and the clustering then corresponds to coloring the observations',\n",
              " 'This notation can be formalized by introducing a vector µk for each group k = 1,  , K which represents the typical location (or prototypical element) of the group An observation xi then belongs to the cluster k where the distance (typically based on the Euclidean distance ∥xi −µk∥) is the smallest and as we will see in a moment the µk ’s represent the centers of the clusters However, before explaining why the K-means algorithm is the way it is, it is easier to explain what it does since it is such a simple algorithm.302 18 Distance-based clustering techniques −1.5 −1 −0.5 0 0.5 1 1.5 −1.5 −1 −0.5 0 0.5 1 1.5 −1.5 −1 −0.5 0 0.5 1 1.5 −1.5 −1 −0.5 0 0.5 1 1.5 −1.5 −1 −0.5 0 0.5 1 1.5 −1.5 −1 −0.5 0 0.5 1 1.5 −1.5 −1 −0.5 0 0.5 1 1.5 −1.5 −1 −0.5 0 0.5 1 1.5 −1.5 −1 −0.5 0 0.5 1 1.5 −1.5 −1 −0.5 0 0.5 1 1.5 −1.5 −1 −0.5 0 0.5 1 1.5 −1.5 −1 −0.5 0 0.5 1 1.5 Fig Example of running the K-means algorithm for three iterations and K = 4 clusters',\n",
              " 'Then in the next step (top-left) the cluster location vectors µk are updated to correspond to the mean of the assigned points This procedure is repeated in the second row, however, in the third row (bottom-left) the cluster assignments do not change and the method has therefore converged Suppose we wish to apply the K-means algorithm (based on Euclidean distance) to the 2D dataset shown in fig 18.3 (gray circles) for K = 4 clusters The location of each of the four µk cluster locations are indicated by the colored squares This is accomplished by the following steps: \\x88 First, initialize each µk at a random location as shown in fig 18.3.18.2 K-means clustering 303 \\x88 Assign each of the gray points to the nearest µk  It now belongs to this cluster 18.4 (top-left pane) the region belonging to each cluster is indicated by the colors \\x88 Update the location of each µk to be the mean of the points assigned to it 18.4 this is shown in the top-right pane',\n",
              " '18.4 this is shown in row two and three 18.2.1 A closer look at the K-means algorithm So why does the K-means algorithm look the way it does The objective of the K-means algorithm is to find a set of K vectors µ1 ,  , µK as well as an assignment of observations to clusters such that the sum-of-squares of each observation to the nearest vector µk is minimized If we for each point i introduce a binary variable zik describing which cluster k = 1,  , K observation i belongs to, such that if xi belongs to k then zik = 1 and zih = 0 for h ̸= k Considering Euclidean distance we can define the sum-of-squares between each point to the cluster it is assigned to as: E = X N i=1 X K k=1 zik∥xi − µk∥ 2 2  (18.1) Our goal is then to find values of zik and µk to minimize E The two steps in the K-means algorithm accomplish exactly this In the first step, the upper-left pane of fig 18.4, we keep the µk ’s fixed and minimize zik',\n",
              " 'Obviously, this corresponds to selecting zik = 1 for the k where µk is the closest (in Euclidean distance) to xi  In other words: zik = ( 1 if k = arg minh ∥xi − µh∥ 2 2 0 otherwise (18.2) Now consider the second step, the upper-left pane of fig 18.4, where the location µk are updated and zik are kept fixed If we consider the derivative of the objective function with respect to µk we obtain: ∇µk E = 2X N i=1 zik(xi − µk ) (18.3) Setting this equal to zero and solving we obtain: µk = PN i=1 zikxi PN i=1 zik  (18.4) However, the nominator is simply the sum of those observations assigned to cluster k, and the denominator is simply the number of observations assigned to k, so the expression is simply the mean of the observations assigned to cluster k (notice, the update for the µk depends on the distance measure and a change in distance measures may also lead to a change in the updates for the cluster locations)',\n",
              " 'This is also why the K-means algorithm converges; since each step makes the error E smaller, and E ≥ 0, the algorithm must converge.304 18 Distance-based clustering techniques K Sum-of-squares error E 1 2 3 4 5 6 0 100 200 300 400 500 600 Fig Value of the sum-of-squares error function E in the converged state for the 2D dataset shown in fig 18.3 for different values of K The error decreases when K is increased, however, a suitable choice of K can potentially be found as where the drop in error levels off In this case K = 4, which visually also seems to be an appropriate choice 18.2.2 Practical issues with the K-means algorithm The K-means algorithm is a very simple and efficient clustering algorithm, however, it has some drawbacks Firstly, since we rely on the Euclidian distance, it prefers clusters that are “round” and of roughly equal size',\n",
              " 'Secondly, while the K-means algorithm converges quickly, what clustering it converges to depends on how it was initialized For this reason, it is often useful to consider a particular strategy when initializing the K-means algorithm and consider several restarts with different initialization One popular (and simple) choice of initialization is the farthest-first procedure Gonzalez [1985] according to which for k = 1,  , K we initialize µk by: \\x88 Randomly assign one of the observations to be the location of the first cluster center, i.e \\x88 Initialize each subsequent µk as the observation xi which is the farthest away from the cluster it is currently assigned as being closest to of µ1 ,  This initialization ensures the locations µk are well spread-out over the dataset and often gives much faster convergence and better final positions Thirdly, during the K-means algorithm, it is possible that a cluster µk has no observations assigned to it',\n",
              " 'Finally, K-means requires us to choose a suitable K This is a difficult problem and there is no single agreed-upon solution One heuristic procedure is to run the K-means algorithm using different choices of K and consider the K where the drop in error levels off This is done for the dataset in fig 18.4 for K = 1,  , 6 and the sum-of-squares error can be seen in fig 18.5, and the figure suggests K = 4 where the drop in error levels off.18.3 Hierarchical agglomerative clustering 305 Fig Hierarchical agglomerative clustering applied to the 2D dataset shown in the top right Each point is assigned to a singleton cluster (top middle), and the closest clusters are then merged until all clusters have been merged The dendrogram illustrates which clusters are merged in each step and the height of each added clamp is the distance of the two merged clusters 18.3 Hierarchical agglomerative clustering A difficulty in K-means clustering was the requirement of finding a single agreed-upon value K',\n",
              " 'The bottom of the hierarchy correspond to the finest partition (each observation is in a unique (singleton) cluster)306 18 Distance-based clustering techniques Fig By cutting the dendrogram at different heights, a different number of clusters can be obtained As we will see, the shape of the dendrogram can be used as an indication of an appropriate cut-height whereas the top-level of the hierarchy corresponds to the coarsest possible partition corresponding to putting every observation in the same cluster Once again it is easier to show what hierarchical agglomerative clustering does than start with a mathematical definition Recall K-means required a measure of distance between observations (the Euclidian distance) Hierarchical agglomerative clustering requires a measure of distance between groups of observations We will later show natural examples, however, for now assume we are given such a measure Hierarchical agglomerative clustering is then illustrated in fig',\n",
              " 'This correspond to the bottom-layer of the hierarchy shown as an insert \\x88 Iteratively merge the two closest clusters In the hierarchy, this is indicated by drawing a “clamp” between the corresponding clusters The y-location of the vertical bar in the clamp corresponds to the distance of the two clusters \\x88 Repeat until all observations are merged into a single cluster The hierarchy which is constructed is known as a dendrogram The dendrogram is tree-structured and by construction corresponds to a nested sequence of partitions Since the y-location of the vertical bars where clusters are merged indicate their location, the dendrogram can give a visual summary of both the algorithm and the data and is part of why hierarchical clustering is popular Notice, the hierarchical agglomerative clustering algorithm is deterministic and converges in N − 1 steps; to obtain a particular clustering one can cut the dendrogram at a given height, see fig',\n",
              " 'Illustration of the three most popular linkage function, maximum (complete) linkage, minimum (single) linkage and average linkage 18.3.1 Selecting linkage function Recall in hierarchical agglomerative clustering, we merged the closest clusters in each step This requires a distance function between groups of observations If we assume we have a distance function between individual observations, for instance just the Euclidian distance d(xi , xj ) = ∥xi − xj∥2, we can define such a distance function in three ways indicated in fig Consider two groups C1 and C2 of observations we can then define the three linkage functions as: Minimum (or single) linkage Here the distance between the groups is the distance between the closest pair of observations d(C1, C2) = min x∈C1,y∈C2 d(x, y) (18.5) Maximum (or complete) linkage Here the distance between the groups is the distance between the most distant pair of observations d(C1, C2) = max x∈C1,y∈C2 d(x, y)',\n",
              " 'Ward’s method Another popular choice of linkage function is Ward’s method (or simply Ward linkage) which is inspired by the K-means algorithm Suppose at a given step of the clustering algorithm there are K clusters We then compute the K centroid vectors µ1 , · · · , µK as the mean of each cluster and compute the K-means error already introduced in eq (18.1): E = X N i=1 X K k=1 zik∥xi − µk∥ 2 2  The two clusters whose merger provides the smallest increase in the above error are then merged, see also fig 18.9.308 18 Distance-based clustering techniques Ward’s Method Fig Ward’s method for linkage At each step, the sum-of-squares error of the distance from each observation to its cluster center is computed, and the clusters, which provides the smallest increase in the error, is merged Thus, hierarchical agglomerative clustering requires that we select the linkage function from the outset',\n",
              " 'We will illustrate this with three examples 18.10 we consider a dataset consisting of two half-moons We apply hierarchical agglomer\\ufffeative clustering, cut the dendrogram at a height corresponding to two clusters, and color the dataset accordingly Each row shows a linkage function, at the top maximum linkage, in the middle average linkage and at the bottom minimum linkage As indicated, both average and maximum linkage cannot find the right clusters, whereas minimum linkage does Minimum linkage (bottom) only cares about the nearest set of observations, thus, it will chain together the two moons since each point in any of the moons is closer to another point in the same moon On the other hand, maximum linkage (top) cares about the furthest distance Thus, it favors clusters which are round and very compact Average linkage is somewhere in between the two methods and produce clusters which are (roughly) comparable to K-means',\n",
              " 'Notice also the relative scale of the dendrogram y-axis As expected, single linkage merge everything at a much lower height than complete linkage This also gives an indication of where minimum linkage may get into problems Since minimum linkage only cares about the closest pairs of observations, if there is a chain of observations between two clusters minimum linkage will use these to chain together the two clusters This is indicated in fig In the top-row, complete linkage (which is focused on compactness) finds the four clusters, whereas in the bottom-row, single linkage fails as there is a slight “chain” of points merging the two right-most clusters Furthermore, a small group in the bottom-right is slightly further away from the other clusters and is assigned by single linkage its own cluster at this level of the dendrogram',\n",
              " 'Finally, consider the dataset comprised of two differently-sized clusters shown in fig For clusters of different size, complete linkage fails because complete linkage, when for instance determining where a point in the middle belongs, cares about the distance to the edges of the two point-clouds Thus, it will try to roughly divide the point-clouds along the middle which in this case is wrong Single-linkage on the other hand is ideally suited because there are no outliers and a clear gap between the two point-clouds, this is also indicated by the dendrograms.18.3 Hierarchical agglomerative clustering 309 0 2 4 6 8 10 12 14 16 0 2 4 6 8 10 0 0.5 1 1.5 2 Fig Each row corresponds to hierarchical agglomerative clustering applied to the 2D dataset with different linkage functions The choices are maximum linkage, average linkage, and minimum linkage The colors indicate a cut-off corresponding to two clusters',\n",
              " 'Notice also the qualitative difference of the three dendrograms In conclusion, complete linkage works well when all clusters are roughly round, of equal size or there are outliers in the dataset It fails when clusters have very different size, are shaped oddly or they are defined by being connected.310 18 Distance-based clustering techniques 0 0.5 1 1.5 2 2.5 0 0.05 0.1 0.15 0.2 0.25 Fig Hierarchical agglomerative clustering applied to 2D dataset with complete/maximum (top) and single/minimum (bottom) linkage Notice, single linkage is confused by the observations lying between the two right-most clusters, and the outliers, complete linkage is more robust and produce more compact clusters Single linkage on the other hand works well for the case where the clusters are internally con\\ufffenected and separated by gaps It fails when there is outliers in the data or the dataset is otherwise very noisy 18.4 Comparing partitions How do we evaluate a partition-based model',\n",
              " 'Hierarchical agglomerative clustering applied to 2D dataset with maximum (top) and minimum (bottom) linkage In this case maximum linkage (top row) tries to produce compact clusters of roughly equal size and thereby incorrectly mixes up the two blobs Minimum linkage easily solves the problem since the two clusters are spatially separated recommendation It is plausibly the case there is no definite way to evaluate a clustering After all, different people might have different preferences Consider for instance how different people might group the set of all animals, some may group them according to their utility (pets, domestic animals, dangerous animals, etc.) whereas others might cluster them based on their species and others again based on their behaviour (flying, swimming, crawling, burrowing) In this section, we will not attempt to cut this Gordian knot, but rather suppose we have access to side information (i.e',\n",
              " 'The first step in any such procedure is to consider how different two clusterings are This is a necessary312 18 Distance-based clustering techniques Z Q Fig A dataset of N = 9 observations are clustered into two partitions Z and Q indicated by the colors In the case of Z there are K = 3 clusters and for Q there are M = 4 clusters component to any supervised evaluation of a clustering method and so this will be our focus of this section: To produce a proper measure of the difference between a clustering Z and Q We will use the running example in fig 18.13 where the N = 9 observations are clustered into two partitions Z and Q indicated by the colors The example illustrates two problems when comparing partitions',\n",
              " 'Suppose the observations are labeled by i = 1, · · · , N and the cluster assignments for partition Z is z1, · · · , zN such that zi = k means observation i is in cluster k Similarly we denote q1, · · · , qN as the cluster assignments for Q We will denote the total number of clusters in Z and Q as K and M respectively Example 18.4.1: Encoding partitions To completely de-mystify the notation, consider the two partition-example in fig Suppose we label the colors 1 (yellow), 2 (blue), 3 (red) and 4 (green), we then have: Z =  1 1 1 1 2 2 3 3 3 Q =  4 4 1 1 2 2 2 3 3 An in this case, K = 3 and M = 4 The particular numbers would refer to the ground-truth class or partition number as obtained by a clustering method',\n",
              " ', that is, the highest value in Z is K and the largest value in Q is M.\\x00\\x00\\x00\\x00\\x00\\x0018.4 Comparing partitions 313 Before continuing, we will introduce a few results which can be defined purely from Z and Q First, recall the delta function is defined as δhk = ( 1 if h = k 0 otherwise Therefore, the number of observations in Z which belongs to cluster k can be computed as {Number of observations in cluster k in Z} = X N i=1 δzi,k More fundamentally, we will define the joint count matrix n as the K × M matrix defined as: nkm = {Number of observations assigned to cluster k in Z and m in Q} = X N i=1 δzi,kδqi,m (18.8) Based on this matrix, we can count the number of observations assigned to cluster k in Z (and similarly, m in Q) as: n Z = {Number of observations assigned to cluster k in Z} = X M m=1 nkm (18.9) n Q = {Number of observations assigned to cluster m in Q} = X K k=1 nkm (18.10) In the following, all measures we introduce will be expressed using the joint count matrix n',\n",
              " 'Finally, a surprise counting exercise which will prove very useful Suppose we wish to count the possible (distinct) pairs we can make out of n observations To count this, the first observation can be paired to all n−1 other observations, the second to all n−2 (but excluding the first, as we have counted this pair), the third can be paired to n − 3 and so on All in all: {Distinct pairs of n observations} = (n − 1) + (n − 2) + · · · + 2 + 1 + 0 = n(n − 1) 2 (18.11)314 18 Distance-based clustering techniques Example 18.4.2: Counting matrix, continued To continue the example in fig 18.13, for instance n14 = 2 as observations 1 and 2 are assigned to cluster 1 (yellow) and 4 (green) in Z and Q respectively Generally, the reader is encouraged to verify: n = \\uf8ee \\uf8f0 2 0 0 2 0 2 0 0 0 1 2 0 \\uf8f9 \\uf8fb Note the horizontal/vertical sums of n: n Z = \\uf8ee \\uf8f0 4 2 3 \\uf8f9 \\uf8fb , n Q =  2 3 2 2 Agree with the number of observations assigned to each cluster Finally, we can test our counting result',\n",
              " 'A very patient reader can verify the total number of pairs is N(N−1) 2 = 9 × (9 − 1) × 1 2 = 36 18.4.1 Rand index Consider two distinct observations i, j To say that partition Z is similar to Q is to say that when i and j are placed in the same cluster in partition Z, they will also most often be together in partition Q and vice versa To make this more concrete, i, j are both in the same cluster in Z and Q if and only if δzizj = 1 and δqiqj = 1 Therefore, both partition Z and Q agree that i, j are in the same cluster only if 1 = δzizj δqiqj = Sij , (which is otherwise 0) Similarly, both partition Z and Q agree that i, j are not in the same cluster only if 1 = (1 − δzizj )(1 − δqiqj ) = Dij',\n",
              " '(18.12) Notice that the way the Rand index both counts matches and non-matches (S and D) makes it somewhat comparable to the SMC.\\x00\\x0018.4 Comparing partitions 315 Z Q Fig Counting the pairs of observations contributing to S, i.e., pairs of observations the two partitions agree are in the same clusters Expressing the Rand index using the counting matrix We can re-express the Rand index using the counting matrix First, focus on S, pairs of observations assigned to the same cluster in both partitions Each number nkm represent observations assigned to cluster k in Z and m in Q We can form nkm(nkm−1) 2 distinct pairs of these and therefore we can conclude: S = X K k=1 X M m=1 nkm(nkm − 1) 2',\n",
              " '18.13, if we focus on the Q-partition, the green, yellow and red observations are all in the same blocks in the Z-partition as is one pair of blue observations (see fig Similarly we can count the pairs of observation both partitions agree are not in the same cluster which is illustrated in fig For more details see Example 18.4.3316 18 Distance-based clustering techniques Z Q Fig Counting the pairs of observations contributing to D, pairs of observations the two partitions agree are in different clusters (here only shown for partition Z for simplicity)',\n",
              " '18.4.2 Jaccard similarity A problem with the Rand index is that if there are many clusters, there will typically be many more pairs of observations in different clusters than in the same cluster and so in general we can expect D ≫ S which means the Rand index is often close to 1 The reader might notice this problem, and indeed the definition of the Rand index, is very similar to the definition of the simple matching coefficient where we also counted the number of times two vectors agreed on the negative and positive matches We can therefore considered the Jaccard similarity where we disregard the trivial 00 matches:18.4 Comparing partitions 317 J(Q, P) = S 1 2N(N − 1) − D (18.20) Notice it is still the case that 0 ≤ J(Q, P) ≤ 1 Example 18.4.4: Jaccard similarity We can easily compute the Jaccard similarity as all quantities are known We get: J(Q, P) = 4 1 2 9 · 8 − 24 = 1 3',\n",
              " 'It is similar to Jaccard similarity and Rand index but theoretically better motivated Normalized mutual infor\\ufffemation is based on the idea of quantifying how much information one partition provides about the other partition Recall from our earlier discussion of information theory in section 5.5 all we have to specify to compute the mutual information is a joint distribution pkm(k, m) of two variables k and m, and then we can compute the mutual information mechanically (see Box 5.5.1) The two events we are interested in is simply that an observation is assigned to a given cluster, and the joint density corresponds to the event a particular observation is assigned to one cluster in k in Z and at the same time m in Q In other words, we simply define pkm(k, m) = nkm N where nkm is the familiar counting matrix',\n",
              " 'To do this, we define the probability an observation is assigned in k and m as: pkm(k, m) = nkm N , for k = 1,  , K and m = 1,  , M Based on this matrix, we can define the marginal distributions as the K and M-dimensional vectors: pk(k) = X M m=1 pkm(k, m), pm(m) = X K k=1 pkm(k, m) The Entropy in the 1 and 2d-case is then defines as: H[Z] ≡ H[pk] = − X K k=1 pk(k) log pk(k) H[ZQ] ≡ H[pkm] = − X K k=1 X M m=1 pkm(k, m) log pkm(k, m) In both cases, it measures the complexity of pk and pkm in bits In addition, the mutual information and normalized mutual information is defined as: MI[Z, Q] = MI[pkm] = H[Z] + H[Q] − H[ZQ] NMI[Z, Q] = NMI[pkm] = MI[Z, Q] p H[Z] p H[Q]  Where the NMI[Z, Q] is understood as measuring the overlap of the two partitions.18.4 Comparing partitions 319 Example 18.4.5: Mutual information, example To continue our example fig',\n",
              " 'Similarly, the entropy of both partitions is: H[pZQ] = H[ZQ] = − X K k=1 X M m=1 pZQ(k, m) log pZQ(k, m) = −4 × 2 9 log 2 9 − 1 9 log 1 9 = 1.58 From this, we can easily compute the Mutual information and Normalized mutual informa\\ufffetion: MI[Z, Q] = H[Z] + H[Q] − H[Z, Q] ≈ 1.06 + 1.37 − 1.58 ≈ 0.85 and NMI[Z, Q] = MI[Z, Q] p H[Z] p H[Q] ≈ 0.85 √ 1.06√ 1.37 ≈ 0.70.320 18 Distance-based clustering techniques Problems 18.1 Question 1: In Table 18.1 is given the pairwise distances between the four smallest and four largest is\\ufffelands in the Gal´apagos data A hierarchical clustering is used to cluster these eight observations using single (i.e., minimum) linkage Which one of the dendrograms given in Figure 18.16 corresponds to the clustering Hierarchical clustering of the eight observations considered in Table 18.1',\n",
              " 'Pairwise Euclidean distance, i.e d(Oa, Ob) = ||xa − xb||2 = pP m(xam − xbm) 2, between eight observa\\ufffetions of the Gal´apagos data Red observations (i.e., O1, O2, O3, and O4) correspond to the four smallest islands whereas blue observations (i.e., O5, O6, O7, and O8) correspond to the four largest islands A Dendrogram 1 B Dendrogram 2 C Dendrogram 3 D Dendrogram 4 E Don’t know Question 2: Consider the simple 1-dimensional data set comprised of N = 7 observations as shown in table 18.2 Suppose we wish to apply K-means clustering to the dataset and the K = 3 one-dimensional cluster centers are initialized in µ1 = 4, µ2 = 7 and µ3 = 14 After terminating of the K-means clustering algorithm, what are the final (rounded) cluster centers µ1, µ2, µ3 X 3 6 7 9 10 11 14 Table 18.2 Simple 1-dimensional dataset comprised of N = 7 observations A µ1 = 3.00, µ2 = 8.00, µ3 = 12.50 B µ1 = 3.00, µ2 = 7.33, µ3 = 11.67 C µ1 = 4.50, µ2 = 9.25, µ3 = 14.00 D µ1 = 5.33, µ2 = 10.00, µ3 = 14.00 E Don’t know',\n",
              " 'A hierarchi\\ufffecal clustering is used to cluster these nine observations using group average linkage Which of the dendrograms shown in fig 18.17 corresponds to the clustering Dendrogram 3 Dendrogram 4 Dendrogram 1 Dendrogram 2 o2 o6 o1 o3 o7 o5 o4 o8 o2 o6 o1 o3 o7 o5 o8 o4 o3 o6 o1 o2 o7 o5 o8 o4 o3 o6 o1 o2 o7 o5 o4 o8 0 2 4 6 8 10 0 2 4 6 8 10 0 2 4 6 8 10 0 2 4 6 8 10 Fig Hierarchical clustering of the 8 observations con\\ufffesidereded in table 18.318.4 Comparing partitions 321 o1 o2 o3 o4 o5 o6 o7 o8 o1 0 4 7 9 5 5 5 6 o2 4 0 7 7 7 3 7 8 o3 7 7 0 10 6 6 4 9 o4 9 7 10 0 8 6 10 9 o5 5 7 6 8 0 8 6 7 o6 5 3 6 6 8 0 8 11 o7 5 7 4 10 6 8 0 7 o8 6 8 9 9 7 11 7 0 Table 18.3 Pairwise Cityblock distance, i.e d(oi, oi) = ∥xi − xj∥1 = PM k=1 |xik − xjk|, between 8 observations Each observation oi corresponds to a M = 15 dimensional binary vector, xik ∈ {0, 1} The blue observations {o1, o2, o3, o4} be\\ufffelong to class C1 and the black observations {o5, o6, o7, o8} belong to class C2 A Dendrogram 1',\n",
              " 'C Dendrogram 3 D Dendrogram 4 E Don’t know Question 4: Figure 18.18 contains four dendro\\ufffegrams generated according to the distance matrix given in Table 18.4 By thresholding dendrogram 2 we obtain the following clusters Cluster 1: A4, B1, B2, B3 Cluster 2: A1, B4 Cluster 3: A2 Cluster 4: A3 Let mij denote the number of observations of class j in cluster i, mi = P j mij denote the number of observa\\ufffetions in cluster i, and m = P i mi denote the total num\\ufffeber of observations Let further pij = mij mi denote the probability that a member of cluster i belongs to class j The purity of cluster i is given as pi = maxj pij and the overall purity of a clustering is given as P purity = K i=1 mi m pi  Let the class an observation belongs to be defined in terms of whether the person considered has a liver disease (i.e., B1, B2, B3 and B4) or not (i.e., A1, A2, A3, and A4) What is the purity of the above clustering',\n",
              " 'Euclidean distances between four selected sub\\ufffejects without a liver disease (denoted A1, A2, A3, and A4) and four selected subjects with a liver disease (denoted B1, B2, B3 and B4) Four dendrograms generated according to the distance matrix given in Table 18.4 A purity = 1 8 B purity = 1 2 C purity = 2 3 D purity = 3 4 E Don’t know.19 Mixture models for unsupervised clustering The goal of density estimation is to describe the probability distribution a given set of observation X have originated from Learning probability distributions is relevant in a number of contexts Consider for instance a standard application of Bayes’ theorem p(y = c|x) = p(x|y = c)p(y = c) PC c ′=1 p(x|y = c ′)p(y = c ′) Applying this to a practical problem involves estimating the C densities p(x|y)',\n",
              " 'In this chapter we will focus on probabilistic estimation of densities using the Gaussian mixture-model and a particular simple way to train the Gaussian mixture-model known as the Expectation maximization (EM) algorithm Mixture models were first considered around the middle of the 19th century and their explicit statement is usually attributed to the biostatistician Karl Pearson who used mixture models to analyse the length of crabs [Pearson, 1894] The EM algorithm was first named by Dempster et al [1977], however, ideas reminiscent of the EM algorithm has been used in different contexts before this 19.1 The Gaussian mixture model The goal of the Gaussian mixture-model (GMM) is to derive a distribution for an M-dimensional vector x ∈ RM which we will write as p(x) We wish this distribution to be potentially very flexible and a common strategy for obtaining this in a tractable manner is to make p(x) be a combination of simpler, more tractable elements',\n",
              " 'The multivariate normal distribution for an M-dimensional vector is defined as the density: N (x|µ, Σ) = 1 p (2π) d|Σ| e − 1 2 (x−µ) T Σ−1 (x−µ) ,324 19 Mixture models for unsupervised clustering x y Probability Density −3 −2 −1 0 1 2 3 −3 −2 −1 0 1 2 3 0.02 0.04 0.06 0.08 0.1 0.12 0.14 x y −2 0 2 −2 0 2 Fig Example of the probability density function of a 2-dimensional multivariate normal distribution In left it is plotted as a function of x = [x y] T , i.e N (x|µ, Σ), whereas on the right the same distribution is shown as a contour plot where µ ∈ RM is the mean and Σ is the M ×M covariance matrix An example is given in fig 19.1 corresponding to the multivariate normal distribution Σ = \\x14 1 0.8 0.8 1 \\x15 and µ = \\x14 0 0 \\x15  In the Gaussian mixture-model (GMM) we want to use the multivariate normal distribution as a building block to create a more flexible distribution Suppose K is an integer for instance K = 4 Let’s imagine we select an integer 1,',\n",
              " 'For instance z =  0 1 0 0T , is the event we selected k = 2 Then z is a binary vector where only one entry can be non-zero at a time Suppose the probability we select k is πk: P(We select option k) = πk, then a little thought reveals that p(z) = Y K k=1 π zk k  Well if we take the above example, we get: p(z =  0 1 0 0T ) = Y K k=1 π zk k = π 0 1π 1 2π 0 3π 0 4 = π2,\\x00\\x00\\x00\\x0019.1 The Gaussian mixture model 325 p(x) x −3 −2 −1 0 1 2 3 0 0.2 0.4 0.6 0.8 1 p(x|z1 = 1) p(x|z2 = 1) p(x|z3 = 1) p(x|z4 = 1) x −3 −2 −1 0 1 2 3 0 1 2 3 x2 p(x) −5 0 5 −5 0 5 0 0.02 0.04 0.06 0.08 0.1 0.12 x y −5 0 5 −6 −4 −2 0 2 4 6 Fig Top row: One-dimensional Gaussian mixture model example with K = 4 mixture components In the left column is shown the density, p(x), and in the right pane the K = 4 individual mixture components Notice the weights scale the mixture components in the density In the lower pane is shown a 2D Gaussian mixture model, also with K = 4, both as a 3D surface plot and as a contour plot',\n",
              " 'We now imagine that when we know what k is, for instance k = 2, then we know what distribution x has, specifically we assume it is a multivariate normal distribution with parameters µk and Σk To put this in symbols p(x|zk = 1) = N (x|µk , Σk) We can once again write this in the simpler form p(x|z) = Y K k=1 N(x|µk , Σk) zk , (19.2) since for instance,326 19 Mixture models for unsupervised clustering Algorithm 8: Expectation-Maximization algorithm 1: Initialize µk , Σk and πk for k = 1,  , K 2: while The likelihood L changes do 3: Update γik = P N(x|µkΣk)πk K k′=1 N(x|µk′Σk′ )πk′ (E-step) 4: Update the parameter values in this order (where Nk = PN i=1 γik): (M-step) 5: µk = 1 Nk PN i=1 γikxi 6: Σk = 1 Nk PN i=1 γik(xi − µk )(xi − µk ) T 7: πk = Nk N 8: Compute the likelihood L = PN i=1 log hPK k=1 πkN (xi|µk , Σk) i 9: end while p(z =  0 1 0 0T ) = N (x|µ1 , Σ1) 0N (x|µ2 , Σ2) 1N (x|µ3 , Σ3) 0N (x|µ4 , Σ4) 0 = N (x|µ2 , Σ2) We are actually done',\n",
              " 'In particular, using eq (19.1) and eq (19.2), it must be the case p(x) = X z p(x, z) = X z p(x|z)p(z) = X K k=1 πkN (x|µk , Σk) (19.3) The normal distributions in the GMM is known as the mixture components and the values πk are known as the weights 19.2 is shown two examples of a Gaussian mixture model The top row is an M = 4 mixture component example used to represent the density of a single real number x In the right-pane the individual mixture components are plotted; notice the height does not correspond to their height in the GMM since they are scaled with πk In the bottom row is shown the same M = 4 GMM as a surface and contour plot 19.2 The EM algorithm The GMM is a general and flexible way to represent continuous densities, but without a useful way to train the GMM it is not very useful The Expectation Maximization (EM) algorithm provides an elegant method for finding the parameters of a GMM which approximates a dataset X of N observations',\n",
              " ', µK} Σ = {Σ1,  , ΣK} the objective of the EM algorithm is then to find the values of the parameters π, µ, Σ which maximizes the log of the likelihood of the data\\x00\\x00\\x00\\x0019.2 The EM algorithm 327 x1 x2 −4 −2 0 2 4 6 8 −4 −2 0 2 4 x1 x2 p(x) −6 −4 −2 0 2 4 6 −6 −4 −2 0 2 4 6 0.01 0.02 0.03 0.04 0.05 0.06 Fig The initialization step of the EM algorithm when applied to the 2D dataset shown as the gray points The K = 3 mixture components are shown as a contour plot in the left pane, and in the right pane as a surface plot The colored circles represent the area capturing twice the standard deviation of each mixture component L(π, µ, Σ) = log p(X|µ, Σ,π) = X N i=1 log p(xi |µ, Σ,π) = X N i=1 log \"X K k=1 πkN (xi |µk , Σk) #  (19.4) This could be accomplished using gradient descent, which we encountered earlier in chapter 15, however, the EM algorithm takes advantage of the particular form of the problem to provide a much more effective method',\n",
              " 'First some notation: For a given data point xi , the probability xi belongs to component k can be computed with (as usual) Bayes theorem: p(zk = 1|xi) = p(xi |zk = 1)p(zk = 1) PK k′=1 p(xi |zk′ = 1)p(zk′ = 1) = N (xi |µkΣk)πk PK k′=1 N (xi |µk′Σk′ )πk′ = γik (19.5) We can then define the “total mass” of a component k as Nk = PN i=1 γik Notice N = PK k=1 Nk because X K k=1 Nk = X K k=1 X N i=1 p(zk = 1|xi) = X N i=1 \"X K k=1 p(zk = 1|xi) # = X N i=1 1 = N Since γik denotes the probability observation i belongs to cluster k, we can define the empirical mean, the empirical covariance and the empirical mass of the clusters as µk = 1 Nk X N i=1 γikxi , Σk = 1 Nk X N i=1 γik(xi − µk )(xi − µk ) T , and πk = Nk N',\n",
              " 'Each row corresponds to the first three steps of the EM algorithm and each column to the E-step and M-step In the top-left pane, the observations are assigned to the three clusters in the E-step The top-left right pane shows the M-step where the parameters πk, Σk and µk are updated based on the assignments This continues for two additional steps Initialize: First we initialize µ, Σ and π Expectation step: Compute γik for all i, k Maximization step: Update µk , Σk and πk Iterate: Repeat the two previous steps until the likelihood eq (19.4) does not change.19.2 The EM algorithm 329 x1 x2 −4 −2 0 2 4 6 8 −4 −3 −2 −1 0 1 2 3 4 5 Iterations t Likelihood 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 1500 2000 2500 3000 3500 4000 4500 Fig Running the EM algorithm for 20 iterations produces the above partitioning The likelihood is plotted in the right-pane As can be seen, the likelihood continues to increase but at a diminishing rate',\n",
              " 'To illustrate the EM algorithm, consider the 2d dataset shown in fig 19.3 with the given initialization of clusters 19.4 is shown the first three steps of the EM algorithm The left-most column corresponds to the E-step and the right-most column to the M-step with the assignments to clusters γik being indicated by the colors Furthermore, the EM algorithm maximizes the likelihood and in fig 19.5 is shown the 20th step of the EM algorithm and the log likelihood 19.2.1 Why the EM algorithm works⋆ The above presentation leaves two important questions unanswered Firstly, the steps of the EM algorithm might appear as arising from nothing and secondly, why should we believe the EM algorithm works To begin with the later question, what the EM algorithm tries to do is to maximize the log of the likelihood of the data L(π, µ, Σ), and the way we will show this is simply by showing that both the M-step and the E-step increases the log-likelihood',\n",
              " 'To begin, suppose we collect the parameters π, µ, Σ into the symbol θ = {π, µ, Σ} Recall according to eq (19.3) each observation xi comes with a latent (binary) vector zi that indicates which mixture component xi belongs to That is, if zik = 1 then xi belongs to component k and we write: p(xi |θ) = X zi p(xi , zi |θ) = X zi p(xi |zi , θ)p(zi) = X K k=1 πkN (xi |µk , Σk) (19.7) If we collect all the zi ’s in an N × K matrix Z we can therefore write: p(X|θ) = X Z p(X, Z|θ),330 19 Mixture models for unsupervised clustering where p(X, Z|θ) = QN i=1 p(xi , zi |θ) We can now proceed with a little algebra Recall that the log of the likelihood, which we wish to maximize, is simply L(X|θ) = log P(X|θ) and the later probability can be re-written using the basic rules of probability: log p(X|θ) = log p(X|θ)P(Z|X, θ) P(Z|X, θ) = log p(X, Z|θ) − log p(Z|X, θ) (19.8) Suppose we consider any other setting of the parameters θ old',\n",
              " '(19.8) gives (the left-hand side is not affected by the expectation because it is independent of Z): log p(X|θ) = Ep(Z|X,θ old) [log p(X, Z|θ)] − Ep(Z|X,θ old) [log p(Z|X, θ)]  (19.9) Now to the quite amazing thing First, it follows from Jensen’s inequality1 that Ep(Z|X,θ old) [log p(Z|X, θ)] ≤ Ep(Z|X,θ old) h log p(Z|X, θ old) i  (19.10) In other words, considering only the last term the log-likelihood becomes as small as possible if θ = θ old Let’s connect this to the EM algorithm Suppose θ old is the value of θ at a given step of the algorithm Suppose then we select θ as the value that maximize the first term in eq (19.9): θ = arg max θ Ep(Z|X,θ old) [log p(X, Z|θ)] (19.11) Using eq (19.9) we then have that for this θ: By eq (19.11) : Ep(Z|X,θ old) [log p(X, Z|θ)] ≥ Ep(Z|X,θ old) h log p(X, Z|θ old) i (19.12) By eq (19.10) : −Ep(Z|X,θ old) [log p(Z|X, θ)] ≥ −Ep(Z|X,θ old) h log p(Z|X, θ old) i (19.13) Using these two expression on each term in eq',\n",
              " 'Then, for any density r(x) it holds Ep(x) [log p(x)] = Ep(x) \\x14 log p(x) r(x) \\x15 + Ep(x) [log r(x)] = −Ep(x) \\x14 log r(x) p(x) \\x15 + Ep(x) [log r(x)]  By Jensen’s inequality the first term is always less than 0 because −Ep(x) h log r(x) p(x) i ≥ − log Ep(x) h r(x) p(x) i = − log P x r(x) = − log 1 = 0 Applying this to the right-hand side of the above equation we get: Ep(x) [log p(x)] = −Ep(x) \\x14 log r(x) p(x) \\x15 + Ep(x) [log r(x)] ≥ Ep(x) [log r(x)]  The result now follows by replacing x with Z, p with p(Z|X, θ old) and r with p(Z|X, θ)\\x0019.2 The EM algorithm 331 In other words, choosing θ to maximize Ep(Z|X,θ old) [log p(X, Z|θ)] in eq (19.11) also maximize the log-likelihood L(X|θ) How is this connected with the EM algorithm Firstly, the posterior p(Z|X, θ old) exactly corresponds to γik computed in the E-step using eq We can then examine what happens in the maximization-step eq',\n",
              " '19.2.2 Some problems with the EM algorithm The EM algorithm is guaranteed to always increase the log likelihood L(π, µ, Σ), however, this does not mean the EM algorithm is guaranteed to be well-behaved Firstly, what values of π, µ and Σ the EM algorithm converges to depends upon the initialization; this is similar to K-means clustering but in general the increased flexibility of the EM algorithm for GMMs increases this problem Secondly, the EM algorithm may exhibit divergent behaviour If a mixture component k is centered upon a single observation, and this is the only observation for which γik is large, the EM algorithm may diverge in the sense the cluster becomes more and more peaked around this observation; in other words, the EM algorithm diverges To compensate for this one can add a regularization term to Σk as Σk = 1 Nk X N i=1 γik(xi − µk )(xi − µk ) T + λI where λ > 0 is the regularization term',\n",
              " 'Third, the EM algorithm in its present form requires (K − 1) | {z } π + KM|{z} µ1 ,...,µK + K(M + 1)M/2 | {z } Σ1,...,ΣK parameters; for high-dimensional datasets the number K(M + 1)M/2 can be brought down by considering a diagonal covariance matrix to KM There is however also goods news with regards to the EM algorithm for GMMs Asides accomplishing the primary objective, a general density estimator which can be fitted efficiently, an advantage of the EM algorithm over K-means is that one can select K using cross-validation.332 19 Mixture models for unsupervised clustering Training Test −2 −1 0 1 2 3 −2 −1 0 1 2 3 −2 −1 0 1 2 3 −2 −1 0 1 2 3 Fig Example of four GMMs fitted to a small dataset comprised of N = 13 training observations and N test = 4 test-observations indicated by the red crosses The figure illustrates how the GMM begins to overfit the data as the number of mixture components is increased The test log-likelihood is shown in fig',\n",
              " 'Since the goal of fitting a GMM using for instance the EM algorithm is to maximize the log-likelihood, it is natural to quantify the predictive performance in terms of the log-likelihood measured on a test set Xtest : L test(π, µ, Σ) = log p(Xtest|µ, Σ,π) (19.17) = N Xtest i=1 log \"X K k=1 πkN (x test i |µk , Σk) #  (19.18) One can then apply cross-validation using −Ltest(π, µ, Σ) as an error measure to select the number of mixture components K This procedure is illustrated in fig 19.6 where four different GMMs corresponding to K = 1, 2, 3, 4 is fitted until convergence on a small 1d dataset comprised of N = 13 training observations and Ntest = 4 test-observations indicated by the red crosses As seen, the GMM begins to overfit as K becomes large leading to reduced test log-likelihood (L test) plotted in fig',\n",
              " 'Test log-likelihood as evaluated on the four test observations and four values of K, K = 1, 2, 3, 4 shown in fig 19.6.334 19 Mixture models for unsupervised clustering Problems 19.1 Question 1: Let N (x|µ, Σ) = 1 p 2π|Σ| exp \\x12 − 1 2 (x − µ) ⊤Σ−1 (x − µ) \\x13 define the multivariate normal distribution with mean µ and covariance matrix Σ In Figure 19.8 is given 5000 observations drawn from a density defined by a Gaussian Mixture Model (GMM) with three clusters 5000 data observations drawn from a Gaussian Mixture Model (GMM) with three clusters Which one of the following GMM densities was used to generate the data',\n",
              " 'Question 2: Which one of the following state\\ufffements pertaining to clustering is correct A k-means and Gaussian Mixture Models are guaran\\ufffeteed to find the same solutions regardless of initial\\ufffeization B The level at which clusters merge in the dendrogram in hierarchical clustering using minimum/single-, maximum/complete- or group average linkage can be determined by the proximities between all the obser\\ufffevations C In k-means the cluster centers are updated as the average of the observations belonging to the cluster regardless of the distance measure used D A Gaussian Mixture Model with diagonal covariance matrix has the same number of free parameters as k-means E Don’t know Question 3: Suppose the points in the scatter plot fig 19.9 was generated from a Gaussian mixture-model (GMM) of the form19.2 The EM algorithm 335 y x −10 −5 0 5 10 −5 0 5 10 15 Fig Scatter plot of observations p(x, y) = X 2 i=1 wiN \\x12\\x14x y \\x15 ; \\x14 0 µi \\x15 , \\x14 σ 2 i 0 0 δ 2 i \\x15\\x13  and suppose µ1 = 7, µ2 = 1',\n",
              " 'A w1 = 0.5, σ2 1 = 2σ 2 2 , δ2 1 = 2δ 2 2 B w1 = 0.7, δ2 1 > σ2 2 C w1 = 0.7, σ2 1 = 20, δ2 2 = 1 D w1 = 0.5, p(0, 0) < p(0, 7) E Don’t know.20 Density estimation Anomaly detection attempts to find observations that can be regarded as different from the other observations A tempting way to put this is we should consider an observation anomalous when it lies in a low density region of the data, i.e a region where we would consider it unexpected to find an observation We will therefore mainly regard anomaly detection as a problem of estimating the density of a dataset and then obtaining the (candidate) outliers is simply a matter of finding the lowest-density observations The GMM can be regarded as the primary density-estimation tool for our disposal, however, for very large datasets the GMM might be too expensive to fit',\n",
              " 'It is therefore useful to consider approximate, deterministic methods for density estimation which are more robust In this section, we will consider two such approaches: kernel density estimation, which is an approximation to the GMM, and Average relative density which is an entirely separate method not based on probabilities Kernel density estimation was separately discovered by Murray Rosenblatt and Emanuel Parzen [Rosenblatt et al., 1956, Parzen, 1962], meanwhile the section on the average relative density is based on Tan et al 20.1 The kernel density estimator A problem with the Gaussian mixture-model is that it simply contains many parameters to be fitted and selecting different values of these parameters (or re-starting the EM algorithm from different initial configurations) will lead to different assignment of density A kernel density estimator (KDE) is best seen as a deterministic approximation to the Gaussian mixture model which tries to overcome some of these limitations',\n",
              " '(20.1) where π, µ and Σ are all parameters to be tuned When we apply a KDE to a dataset X of N observations we simply assume the GMM consists of K = N components centered on top of each data point and with diagonal covariance matrix In other words, we select338 20 Density estimation Training Test −2 −1 0 1 2 3 −2 −1 0 1 2 3 −2 −1 0 1 2 3 Bandwidth Test log likelihood 0.5 1 1.5 2 2.5 3 −9 −8 −7 −6 Fig Example of a KDE fitted to a small dataset comprised of N = 13 training observations and N test = 4 test-observations indicated by the red crosses The figure illustrates how the KDE overfits as the kernel parameter λ is varied as λ = 2, 0.5, 0.15 The last pane shows the test log-likelihood πk = 1 N , µk = xk and Σk = λ 2 I where λ is known as the kernel width This gives a density of the form: pλ(x) = 1 N X N i=1 N (x|xi , λ2 I) (20.2) 20.1.1 Selecting the kernel width λ We can select λ similar to how we selected K for the GMM namely by using cross-validation',\n",
              " 'LOO estimation of the kernel width parameter λ for the full dataset comprised N = 17 obser\\ufffevations along with the KDE corresponding to the best bandwidth L(λ) = log p(Xtest|λ) = N Xtest j=1 log p(x test j |λ) = N Xtest j=1 log \" 1 N X N i=1 N (x test j |xi , λ2 I) # A simple example using a dataset of N = 13 observations and a test set of Ntest = 4 observations can be found in fig Another advantage of the KDE over the GMM is that leave-one-out cross-validation can be carried out very quickly: For each pair of observations we can pre-compute Mij = N (xi |xj , λ2I) once and re-use them in the computation of the leave-one-out estimate of the log of the likelihood as: L(λ) = 1 N X N i=1 log \\uf8ee \\uf8f0 X j̸=i 1 N − 1 Mij \\uf8f9 \\uf8fb  The leave-one-out estimate of the log of the likelihood for the full dataset comprised of N = 17 observations can be found in fig 20.2 along with KDE corresponding to the highest log likelihood according to the LOO estimator',\n",
              " 'Uneven densities and the GMM Let us turn to a problem for which the KDE or GMM may not be suitable 20.3 we have shown a simple 2d dataset comprised of two clusters of data of very uneven density and two candidate outliers indicated by the red circles Comparing the two outliers, the right-most candidate outlier is clearly further away from its nearest neighbours, however, it also lies in a region of relatively lower density The KDE is unable to make use of this difference in density as it use the same kernel width for the entire dataset and therefore tends to consider the right-most point a better candidate outlier as shown in fig 20.4 (top row) for different choices of the kernel width (λ = 0.2, 1, 4) In the bottom row we have shown the density obtained by applying the GMM for K = 1, 2, 4 As shown,340 20 Density estimation −4 −2 0 2 −4 −3 −2 −1 0 1 Fig A simple 2d dataset comprised of two clusters of data of very uneven density and two candidate outliers indicated by the red circles',\n",
              " 'Which of the two should we suspect are outliers the GMM rapidly begins to overfit the data and we should therefore cross-validate to select K In addition, the use of specific cluster centers may lead to artificially high-density regions as shown by the elongated oval shape in the plot for K = 4 As a rule, this makes the GMM more flexible for fitting densities and good at handling densities which are elongated along one or more directions (i.e elliptical densities), but also somewhat prone to spurious behaviour due to the particulars of how the EM algorithm decided to place the cluster centers during a particular run Thus, when using GMMs for outlier detection it is important the number of components be carefully determined (i.e., using cross-validation) and naturally, the observations which we wish to examine as being potential outliers should not be part of the data used for training the GMM density',\n",
              " 'However, the ARD is also different from the KDE or GMM in that it does not rely on probabilities Recall the definition of the K nearest neighbourhood of a point x given in eq (12.1) from chapter 12, i.e the K observations in the dataset X which are closest to x: NX(x, K) = {The K observations in X which are nearest to x}  (20.3) The average distance to the K nearest neighbours is given by 1 K X x′∈NX(x,K) d(x, x ′ ), where d is the relevant distance measure for our dataset, for instance the Euclidian distance d(x, y) = ∥x − y∥2 Intuitively, if the average distance to the nearest neighbours is low, that20.2 Average relative density 341 −4 −3 −2 −1 0 1 −4 −3 −2 −1 0 1 −4 −3 −2 −1 0 1 −4 −3 −2 −1 0 1 −4 −3 −2 −1 0 1 −4 −3 −2 −1 0 1 −4 −3 −2 −1 0 1 −4 −3 −2 −1 0 1 −4 −3 −2 −1 0 1 −4 −3 −2 −1 0 1 −4 −3 −2 −1 0 1 −4 −3 −2 −1 0 1 Fig (top row:) The kernel density estimator applied to a 2d dataset for different settings of the kernel width From left to right we have plotted λ = 0.2, 1, 4',\n",
              " 'The second component for K = 2 is quite faint and the GMM rapidly begins to overfit for K > 2 means there are many observations close to x and so the density at x is high and contrary, if the average distance is high, the density is low It thus makes sense to define the density around x computed by K neighbours as the inverse of the average distance densityX(x, K) = 1 1 K P x′∈NX(x,K) d(x, x′)  (20.4) Suppose for a dataset X we wish to evaluate the density of observation i, xi , of the dataset Obviously, we don’t want to include xi as a member of the K-neighbourhood because that would bias the density upwards Imagine if K = 1, then obviously NX(xi , K) = {xi} because xi is in X and so densityX(xi , K) = 1 1 1 d(xi,xi) = 1 0 = ∞ Rather in the case where we wish to compute the density of an observation xi from X we therefore use: densityX\\\\i (xi , K) = 1 1 K P x′∈NX\\\\i (xi,K) d(xi , x′) , (20.5) where, as in eq',\n",
              " 'One could use the (estimated) density directly, however, if we are looking for outliers it is perhaps more relevant still to look for those points where the density is lower than what it typically is for surrounding points This is exactly what the average relative density (ard) attempts to accomplish\\x00\\x00342 20 Density estimation −4 −3 −2 −1 0 1 −4 −3 −2 −1 0 1 −4 −3 −2 −1 0 1 −4 −3 −2 −1 0 1 −4 −3 −2 −1 0 1 −4 −3 −2 −1 0 1 −4 −3 −2 −1 0 1 −4 −3 −2 −1 0 1 −4 −3 −2 −1 0 1 −4 −3 −2 −1 0 1 −4 −3 −2 −1 0 1 −4 −3 −2 −1 0 1 Fig (top row:) Density plotted for the 2d dataset shown in fig 20.3 for K = 2, 4, 6 The density relies only on the average distances and so considers all the top-right points to be anomalous (bottom row:) The ard takes the relative density into account and therefore do not consider the low-density cluster to be anomalous but rather considers the left-most candidate outlier to be far more suspicious',\n",
              " '(20.5) to estimate the density of each xj : ardX(x, K) = densityX(x, K) 1 K P xj∈NX(x,K) densityX\\\\j (xj , K)  (20.6) It is instructive to consider what this definition means for K = 1 In this case we first find the one observation in X closest to x namely NX(x, K) = {xj} and then we simply compute the relative density: ardX(x, 1) = densityX(x, 1) densityX\\\\j (xj , 1) Suppose further that the observation in X closest to xj (but which is not xj itself) is NX\\\\j (xj , 1) = {xk} In this case the above becomes: ardX(x, 1) = 1 d(x,xj ) 1 d(xj ,xk) = d(xj , xk) d(x, xj ) That is, if x is closer to its nearest neighbour xj than it’s nearest neighbour xj is to it’s nearest neighbour xk then the ard is high and vice versa Finally, if we wish to compute the ard for an already existing observation xi in X then similar to eq (20.5) we have to exclude that observation from X to not bias the ard upwards',\n",
              " '(20.7) The result of plotting the density and the ard can be seen in the top and bottom rows of fig The top row illustrates the density for K = 2, 4, 6 and the bottom row the ard for the same choices of K We see how the density marks all the points in the low-density region as outliers, however, the ard is able to take into account they are in a low-density region and consider the left-most candidate outlier far more likely to be anomalous.344 20 Density estimation Problems 20.1 Question 1: O1 O2 O3 O4 O5 O6 O7 O8 5.11 4.79 4.90 4.74 2.96 5.16 2.88 Table 20.1 Pairwise Euclidean distance, i.e d(Oa, Ob) = ||xa − xb||2 = pP m(xam − xbm) 2, between observation O8 and observation O1–O7 given in Table 20.2 We would like to quantify if O8 is an outlier using a Gaussian kernel density estimator where we use the seven observations O1, O2,  ., O7 to estimate the density at observation O8 based on the Euclidean distances given in Table 20.2 and reproduced in terms of observation O8 in Table 20.1',\n",
              " 'We note that |σ 2I| is the determinant of the diagonal matrix with σ 2 in the diagonal For σ = 1 we have |σ 2I| = 1 What is the density at observation O8 using only observations O1-O7 in the above Gaussian kernel density estimator O1 O2 O3 O4 O5 O6 O7 O8 O1 0 2.39 1.73 0.96 3.46 4.07 4.27 5.11 O2 2.39 0 1.15 1.76 2.66 5.36 3.54 4.79 O3 1.73 1.15 0 1.52 3.01 4.66 3.77 4.90 O4 0.96 1.76 1.52 0 2.84 4.25 3.80 4.74 O5 3.46 2.66 3.01 2.84 0 4.88 1.41 2.96 O6 4.07 5.36 4.66 4.25 4.88 0 5.47 5.16 O7 4.27 3.54 3.77 3.80 1.41 5.47 0 2.88 O8 5.11 4.79 4.90 4.74 2.96 5.16 2.88 0 Table 20.2 Pairwise Euclidean distance, i.e d(Oa, Ob) = ||xa − xb||2 = pP m(xam − xbm) 2, between eight observa\\ufffetions of the Gal´apagos data Red observations (i.e., O1, O2, O3, and O4) correspond to the four smallest islands whereas blue observations (i.e., O5, O6, O7, and O8) correspond to the four largest islands A 3.4 · 10−32 B 1.3 · 10−8 C 6.5 · 10−6 D 5.1 · 10−2 E Don’t know',\n",
              " 'In order to assess if this is the case we would like to calculate the average relative KNN density based on the observations given in Ta\\ufffeble 20.3 only We recall that the KNN density and aver\\ufffeage relative density for the observation x are given by: density(x, K) = \\x10 1 K P y∈N(x,K) distance(x, y) \\x11−1 , a.r.d.(x, K) = density(x,K) 1 K X y∈N(x,K) density(y, K) , where N(x, K) is the set of K nearest neighbors of obser\\ufffevation x and a.r.d(x, K) is the average relative density of x using K nearest neighbors Based on the data in Table 20.3, what is the average relative density for ob\\ufffeservation O1 for K = 2 nearest neighbors',\n",
              " 'Pairwise Euclidean distance between the 10 first observations in the PM10 data Red observations (i.e., O1, O3, O5, O6, O7 and O8) are observations where the pollution levels are above the median value and dark green observations (i.e., O2, O4, O9 and O10) correspond to observations where the pollution level is below the median value A 0.01 B 0.02 C 0.23 D 0.46 E Don’t know Question 3: One definition of an outlier is the following: An outlier is an object that has a low probability with respect to a probability distribution model of the data Consider the data set in Table 20.4 To detect outliers, we standardize the data zn = xn − mean(x) std(x) , mean(x) = 6, std(x) = 28, and model them with a standard univariate Normal dis\\ufffetribution N(0, 1) We define an outlier as a data object with an attribute |zn| > c, where c is a constant such that the probability that |zn| > c is equal to α, i.e., p(|zn| > c) = α We choose α = 0.0027 corresponding to c = 3.00',\n",
              " 'A simple data set with eight data objects each with one attribute A There are no outliers B x5 = 75 is an outlier C x3 = −8 and x5 = 75 are outliers D x4 = 0, x3 = −8, x5 = 75 are outliers E Don’t know Question 4: We again consider the ten subjects given in Table 20.5 We will consider this data set a mar\\ufffeket basket problem where the customers are the ten sub\\ufffejects and they have various combinations of the six items denoted Y AY , Y AN , OAY , OAN , P AY , P AN  Which one of the proposed solutions below includes all the fre\\ufffequent itemsets with support of more than 52 % Y AY Y AN OAY OAN P AY P AN S1 1 0 1 0 1 0 S2 1 0 1 0 0 1 S3 0 1 0 1 1 0 S4 0 1 1 0 1 0 S5 0 1 1 0 1 0 NS1 0 1 1 0 1 0 NS2 0 1 0 1 1 0 NS3 1 0 0 1 0 1 NS4 0 1 1 0 1 0 NS5 0 1 1 0 1 0 Table 20.5 Given are five subjects that survived in Haber\\ufffeman’s study (denoted S1, S2,  ., S5) as well as the five sub\\ufffejects that did not survive in Haberman’s study (denoted NS1, NS2,',\n",
              " 'A {Y AN },{OAY }, {P AY } B {Y AN },{OAY }, {P AY }, {Y AN , P AY }, {OAY , P AY } C {Y AN },{OAY }, {P AY }, {Y AN , OAY }, {Y AN , P AY }, {OAY , P AY } D {Y AN },{OAY }, {P AY }, {Y AN , OAY }, {Y AN , P AY }, {OAY , P AY }, {Y AN , OAY , P AY } E Don’t know Question 5: We suspect that observation O8 may be an outlier In order to assess if this is the case we would like to calculate the average relative KNN density based on the observations given in Ta\\ufffeble 20.2 only We recall that the KNN density and aver\\ufffeage relative density for the observation x are given by: density(x, K) = \\x10 1 K P y∈N(x,K) distance(x, y) \\x11−1 , a.r.d.(x, K) = density(x,K) 1 K X y∈N(x,K) density(y, K) , where N(x, K) is the set of K nearest neighbors of obser\\ufffevation x and a.r.d(x, K) is the average relative density of x using K nearest neighbors Based on the data in Table 20.2, what is the average relative density for ob\\ufffeservation O8 for K = 3 nearest neighbors A 0.19 B 0.28 C 0.56 D 1.79 E Don’t know',\n",
              " 'We wish to compute the average relative KNN density (a.r.d) of the observations in table 20.6 using the cityblock distance indicated by the table Letting d(x, y) denote the cityblock distance metric this is defined as density(x, K) = 1 1 K P y∈N(x,K) d(x, y) a.r.d(x, K) = density(x, K) 1 K P z∈N(x,K) density(z, K) , N(x, K) : Set of K-nearest neighbours of x What is the a.r.d of observation o1 using K = 1 nearest neighbours o1 o2 o3 o4 o5 o6 o7 o8 o1 0 4 7 9 5 5 5 6 o2 4 0 7 7 7 3 7 8 o3 7 7 0 10 6 6 4 9 o4 9 7 10 0 8 6 10 9 o5 5 7 6 8 0 8 6 7 o6 5 3 6 6 8 0 8 11 o7 5 7 4 10 6 8 0 7 o8 6 8 9 9 7 11 7 0 Table 20.6 Pairwise Cityblock distance, i.e d(oi, oi) = ∥xi − xj∥1 = PM k=1 |xik − xjk|, between 8 observations Each observation oi corresponds to a M = 15 dimensional binary vector, xik ∈ {0, 1} The blue observations {o1, o2, o3, o4} be\\ufffelong to class C1 and the black observations {o5, o6, o7, o8} belong to class C2',\n",
              " 'Question 7: Consider again the distances in ta\\ufffeble 20.6 Suppose we wish to perform mixture modelling (see chapter 9.2 of “Introduction to data mining”) and we consider mixture distributions of the form (λ > 0): p(x|θ) = 1 2λ exp(−d(x, θ)/λ)346 20 Density estimation Suppose we consider K = 8 mixture components, the pa\\uffferameter θ1,  , θ8 of each mixture component is taken to be the position of the observations o1,  , o8 and each mixture component is weighted equally in the full mix\\ufffeture distribution Suppose we set λ = 4 and let d denote the cityblock distance metric What is the probability density at observation o1 A Probability density at o1 ≈ 0.043 B Probability density at o1 ≈ 0.031 C Probability density at o1 ≈ 0.013 D Probability density at o1 ≈ 0.341 E Don’t know.21 Association rule learning Association rule learning is the discovery of interesting relations between features in a dataset',\n",
              " 'Automatic discovery of such rules is known as association mining and is of large commercial interest since the invention of the efficient Apriori method for discovering association rules in the early 90s [Agrawal et al., 1993, 1994] that, at the time of writing, has more than 38 000 citations In this chapter, we will discuss basic concepts relating to association rule learning and introduce this popular method, the Apriori algorithm, for automatic rule discovery 21.1 Basic concepts We will still denote our dataset X as an N × M matrix and assume X is binary Each row (observation) of the matrix corresponds to a transaction and each column (attribute) to an item An example is shown in table 21.1 where we consider N = 5 transactions corresponding to M = 4 items',\n",
              " 'For instance if Xij = 1 then person i bought item j Because of this interpretation, it is common to use set notation Suppose xi =  0 1 1 0T  This will be written as the set: ti = {I2, I3} to denote that transaction i corresponded to a person buying item I2 and I3 (butter and beer) and we will write t1,  , tN for all transactions Since we will use set notation somewhat often it is perhaps a good idea to review some basic concepts Suppose r = {I1, I2, I4} and s = {I2, I3, I4, I5} Then we denote the size by vertical bars such that |r| = 3 and |s| = 4 The intersection, i.e the elements in both sets, and the union, i.e the elements in either of the sets are written as r ∩ s = {I2, I4}, and r ∪ s = {I1, I2, I3, I4, I5} A special set is the empty set ∅ = { } and two sets r, u are disjoint if r ∩ u = ∅ For instance {I1, I2, I4} ∩ {I3, I5} = ∅ Set membership (i.e if an element is in the set) is written as x ∈ r In\\x00\\x00348 21 Association rule learning Table 21.1',\n",
              " 'milk butter beer diapers 1 0 1 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 our case I3 ∈ r is false but I3 ∈ s is true If all elements in a set c is contained in a set r this will be written as c ⊆ t, for instance: {I2, I4} ⊆ r Finally, set difference, that is the operation where we remove the elements in one set from another, is written as: r \\\\ s = {I1}, and s \\\\ r = {I3, I5} 21.1.1 Itemsets and association rules Returning to association mining, the set of all items will be written as I = {I1, I2,  (21.1) Each transaction is then a subset of I We will write T = {t1,  , tN } for the set of all transactions Notice, in set-notation, ti ⊆ I With this notation in place, we can make our first real definition: an itemset is simply a subset of I Each transaction is an itemset, however, also c = {I3, I5} is an itemset even though it is not a member of all transactions T An association rule is written as X → Y, (21.2) where X, Y ⊆ I and X ∩ Y = ∅',\n",
              " 'For instance, we can consider the rule {butter, beer} → {milk}, which is saying that people who buy butter and beer will also tend to buy milk What is a useful rule One definition is to say it should satisfy two criteria: High support It should be invoked fairly often, i.e X ∪ Y should form a set of items many buy High confidence When the rule is triggered, i.e someone buys X, then the person should be very likely to also buy Y  These quantities are measured by the support and confidence which, as we will see, are nothing more than dressed-up probabilities.21.1 Basic concepts 349 21.1.2 Support For an itemset X we can define a number, the support, which is the fraction of transactions which contains the itemset X Formally: supp(X) = {Number of transactions containing X} N = |{t ∈ T|X ⊆ t}| N',\n",
              " 'When we talk about the support of an association rule X → Y , we mean the support of both X and Y  In other words: supp(X → Y ) = supp(X ∪ Y ) (21.4) Let’s try a few examples based on the market basket data X having five transactions of four items given in Table table 21.1 For instance: supp({I2, I3}) = 1 5 , supp({I1, I3, I4}) = 2 5 , supp({I1, I2, I3, I4}) = 0, supp({I3, I4} → {I2}) = 1 5  Support and probabilities It is important to stress the support is nothing but the empirical probability of the itemset If for instance X = {I3, I5} we can just as easily write: supp(X) = p(X) = p(I3 = 1, I5 = 1), which is just the probability that the third and fifth coordinate is 1 21.1.3 Confidence To quantify confidence we introduce the confidence of an association rule X → Y as the fraction of transactions which contain X that also contains Y  Formally: conf(X → Y ) = supp(X ∪ Y ) supp(X)',\n",
              " 'To give a single example: conf({I3, I4} → {I2}) = 1 5 3 5 = 1 3 .350 21 Association rule learning Returning to our original problem, we are interested in association rules X → Y where the support of the rule is higher than some pre-specified value and where the confidence too is higher than another pre-specified value (or, equivalently, find sets Z = {X ∪ Y } which occur with high probability and pairs of sets, X, Y , such that p(Y |X) is large) This ensures the rules are relevant (high support) and that they are mostly true (confidence) However, finding rules with a high support pose a difficult challenge If for instance we suppose M = 1000 (which is a fairly low number considering the number of items in an ordinary supermarket) and we are interested in all itemsets involving k = 5 items there are M ≈ 8.25 × 1012 potential itemsets to check In the next section, we will look at a method, the Apriori algorithm, which makes this search much faster',\n",
              " 'We assume we are given N transactions of M items and a minimum support value 0 < ϵ ≤ 1 When a particular itemset X has support higher than ϵ, supp(X) ≥ ϵ, we say X is frequent A word of warning: the Apriori algorithm may seem quite complicated especially on a first glance; however, it builds on a very simple principles which we will discuss first Itemsets have what is known as the downwards closure property Downwards closure simply says that if X is frequent, then so is any of its subsets This is very easy to prove: If a transaction contains X, then it also contains any subset A ⊂ X, and so A ⊂ X implies supp(A) = |{t ∈ T|A ⊂ t}| N ≥ |{t ∈ T|A ⊂ X ⊂ t}| N = supp(X) (21.6) This implies that if A is not frequent (infrequent), then so is any set containing X So how can this principle allow us to find all frequent itemsets Suppose we first compute the support of all itemsets which only contain a single item {Ii} for i = 1,',\n",
              " 'The idea is then to start with all (frequent) itemsets and iteratively find frequent itemsets with k = 1, 2,  We let Lk denote the set of all frequent itemsets with k elements For instance L1 = {{i}|supp({i}) ≥ ϵ} (21.7) The algorithm then at step k compute Lk from Lk−1 as follows: \\x88 First generate a set of candidate itemsets of size k, Ck, by adding all items to the itemsets in Lk Formally first define C ′ k = {s ∪ {j}|s ∈ Lk−1, j /∈ s} (21.8)21.2 The Apriori algorithm 351 Algorithm 9: Apriori algorithm 1: Given N transactions and let ϵ > 0 be the minimum support count 2: L1 = {{j}|supp({j}) ≥ ϵ} 3: for k = 2,  , M and Lk ̸= ∅ do 4: C ′ k = {s ∪ {j}|s ∈ Lk−1, j /∈ s} 5: Set Ck = C ′ k 6: for each c ∈ C ′ k do 7: for each s ⊂ c such that |s| = k − 1 do 8: if s is not frequent, i.e',\n",
              " 'is not in Lk−1 That an itemset c contains a subset not in Lk−1 can be written as: {s|s ⊂ c, |s| = k − 1} ∩ Lk−1 = ∅ (21.9) Removing all these itemsets from Ck can therefore be written as: Ck = C ′ k \\\\ {c|{s|s ⊂ c, |s| = k − 1} ∩ Lk−1 = ∅} (21.10) This is quite a daunting expression and it is somewhat easier to comprehend what it does by an example (which we will provide in a moment) or by breaking it into smaller steps In line 5 to line 12 of algorithm 9 the expression eq (21.10) is computed in a sequence of simpler steps which the reader is invited to consult \\x88 We then compute the support for each of the itemsets c ∈ Ck and let Lk be those candidates in Ck with support greater than ϵ \\x88 The method terminates when Lk = ∅',\n",
              " 'Suppose we set ϵ = 0.15 and apply the Apriori algorithm to the problem in table 21.1 to find all frequent itemsets To be frequent if ϵ = 0.15 means the itemset must be found in at least 1 transactions (why because 1 5 = 0.2 > ϵ) Initialization We first observe that L1 must contain all items because all items occur in at least one transaction We write this as352 21 Association rule learning L1 = \\uf8ee \\uf8ef \\uf8ef \\uf8f0 1 · · · · 1 · · · · 1 · · · · 1 \\uf8f9 \\uf8fa \\uf8fa \\uf8fb  First iteration, k = 2: The next step is to form C ′ 2 , which is done by taking each element in L1 (for instance {I3}) and then add each item which is not I3 to this element to get {I1, I3}, {I2, I3} and {I3, I4} Doing this we obtain: C ′ 2 = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8f0 1 1 · · 1 · 1 · 1 · · 1 · 1 1 · · 1 · 1 · · 1 1 \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fb  So far so good Now, to form C2 from C ′ 2 involve the following steps: Start with the first element in C ′ 2 , {I1, I2} Then take each subset which has size k − 1 = 1, namely {I1} and {I2}',\n",
              " 'Proceeding this way we see that in fact C2 = C ′ 2 as shown above Finally, we go over all itemsets in C2 and compute their support We see that supp({I1, I2} = 0 and so this itemset is not included in L2, however, all other itemsets occur in at least 1 transaction and are therefore accepted, therefore L2 = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8f0 1 · 1 · 1 · · 1 · 1 1 · · 1 · 1 · · 1 1 \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fb  Second iteration, k = 3: In the second iteration, we first add all singleton sets to L2 to get the candidate sets C ′ 3  For instance, starting with {I2, I3} ∈ L2 we obtain the candidate transactions {I1, I2, I3}, {I2, I3, I4} ∈ C ′ 3  Ignoring duplicates this list is: C ′ 3 = \\uf8ee \\uf8ef \\uf8ef \\uf8f0 1 1 1 · 1 · 1 1 1 1 · 1 · 1 1 1 \\uf8f9 \\uf8fa \\uf8fa \\uf8fb  Next we proceed by the difficult rule in eq We first set C3 = C ′ 3 and start with the first transaction c = {I1, I2, I3} We consider all subsets of c with one element removed, s = {I1, I2}, {I2, I3}, {I1, I3} and notice that {I1, I2} is not in L2',\n",
              " 'Doing this for all itemsets leave us with: C3 = \\x14 1 · 1 1 · 1 1 1\\x15 .21.3 Using the Apriori algorithm to find itemsets with high confidence 353 Computing their support we notice: supp({I1, I3, I4}) = 2 5 , and supp({I2, I3, I4}) = 1 5 and therefore L3 = \\x14 1 · 1 1 · 1 1 1\\x15  Third iteration, k = 4: Since L3 = \\x14 1 · 1 1 · 1 1 1\\x15 the third iteration is very simple We form the itemset C ′ 4 =  1 1 1 1 and obtain in the next step that s = {I1, I2, I3}, {I1, I3, I4}, {I1, I2, I4}, {I2, I3, I4} needs to be checked Since only {I1, I3, I4}, {I2, I3, I4} ∈ L3 we get C4 = ∅ and therefore L4 = ∅ The algorithm therefore terminates and we finally have: L = \\uf8ee \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8ef \\uf8f0 1 · · · · 1 · · · · 1 · · · · 1 1 · 1 · 1 · · 1 · 1 1 · · 1 · 1 · · 1 1 1 · 1 1 · 1 1 1 \\uf8f9 \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fa \\uf8fb 21.3 Using the Apriori algorithm to find itemsets with high confidence Finding association rules X → Y with high confidence can easily be solved using the Apriori algorithm',\n",
              " 'This suggests the following strategy: We first use the Apriori method to generate all itemsets Z with support greater than ϵ: supp(Z) ≥ ϵ If ϵ is chosen reasonably large, these itemsets will typically be fairly small, perhaps on the order of about 5 − 10 items Given these itemsets, we can then search over all subsets X of Z and find those subsets where supp(X) ≤ 1 δ supp(Z) Then defining Y = Z \\\\ X we are guaranteed the association rule X → Y satisfy both the above requirements This procedure can be speed up by noticing that if W ⊂ X, then supp(W) ≥ supp(X) Thus, if we have already seen that a particular set X has supp(X) > 1 δ supp(Z), there is no need to check the subsets X′ of X because they are guaranteed to have low confidence too',\n",
              " 'joint probabilities that are frequent by having high support However, it is only possible to find associations with high confi\\ufffedence within these itemsets identified to have high support, whereas there may be many other associ\\ufffeation rules of high confidence As such, if you were to buy lobster you are likely to also buy lemon and white wine, however, as lobster is bought very infrequently the itemset {lobster, lemon, white wine} will in general be below the support threshold ϵ and such high-confidence rule missed by the algo\\uffferithm Customers may also have different preferences and can typically be segmented into customer types It can therefore be useful to consider preferences within segments of consumers rather than in terms of all transactions',\n",
              " 'While our initial motivation for association mining was the analysis of market baskets, i.e the transactions of customers and their items purchased, association mining has very general applicabil\\ufffeity For instance association mining can be used within medicine (i.e., identifying patterns such as if you have these and these symptoms it is likely you also have these symptoms), bioinformatics (i.e., identifying association between genes), and general questionnaire data (i.e., if you answered this and this it is likely you will also answer this) to mention but a few potential domains of application The Apriori algorithm assumes binary features whereas in many real applications, datasets may not be binary and therefore some type of binarization must be invoked prior to the analyses How to binarize the data can be unclear whereas the binarization may influence results For instance if we binarize an attribute such as age we could simply threshold by the median value (i.e',\n",
              " 'In this case, the binarization will heavily influence the support, i.e using the median we cannot have support ϵ > 50% and if we for instance split according to 10th percentiles using 1-out-of-10 coding we will obtain 10 new binary attributes from the original attribute age and in general not be able to get support ϵ > 10% Finally, care should be taken interpreting association rules as support and confidence are nothing but joint and conditional probabilities respectively Thus, similar to our discussion of Bayesian networks in chapter 13 the arrows in association mining does not imply causality As such, we have for the example given in Table 21.1 that the confidence of the rule {beer} → {diapers} is 75% whereas the confidence of the rule {diapers} → {beer} is also 75%.21.4 Some limitations 355 Problems 21.1 Question 1: We consider the twelve costumers given in Table 21.2',\n",
              " 'Which one of the proposed solutions below includes all the frequent itemsets with support of more than 40 % MH ML PH PL DH DL LIS1 1 0 0 1 1 0 LIS2 1 0 1 0 1 0 LIS3 0 1 0 1 0 1 LIS4 0 1 0 1 0 1 LIS5 1 0 1 0 0 1 LIS6 1 0 1 0 1 0 OPO1 1 0 1 0 0 1 OPO2 0 1 0 1 1 0 OPO3 0 1 1 0 0 1 OPO4 0 1 0 1 0 1 OPO5 0 1 1 0 0 1 OPO6 1 0 1 0 1 0 Table 21.2 Given are the six first costumers of Lisbon and Oporto including whether these costumers spent more or less than the median consumption of MILK (MH, ML), PAPER (PH, PL), and DELI (DH, DL) Subscript H and L are thus used to respectively denote a relatively high and low level of consumption (i.e., above or below the median consumption) A {ML}, {MH}, {PH}, {PL}, {DH}, {DL} B {ML}, {MH}, {PH}, {PL}, {DH}, {DL}, {MH, PH} C {ML}, {MH}, {PH}, {PL}, {DH}, {DL}, {MH, PH}, {ML, DL} D {ML}, {MH}, {PH}, {PL}, {DH}, {DL}, {MH, PH}, {MH, DH}, {ML, PL}, {ML, DL}, {PL, DL} E Don’t know Question 2: Consider again the dataset in Ta\\ufffeble 21.2',\n",
              " 'A 25% B 40% C 60% D 80% E Don’t know.Solutions Problems of Chapter 2 2.1 The correct answer is B: For both Age and PV there are a natural zero and we can apply all the operators <, >, =, ̸=, ∗, / thus these attributes are ratio As Race, HT and UI are binary categorical, i.e =, ̸= can be applied to them but not <, > these attributes are not ordinal Age is ratio but not continuous as the attribute is measured in whole years Furthermore, MW is continuous and PV is discrete 2.2 The correct answer is C: All the attributes are ratio since 0 means absence of what is being measured As the Plants and E-Plants both are based on counts they are discrete whereas all remaining attributes are continuous and greater than zero as they quantify distances and areas (which are non-negative quantities) 2.3 The correct answer is D: x1, x2 are ratio, x3 is ordinal, x4 is nominal and x5 is interval Accordingly only option four is correct 2.4 The correct answer is B: For the atributes x1,',\n",
              " 'thus these five input attributes are all ratio x6 is nominal as this variable categorizes which region each observation belongs to of the six different regions in the dataset The output yr is ratio as zero naturally indicates absence of GNP and we again can naturally apply subtraction and addition (required for an interval attribute) but also multiplication (the GNP of one country can be three times larger that of another etc.) Problems of Chapter 3 3.1 The correct answer is A: CAL, PROT, FAT, FIB, SUG, POT, VIT, SHELF WEIGHT have negative coefficients of PCA1 whereas TYPE, SOD, CARB, CUPS have positive coefficients result\\ufffeing in a negative projection onto the first principal component The magnitude of the coefficients for PROT and SHELF are very small hence PCA2 does not primarily discriminate between low values of PROT and high values of SHELF and high values of PROT and low values of SHELF even though PROT has a small negative coefficient and SHELF a small positive coefficient',\n",
              " 'Finally, PCA1 and PCA2 will by definition always be orthogonal to each other despite the preprocessing of the data 3.2 The correct answer is A: The first three principal components account for σ 2 1+σ 2 2+σ 2 3 σ 2 1+σ 2 2+σ 2 3+σ 2 4+σ 2 5+σ 2 6 = 61.3% of the variation Thus, A is incorrect 3.3 The correct answer is D: The variation explained by each principal component is given by σ 2 P i i ′ σ 2 i ′  As such we find: V arExpP C1 = 9.7 2 9.72+6.72+5.72+3.72+3.02+1.32+0.72 = 0.4792 V arExpP C1 − 3 = 9.7 2+6.7 2+5.7 2 39.72+6.72+5.72+3.72+3.02+1.32+0.72 = 0.8733 V arExpP C7 = 0.7 9.72+6.72+5.72+3.72+3.02+1.32+0.72 = 0.0025 V arExpP C1 − 4 = 9.7 2+6.7 2+5.7 2+3.7 2 9.72+6.72+5.72+3.72+3.02+1.32+0.72 = 0.9431 V arExpP C1 − 5 = 9.7 2+6.7 2+5.7 2+3.7 2+3.0 2 9.72+6.72+5.72+3.72+3.02+1.32+0.72 = 0.9889 As such the first PC accounts for less than 50% of the variance, the first three principal components accounts for less than 90% whereas the last component accounts for less than 1%',\n",
              " '3.4 The correct answer is D: The terminology is taken from the appendix of Tan et The principal directions must be normalized and orthogonal leaving only C and D It is however visually clear the shape is both elongated along and symmetrical about the diagonal direction leaving option D as the correct choice 3.5 The correct answer is B: The projection can be found by substracting the mean from X and projecting onto the first two columns of V (see appendix B of Tan et al) The first point with the mean subtracted has coordinates  3 − 7/3 2 − 4/3 1 − 5/3  This should be (left) multiplied with the first two columns of V : \\uf8ee \\uf8f0 3 − 7/3 2 − 4/3 1 − 5/3 \\uf8f9 \\uf8fb ⊤ \\uf8ee \\uf8f0 −0.99 −0.13 −0.09 0.7 0.09 −0.7 \\uf8f9 \\uf8fb =  −0.78 0.85 corresponding to option B 3.6 The correct answer is C: The variance explained by each principal component is given by σ 2 P i i ′ σ 2 i ′',\n",
              " 'As the fourth component accounts for 4.36% of the variance the last statement is incorrect Problems of Chapter 4 4.1 The correct answer is C: Notice the definition of the cityblock distance corresponds to the number of 01 and 10 matches between the binary vectors: f01 + f10 = X M k=1 |xik − xjk| Then since f01 + f10 + f11 + f00 = M we can compute SMC(o1, o3) = f11 + f00 M = M − f01 − f10 M = 8 15 = 0.53 The other options are not true, on the simulated dataset the correct options are: COS(o1, o3) = 0.565685424949, J(o1, o3) = 0.363636363636 4.2 The correct answer is D: The three measures of similarity is given by J(x, y) = f11 f01 + f10 + f11 SMC(x, y) = f00 + f11 f01 + f10 + f11 + f00 cos(x, y) = x · y ∥x∥∥y∥ We now have J(NS1, NS2) = 1 7 SMC(NS1, NS2) = 2 8 = 1 4 cos(NS4, NS5) = 2 2 · 2 = 1 2 SMC(NS5, AS5) = 6 8 = 3 4 J(NS5, AS5) = 3 5 cos(NS5, AS5) = 3 4360 Solutions Hence the correct answer is cos(NS5, AS5) = 3 4',\n",
              " 'Hence, the correct answer is SMC(S1, S2) = cos(S1, S2) 4.4 The correct answer is D: To solve the problem, note that we can read of the median, 25’th, and 75’th percentiles from table 4.5 as qp=50%, qp=25%, and qp=75% respectively These can be matched to the histograms in fig 4.4 by observing histogram 2 does not have observations above 25 and thus must therefore be DeathRt Histogram 4 is the only histogram having observations above 88.25 which only holds for InfMort (see 75th percentile) This only holds for answer option D 4.5 The correct answer is A: As the correlation between x1 and x2 is positive the covariance matrix only has positive elements The covariance matrix will have a shape in the direction of the green cirles and blue plusses and therefore these pairs of observations will have relatively short Mahanalobis distance between each other, when compared to the other pairs of observations',\n",
              " 'Problems of Chapter 5 5.1 The correct answer is D: Let A denote the event that the classifier classifies a picture as a penguin, and let B denote the event that a picture contains a penguin From the text we are told \\x88 P(A|B) = 0.97 \\x88 P(A|B¯) = 0.03Solutions 361 \\x88 P(B) = 0.01 \\x88 P(B¯) = 1 − P(B) Using Bayes rule, we find that P(B|A) = P(A|B)P(B) P(A|B)P(B) + P(A|B¯)P(B¯) = 0.97 · 0.01 0.97 · 0.01 + 0.03 · (1 − 0.01) ≈ 0.25 Problems of Chapter 6 6.1 The correct answer is C: The trick to solving the problem is to not use Bayes theorem',\n",
              " 'We now find using Bayes theorem: P(P A|SY ) = P (SY |P A)P (P A) P (SY ) = P (SY |P A)P (P A) P (SY |P A)P (P A)+P (SY |NA)P (NA) = 0.36·0.56 0.36·0.56+0.14·0.44 = 0.766 ≈ 76.6% 6.3 The correct answer is B: E[x] = Z xp(x) = Z 0.2 0 x · 0.6 + Z 0.6 0.2 x · 1 + Z 0.9 0.6 x · 1.6 = 0.6 · 0.5 · (0.2 2 − 0 2 ) + 1 · 0.5 · (0.6 2 − 0.2 2 ) + 1.6 · 0.5 · (0.9 2 − 0.6 2 ) = 0.532, where we have used that R b a xdx = 0.5 · (b 2 − a 2 )362 Solutions Problems of Chapter 7 7.1 The correct answer is B: The 25th and 50th percentile but not the 50th and 75th percentiles of the attribute DB coincides AlA and AsA will not necessarily be highly correlated even though their distributions may have a similar shape (hence, this is correct) For attributes to be correlated it is important they take on high or low values systematically, however, this can not be inspected in a boxplot TB is not likely to be normal distribution as this attribute does not have a symmetric but highly right skewed distribution',\n",
              " '7.2 The correct answer is A: The solution can be obtained by first observing the median of the dataset is 1, leaving option A and B, then noticing the 10 observations taking the value 3 is 10/60 ≈ 17% of the dataset and since the top-most whisker must be at the 90th percentile according to Tan fig 3.12 this leave option A 7.3 The correct answer is D: Even though there are observations marked as outliers these should not necessarily be removed None of the attributes appear to be normal distribution but have a skewed distribution As a result, for all the attribute the mean value will be larger and somewhat different from the median value of the data Only if we standardize the data each attribute is expected to be given equal importance in the PCA Problems of Chapter 8 8.1 The correct answer is C: WINDDIR and HOUR are not part of the model and thus irrelevant',\n",
              " 'As x7 has a positive coefficient pollution is according to the model increasing over time and not decreasing As x2 has a negative coefficient of -0.01 higher temperatures will result in lower pollution levels according to the model 8.2 The correct answer is A: Since both x1, x2 and x6 have negative coefficients large values of these attributes will in general make the model predict the consumer is from Lisbon Since the offset is negative this implies that if a costumer after the standardization has x1 = x2 = x3 = x4 = x5 = x6 = 0 the customer is more likely to come from Lisbon than Oporto as the offset x0 = −0.51 As y = 1 denotes the consumer is from Oporto the logit function will return the probability a person is from Oporto Even though the coefficients of FRESH and PAPER are the smallest they may still contribute in the predictions and we can not from this analysis conclude that they should be removed from the modeling',\n",
              " '8.3 The correct answer is B: It is not reasonable to say AreaNI is irrelevant as it is included in the model with a non-zero coefficient and as seen from the boxplot in Figure 8.10 the attribute has a large range compared to the other attributes However, as the coefficient of x5 pertaining to DistNI is negative this implies that short distances to neighboring island would result in a prediction of larger area than large distances to the neighboring island would and this is hence correct Even though the coefficient for x2 number of endemic plants has the largest magnitude coefficient the range of this attribute is rather limited as seen from Figure 8.10 and it is thus not reasonable toSolutions 363 say this is the most important attribute for predicting the Area As the coefficients in front of x4 is positive and x6 negative an island that is highly elevated and close to Santa Cruz Island will in general be predicted to be relatively large',\n",
              " '(21.14) Decision tree: p = 26 26 + 34 = 13 30 , (21.15) r = 26 26 + 55 = 26 81 , (21.16) T NR = 191 191 + 34 = 191 225 , (21.17) F P R = 34 191 + 34 = 34 225  (21.18) Thus, the precision of the logistic regression classifier is indeed higher than the precision of the decision tree classifier whereas the remaining statements are incorrect 8.5 The correct answer is A: First observe the value of the linear regression function at (x1, x2) = (0, 0) is 1 1 + e−w0 This gives for option A, D and B, C respectively: A, D : 1 1 + e−w0 = (1 + e −2 ) −1 = 0.88 B, C : 1 1 + e−w0 = (1 + e −(−2)) −1 = 0.12 Inspecting any of the two figures clearly indicate we can rule out B, C leaving A, D However consider option D and the point (1, 1) Then we have a density estimate of 1 1 + e−(2+1+1−10) = 1 1 + e 6 ≈ 0.0025',\n",
              " 'Inserting for the split defined by the PAN attribute we obtain: ∆ =(1 − (( 81 306 ) 2 + ( 225 306 ) 2 )) −[ 170 306 (1 − (( 62 170 ) 2 + ( 108 170 ) 2 )) + 136 306 (1 − (( 19 136 ) 2 + ( 117 136 ) 2 ))] = 0.025 9.2 The correct answer is A: The two classes would be well separagted by the decisions A=∥ \\x14 x1 x2 \\x15 − \\x14 0.5 0.25 \\x15 ∥∞ < 0.25 B=∥ \\x14 x1 x2 \\x15 − \\x14 0.5 0.5 \\x15 ∥2 < 0.25 Decision A would capture the red crosses close to (0.25,0.5) Decision B will separate the circular shape of red crosses in the upper middle from all the remaining observations that are black circles 9.3 The correct answer is B: The relevant definitions can be found in section 4.3 of the textbook The split at 2.5 divide the set X into two parts, the lower and upper part We also need the frequencies for all the data',\n",
              " 'lower :I(l) = 1 − 3/5 = 2/5 upper :I(u) = 1 − 1/2 = 1/2 Then combining these we have ∆ = I(a) − (5/7)I(l) − (2/7)I(u) = 4/7 − (5/7)(2/5) − (2/7)(1/2) = 1 7 (4 − 2 − 1) = 1 7Solutions 365 Which is roughly ∆ ≈ 0.143 9.4 The correct answer is A: Trying to evaluate the trees in the corners (−1, 1) and (1, −1) rule out all but option A and C Then considering the corner of the upper-left square must be “cut of” by the circle allow one to rule out C leaving the correct choice A; alternatively evaluate the classifiers at (−0.2, 0.2) also show C cannot be correct Problems of Chapter 10 10.1 The correct answer is D: The dataset is first split into two datasets of size Dcv = 800, Dval = 200 Focusing on the cross validation, for each of the L = 6 values of λ we need to evaluate K = 10 cross-validation splits into datasets of size Dcv−train = 720, Dcv−test = 80 The time taken for this is Tcv = LK(D2 cv−train + 1/2D2 cv−test) This gives us the optimal value of λ',\n",
              " 'This takes: Tval = (D2 cv + 1/2D2 val) The total time elapsed is then T = Tcv + Tval = 31.956 · 106  10.2 The correct answer is B: Using forward and backward selection we would like to minimize the test error Thus, the forward selection would first select x3 having lowest test error and subse\\ufffequently x1 decreasing the test error the most in combination with x3 Subsequently, x2 is selected as this has minimal test error in combination with x1 and x3 Selecting also x4 does not improve the test error hence the selection procedure will terminate when x1, x2, and x3 are selected The backward feature selection will remove feature x3 to minimize the test error but removing additional features will increase the test error hence the backward selection strategy will terminate with the features x1, x2 and x4 being selected which is also the optimal feature combination for this data Thus, backward selection will indeed result in a better model being selected than using forward selection',\n",
              " 'We may indeed overfit to the data However the training error will monotonically decrease 10.4 The correct answer is D: Using forward and backward selection we would like to minimize the test error Thus, the forward selection would first select x5 having lowest test error and sub\\ufffesequently x2 decreasing the test error the most in combination with x5 Further selecting features in combination with x2 and x5 does not improve the test error thus the model will terminate The backward feature selection will remove feature x5 to minimize the test error and subsequently x1366 Solutions which constitutes the optimal feature configuration for the problem Thus, removing additional features will not increase the test error hence the backward selection strategy will terminate with the features x2 and x6',\n",
              " 'Thus, the error rate for logistic regression is smaller and the accuracy higher than the decision tree classifier As there are 225 subjects that died and only 81 subjects that survived the classes are imbalanced Thus, predicting everything to be in the largest class (died) would give an accuracy of 225 306 which is larger than the accuracy obtained by the decision tree classifier 10.6 The correct answer is B: Recall the accuracy is defined as (Tan 4.2) acc = f00 + f11 N i.e the sum of true negatives and positives divided by the total number of observations',\n",
              " 'For a very small dataset it is better to use leave-one-out cross validation as this will keep as much data for training as possible Only one level of cross-validation is needed for tuning model parameters Two levels are used when quantifying performance of the model with parameters selected Leave-one-out cross-validation is computationally expensive since as many models as observations needs to be trained 10.8 The correct answer is B: Firstly notice the training error column can be disregarded Forward selection then first selects x2, then x2, x4, then x2, x3, x4 and finally x1, x2, x3, x4 Backward selection however start with x1, x2, x3, x4, then disregards x2 to form x1, x3, x4 and terminates Since the test error for forward selection is 25 and for backward selection 15 only option B is correct.Solutions 367 Problems of Chapter 11 11.1 The correct answer is B: Since the cross-validation folds are non-overlapping, we can easily find by summing columns 2 and 3 in table 11.2',\n",
              " 'We find that n1 = 28 and n2 = 35 We can calculate the p-value from the CDF of the binomial distribution as p = 2cdfbinom(m = min{n1, n2}|θ = 1/2, N = n1 + n2) = 2cdfbinom(m = 28|θ = 1/2, N = 63) ≈ 2 · 0.225 ≈ 0.45 Therefore, B is correct Problems of Chapter 12 12.1 The correct answer is B: O1-04 are all closest to each other than to O5-O8 and will thus be correctly classified O5 is closest to O7, O2 and O4 and will thus be misclassified O6 is closest to O1, O4 and O3 and will thus be misclassified O7 is closest to O5, O8 and O2 and will thus be correctly classified and O8 is closest to O7, O5 and O4 and is thereby also correctly classified As two observations will be misclassified the error rate will be 2/8=1/4 12.2 The correct answer is D: Since there are 7 observations, K = 7 must classify everything to the largest class and so k2 = 7 Next, for K = 1 the ticks must be colored correctly and so k3 = 1, however by checking the left-most part of the k4-pane it is easy to see k4 = 5',\n",
              " '12.3 The correct answer is A: The true accuracy is 0.125 or 1/8',\n",
              " '13.4 The correct answer is A: True answer is: 0.83 This can be found by computing the per-class probabilities p(f1 = 0|C1) = 3/5, p(f2 = 1|C1) = 1 p(f1 = 0|C2) = 1/5, p(f2 = 1|C2) = 3/5 The class label priors is p(C1) = p(C2) = 1 2 and so the Naive-Bayes estimate is pNB(C1|f1 = 0, f2 = 1) = p(f1 = 0|C1)p(f2 = 1|C1)p(C1) p(f1 = 0|C1)p(f2 = 1|C1)p(C1) + p(f1 = 0|C2)p(f2 = 1|C2)p(C2) = 3/5 3/5 + (1/5)(3/5) = 5 6 Problems of Chapter 14 14.1 The correct answer is B: The aim of regularized least squares regression is to reduce the model’s variance without introducing too much bias and not the reverse Linear regression with transformed inputs can indeed model nonlinear relations, as the inputs may by the transformation be non-linearly transformed It is useful to plot attributes vs',\n",
              " '14.2 The correct answer is B: Reducing the amount of training data is the only option that will typically increase the amount of over-fitting The other choices will typically decrease over-fitting Problems of Chapter 15 15.1 The correct answer is C: The aim of regularized leats squares regression is to reduce the model’s variance without introducing too much bias and not the reverse The regularization strength is normally chosen to be the value that minimize the error on the test set using cross-validation Artificial neural networks with linear transfer functions can indeed be written in terms of a linear regression model However, forward and backward selection uses the test-error and not the training error to determine which attributes to remove or select 15.2 The correct answer is A: To compute the output, initialize n1 = f(1) = 1, n2 = f(2) = 2',\n",
              " 'And so the correct output is ˆy = 0.04 15.3 The correct answer is D: Classifier 1 has a decision boundary defined by one linear boundary and is thus based on logistic regression whereas classifier 2 has a very complicated decision boundary that is defined in terms of the observation that is the closest and is therefore based on the 1-nearest neighbor classifier The decision boundary of classifier 3 is based on horizontal and vertical lines and thus is based on the decision tree classifier Classifier four has smooth but non-linear decision boundaries and is thus based on the artificial neural network 15.4 The correct answer is C: It is apparent the decision boundary which best match a 1NN classifier is P3; this rule out all but option C Problems of Chapter 16 16.1 The correct answer is B: The ROC is defined by considering all conceivable thresholds and plotting the true positive rate (TPR) against the false positive rate (FPR) For a threshold larger than 1 we have that TPR=FPR=0',\n",
              " 'lowering the threshold we get when thresholding above 0 that all 11 of the 11 observations or which y=0 are false positive, i.e FPR=1, and all three of three observations where y=1 are true positive, thus TPR=1, giving an AUC =0.864.370 Solutions 16.2 The correct answer is C: To compute the AUC, we need to compute the false positive rate (FPR) and true positive rate (TPR) for particular choices of threshold value ˆy To compute e.g the TPR, one assumes every observation predicted to belong to class 1 with a probability higher than ˆy is actually assigned to class one We then divide the total number of observations belonging to class one and which are predicted to belong to class 1 with the number of observations in the positive class Similarly for the FPR, where we now count the number of observations that are assigned to class one but in fact belongs to class 0, divided by the total number of observations in the negative class',\n",
              " 'The ROC curve is then obtained by plotting these two curves against each other for each threshold value, the point (x, y) = (FPR, TPR) is on the AUC curve This rules out all options except C TPR, FPR curves for the logistic regression classifier in fig 16.3 The correct answer is B: The false positive rate is F P R = F P T N + F P Thus we can find the number of false positives as F P = F P R × T N 1 − F P R ≈ 96.0 Notice thatSolutions 371 T P R = T P T P + F N N = (T P + F N) + (T N + F P) Then T P R = T P N − (T N + F P) which implies T P = T P R × (N − T N − F P) ≈ 171.0 Problems of Chapter 17 17.1 The correct answer is B: There is one misclassified observation and so ε1 = 1/4 and α1 = 1 2 log 1−ε1 ε1 = 0.5493 Then the un-normalized weights become: w =  e −α1 e α1 e −α1 e −α1  = h √ 1 3 √ 3 √ 1 3 √ 1 3 i normalizing gives: w = 1 6  1 3 1 1 and so option B is the correct',\n",
              " 'Bagging sample with replacement such that the same observation can be included multiple times within a round and hence some observations are not included Boosting does not use leave-one-out cross-validation to learn which observation to sample in the next round When combining classifiers in bagging this is attained by majority voting Problems of Chapter 18 18.1 The correct answer is D: In single linkage the observations that is the closest between the clusters define the level in which they merge As such O1 and O4 are the closest to each other with a distance of 0.96 Then O2 and O3 merge at 1.15 and subsequently 05 and 07 at 1.41 01 and 04 next merge with 02 and 03 at 1.52 As the minimum distance between clusters now become the distance between 05 and 07 the cluster O1, O2, O3, O4 merge with 05, 07 at 2.66 Thus dendrogram 1 and 2 are incorrect As 08 merge having a distance to O7 of 2.88 whereas 06 has a minimal distance to O1 of 4.07 dendrogram 4 is correct and dendrogram 3 incorrect',\n",
              " '18.3 The correct answer is D: The true answer is D, dendrogram 4 This is easy to see by for instance comparing the height at which observations 2 and 6 are linked to the true answer in the table 18.4 The correct answer is D: purity = 4 8 · 3 4 + 2 8 · 1 2 + 1 8 · 1 + 1 8 · 1 = 3 4 Problems of Chapter 19 19.1 The correct answer is B: Answer option B is the correct answer as: Cluster located with center at (15,15) has much more spread in the x2 direction (i.e., variance 15) than the x1 direction (i.e., variance 0.5) Furthermore, the cluster located at (30,0) has positive covariance and the cluster located at (0,0) negative covariance These properties only holds for answer option B 19.2 The correct answer is B: k-means and Gaussian Mixture Models (GMM) are dependent on initialization The dendrogram height is indeed determined by proximity and linkage function The update of centers in k-means depends on distance measure, i.e',\n",
              " 'A Gaussian Mixture Model with diagonal covariance matrix does not have the same number of free parameters as k-means as each center has M parameters and the GMM also includes M parameters to define the covariance of each cluster as well as a parameter defining the size, thus resulting in 2KM + K − 1 parameters in total (-1 due to the sum to one constraint of the parameter defining the relative size) whereas k-means would have KM parameters 19.3 The correct answer is C: The two mixture components have similar shape but differ in their weight This leaves options B and C Since they are elongated in the horizontal direction then σ 2 1 = σ 2 2 > δ2 1 = δ 2 2 , ruling out option B This leaves the last option',\n",
              " 'The z-scores for all data objects are given by (rounded to one decimal) n 1 2 3 4 5 6 7 8 |zn| 0.3 0.4 0.5 0.2 2.5 0.4 0.3 0.4  Thus, according to the definition, no objects are judged to be outliers, since no z-score has an absolute value greater than 3.00 20.4 The correct answer is B: For a set to have support more than 52% the set must occur at least 6 out of the 10 times All the itemsets that have this property are {Y AN },{OAY }, {P AY }, {Y AN , P AY }, {OAY , P AY } 20.5 The correct answer is C: density(xO8, 3) = ( 1 3 · (2.88 + 2.96 + 4.74))−1 = 0.2836 density(xO7, 3) = ( 1 3 · (1.41 + 2.88 + 3.54))−1 = 0.3831 density(xO5, 3) = ( 1 3 · (1.41 + 2.66 + 2.84))−1 = 0.4342 density(xO4, 3) = ( 1 3 · (0.96 + 1.76 + 1.52))−1 = 0.7075 a.r.d.(x, K) = density(xO8, 3) 1 3 (density(xO7, 3) + density(xO6, 3) + density(xO4, 3)) = 0.2836 1 3 · (0.3831 + 0.4342 + 0.7075) = 0.56374 Solutions 20.6 The correct answer is D: The true ARD is 0.75',\n",
              " 'This is easiest to compute as p(x = o1) = X 8 i=1 1 8 1 2λ exp(−d(o1, oi)/λ) Problems of Chapter 21 21.1 The correct answer is C: For a set to have support more than 40% the set must occur at least 5 out of the 12 times All the itemsets that have this property are {ML},{MH}, {PH}, {PL}, {DH}, {DL}, {MH, PH}, {ML, DL} 21.2 The correct answer is C: The confidence is given as P(PL = 1|ML = 1, DL = 1) = P(PL = 1, ML = 1, DL = 1) P(ML = 1, DL = 1) = 3/12 5/12 = 3/5(= σPL,ML,DL σML,DL )A Mathematical Notation376 A Mathematical Notation We have tried to keep the mathematical content of the book to the minimum necessary to achieve a proper understanding However, this minimum level is nonzero, and the reader should have a basic grasp of linear algebra, calculus, analysis and probability theory Elementary notation Numbers are denoted by variables such as x and the set of all real numbers (0, 10, 1 3 , −4, √ 2, π, etc.) will be denoted as R',\n",
              " 'Notice vectors are bolded and are typically lower-case roman letters x, y, · · ·  We use R+ = [0, ∞[ for the set of all non-negative numbers The symbol T is used to indicate the transpose of a vector or matrix For instance x T =  −1 4 1  Uppercase bold roman letters W, A, B, · · · indicate matrices, for instance A = \\x14 −1 0 2 1 1 −2 \\x15 , in which case we say A is a 2 × 3 matrix and we write A ∈ R 2×3  The ith element of a vector is written as xi and the i, j’th element of a matrix as Aij (or Ai,j ) For instance x2 = 4 and A2,3 = −2 If we have N observations x1, · · · , xN of a M-dimensional vector x =  x1  , xM T , we can combine the observations into an N × M data matrix X X = \\uf8ee \\uf8ef \\uf8f0 x T 1  x T N \\uf8f9 \\uf8fa \\uf8fb , (A.1) in which the ith row of X corresponds to the row vector x T i  We will use this notation for our data matrix and the rows of X will correspond to N observations and the M columns of X will correspond to M attributes',\n",
              " 'In cases where it is clear from the context which variable will be averaged over we will omit the suffix and simply write E[x 2 ].\\x00\\x00\\x00\\x00A Mathematical Notation 377 Linear Algebra The matrix product is written as Ax Recall for two matrices A, B: (AB) T = B T A T and that the identity matrix IM is the M × M matrix such that for instance I4 = \\uf8ee \\uf8ef \\uf8ef \\uf8f0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 \\uf8f9 \\uf8fa \\uf8fa \\uf8fb  We may suppress M and simply write I Remember AI = IA = A assuming the dimensions match An N ×M matrix A is said to be symmetric if A T = A and quadratic if N = M For a quadratic matrix A, if there exists a matrix A −1 such that AA−1 = A −1A = I, then A is said to be invertible and A −1 is the inverse A necessary and sufficient requirement is that the determinant of A, det(A), is non-zero Subspaces and Eigenvalues If we are given vectors x1,  , xn ∈ R d and numbers a1,  , an ∈ R then the vector x = a1x1 + a2x2 + · · · + anxn, is said to be a linear combination of x1,',\n",
              " 'That is if x1, · · · , xn ∈ V then a1x1 + a2x2 + · · · + anxn ∈ V All vectors that can be written as a linear combination of a set of vectors x1,  , xn is called the span of x1,  Notice the span is a subspace of R d  A set of vectors x1,  , xn is said to be linearly independent if 0 = a1x1 + a2x2 + · · · + anxn, implies a1 = a2 = · · · = an = 0 Otherwise, they are said to be linearly dependent For each subspace V of R d it is possible to find a set of vectors x1,  , xn, n ≤ d such that x1,  , xd are linearly independent and such that the span of x1,  Such as set is known as a basis of V and n is the dimension of the subspace V  The basis is further said to be orthonormal if x T i xj = δij , where δij = 1 if i = j and 0 otherwise Finally, recall that if A is quadratic and there exists a vector x ̸= 0 and a number λ such that Ax = λx, then x is said to be an eigenvector of A and λ the corresponding eigenvalue',\n",
              " 'In particular, if A is a d × d symmetric matrix, A T = A, then there exists an orthonormal basis of eigenvectors for R d .378 A Mathematical Notation Analysis A function f that maps from a D dimensional space to a single real number will be written as f : R D → R, to explicitly specify the dimensions of the spaces f map between This notation, as well as the notation x ∈ R d , may appear cumbersome at a first glance however when considering functions between high-dimensional spaces it will often be a helpful guide to keep track of what the functions do For the same reason we will only use this notation when it benefits the readability and not for formal exactness High-dimensional functions will play a special role in the following and so if we consider a function which maps from a D dimensional space to a M dimensional space (M > 1) we will write f with a boldface: f : R D → R M',\n",
              " 'Notice, we may also sometimes write f(x) as f(x1, x2, x3) We assume the reader is familiar with derivative evaluated at a point x or the partial derivatives evaluated in x df dx(x) and ∂f ∂x2 (x), (A.2) as well as integrals over some or all variables of a function: I = Z RD f(x) dx, I(x1) = Z R2 f(x1, x2, x3) dx2dx3 (A.3) However, knowledge of integrating actual function will not be used and integrals are mostly used to state theoretical results Finally we will use ∇f(x) as the divergence of a function f : R D → R evaluated at x: ∇f(x) = \\uf8ee \\uf8ef \\uf8f0 ∂f ∂x1 (x)  ∂f ∂xD (x) \\uf8f9 \\uf8fa \\uf8fbA Mathematical Notation 379 Slightly more advanced concepts Recall the multivariate Taylor expansion of a function f : R D → R around a point x can be written as f(x + δ) = f(x) + δ T ∇f(x) + higher order terms  For one dimension this is the familiar result f(x + δ) = f(x) + δ df dx(x) + higher order terms',\n",
              " 'Recall also that if we wish to find the minimum or maximum of a function f : R D under a constraint that another function h : R D → R is zero, written as: x ∗ = arg min x:h(x)=0 f(x) This can be done by introducing a Lagrange multiplier λ ∈ R and solve the problem f(x) + λh(x) = 0, by taking derivatives with respect to x and λ and set these equal to zero That is, by simultaneous solving the D + 1 equations: ∇f(x) + λ∇h(x) = 0 and h(x) = 0 We will only use this technique once and a reader not familiar with the method of Lagrange multipliers should consult the many excellent guides available online as texts or videos Probability Theory In probability theory, we always consider the probability of an event, i.e something which either does or does not occur The probability of an event is written with an upper-case P and is a number between 0 and 1',\n",
              " 'B is called a random or stochastic variable, i.e something which outcome is the result of a random process or is otherwise unknown If we suppose b corresponds to the actual result of the coin-flip (i.e a person writes down b = 0 if the coin came out heads and b = 1 if the coin came out tails) we can write the probability of the outcome as simply: P(B = b)380 A Mathematical Notation Sometimes this will be abbreviated as P(b) We stress probabilities are computed of events (boolean occurrences) and it is therefore not possible to talk about the probability of a continuous number, for instance the probability Napoleon was exactly 1.731 meters tall For continuous numbers we use the probability density function (sometimes simply the probability density) which, for a random variable (x1, x2,  , xd) ∈ R d is a non-negative function p : R d → R+, which integrates to one: Z Rd p(x1,  , dxd = 1, where R+ is the interval [0, ∞[',\n",
              " 'The probability density function is not the same as a probability, however you can obtain proba\\ufffebilities by integrating the probability density function For d = 1 we can for instance consider the probability density function p(x) = 1 √ 2π e − x 2 2 , for which R p(x) dx = 1 In this case the probability that the random variable x falls within the interval [2, 3] is simply: P(x ∈ [2, 3]) = Z 3 2 p(x) dx Notice, this is a proper probability In the Napoleon example too we are allowed to say consider the probability Napoleon was between 1.73 and 1.75 meters tall which is a proper event Confusion of the probability density function and probabilities is common and may lead to difficulties later Probability theory is a rich and interesting mathematical discipline and this introduction does not do it service; however, in this book we will take a “naive approach” and not dwell on the details',\n",
              " 'Mining association rules between sets of items in large databases In Acm sigmod record, volume 22, pages 207–216 Rakesh Agrawal, Ramakrishnan Srikant, et al Fast algorithms for mining association rules very large data bases, VLDB, volume 1215, pages 487–499, 1994 Patricia ME Altham The analysis of matched proportions Biometrika, 58(3):561–576, 1971 Introduction to de finetti (1937) foresight: its logical laws, its subjective sources In Breakthroughs in statistics, pages 127–133 Springer, 1992 Bayes and Mr An essay towards solving a problem in the doctrine of chances by the late rev communicated by mr price, in a letter to john canton, a Philosophical Transactions, 53:370–418, 1763 doi: 10.1098/rstl.1763.0053 URL http: //rstl.royalsocietypublishing.org/content/53/370.short Alessio Benavoli, Giorgio Corani, Janez Demˇsar, and Marco Zaffalon Time for a change: a tutorial for comparing multiple classifiers through bayesian analysis',\n",
              " 'Yoshua Bengio and Yves Grandvalet No unbiased estimator of the variance of k-fold cross\\ufffevalidation Journal of machine learning research, 5(Sep):1089–1105, 2004 Christoph Bergmeir, Rob J Hyndman, and Bonsoo Koo A note on the validity of cross-validation for evaluating autoregressive time series prediction Computational Statistics & Data Analysis, 120:70–83, 2018 Pattern Recognition and Machine Learning Information science and statis\\ufffetics Springer, 2013 ISBN 9788132209065 URL https://books.google.dk/books?id= HL4HrgEACAAJ Daniel A Bloch, Geoffrey S Watson, et al A bayesian study of the multinomial distribution The Annals of Mathematical Statistics, 38(5):1423–1435, 1967 Friedman, C.J Stone, and R.A Classification and Regression Trees The Wadsworth and Brooks-Cole statistics-probability series Taylor & Francis, 1984 ISBN 9780412048418 URL https://books.google.co.in/books?id=JwQx-WOmSyQC Leo Breiman Random forests Machine learning, 45(1):5–32, 2001 David A Burn',\n",
              " 'Handbook of Statistics, 1993 Nitesh V Chawla Data mining for imbalanced datasets: An overview In Data mining and knowledge discovery handbook, pages 853–867 Springer, 2005 P Collinson Of bombers, radiologists, and cardiologists: time to roc Heart, 80(3):215–217, 1998.382 References Paulo Cortez, Ant´onio Cerdeira, Fernando Almeida, Telmo Matos, and Jos´e Reis Modeling wine preferences by data mining from physicochemical properties Decision Support Systems, 47(4): 547–553, 2009 Richard T Cox Probability, frequency and reasonable expectation American journal of physics, 14(1):1–13, 1946 Belur V Dasarathy and Belur V Sheela A composite classifier system design: concepts and method\\ufffeology Proceedings of the IEEE, 67(5):708–713, 1979 Bruno De Finetti La pr´evision: ses lois logiques, ses sources subjectives In Annales de l’institut Henri Poincar´e, volume 7, pages 1–68, 1937 Arthur P Dempster, Nan M Laird, and Donald B Rubin Maximum likelihood from incomplete data via the em algorithm',\n",
              " 'Series B (methodological), pages 1–38, 1977 Thomas G Dietterich Approximate statistical tests for comparing supervised classification learning algorithms Neural computation, 10(7):1895–1923, 1998 Evelyn Fix and Joseph L Hodges Discriminatory analysis-nonparametric discrimination: consis\\ufffetency properties Technical report, DTIC Document, 1951 Yoav Freund and Robert E Schapire A decision-theoretic generalization of on-line learning and an application to boosting Journal of computer and system sciences, 55(1):119–139, 1997 Garnier and A Correspondance math´ematique et physique Vandekerck\\ufffehove, 1838 URL https://books.google.dk/books?id=8GsEAAAAYAAJ Theoria Motvs Corporvm Coelestivm In Sectionibvs Conicis Solem Ambientivm Perthes et J Besser, 1809 URL https://books.google.dk/books?id=7jJbAAAAcAAJ Teofilo F Gonzalez Clustering to minimize the maximum intercluster distance Theoretical Com\\ufffeputer Science, 38:293–306, 1985 Alan H´ajek',\n",
              " 'In Probability, Dynamics and Causality, pages 69–87 Springer, 1997 Alan H´ajek Fifteen arguments against hypothetical frequentism Erkenntnis, 70(2):211–235, 2009 Lars Kai Hansen and Peter Salamon Neural network ensembles IEEE transactions on pattern analysis and machine intelligence, 12:993–1001, 1990 Tibshirani, and J The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition Springer Series in Statistics Springer New York, 2009 ISBN 9780387848587 URL https://books.google.dk/books?id=tVIjmNS3Ob8C Random decision forests In Document Analysis and Recognition, 1995., Proceedings of the Third International Conference on, volume 1, pages 278–282 Harold Hotelling Analysis of a complex of statistical variables into principal components Journal of educational psychology, 24(6):417, 1933 Earl B Hunt, Janet Marin, and Philip J Stone Experiments in induction Academic Press, 1966 Hastie, and R An Introduction to Statistical Learning: with Applications in R',\n",
              " 'Springer New York, 2014 ISBN 9781461471370 URL https://books.google.dk/books?id=at1bmAEACAAJ Edwin T Jaynes Prior probabilities IEEE Transactions on systems science and cybernetics, 4(3): 227–241, 1968 Edwin T Jaynes Probability theory: The logic of science Cambridge university press, 2003 Theory of Probability The International series of monographs on physics At The Clarendon Press, 1939 URL https://books.google.dk/books?id=6_ogAAAAMAAJ.References 383 Harold Jeffreys An invariant form for the prior probability in estimation problems A, 186(1007):453–461, 1946 Stephen C Johnson Hierarchical clustering schemes Psychometrika, 32(3):241–254, 1967 Kahneman, P Slovic, and A Judgment Under Uncertainty: Heuristics and Biases Cambridge University Press, 1982 ISBN 9780521284141 URL https://books.google.co.uk/ books?id=_0H8gwj4a1MC A study of cross-validation and bootstrap for accuracy estimation and model selection pages 1137–1143 Morgan Kaufmann, 1995 Statistics in function space Indian Math',\n",
              " 'Nouvelles m´ethodes pour la d´etermination des orbites des com`etes Didot, 1805 URL https://books.google.dk/books?id=FRcOAAAAQAAJ David JC MacKay Information theory, inference and learning algorithms Cambridge university press, 2003 James MacQueen et al Some methods for classification and analysis of multivariate observations In Proceedings of the fifth Berkeley symposium on mathematical statistics and probability, volume 1, pages 281–297 Oakland, CA, USA., 1967 Warren S McCulloch and Walter Pitts A logical calculus of the ideas immanent in nervous activity The bulletin of mathematical biophysics, 5(4):115–133, 1943 Claude Nadeau and Yoshua Bengio Inference for the generalization error In Advances in neural information processing systems, pages 307–313, 2000 Emanuel Parzen On estimation of a probability density function and mode The annals of mathe\\ufffematical statistics, 33(3):1065–1076, 1962 Judea Pearl Probabilistic reasoning in intelligent systems: networks of plausible inference',\n",
              " 'Judea Pearl, Madelyn Glymour, and Nicholas P Jewell Causal Inference in Statistics: A Primer John Wiley & Sons, 2016 Karl Pearson Contributions to the mathematical theory of evolution Philosophical Transactions of the Royal Society of London A, 185:71–110, 1894 Karl Pearson on lines and planes of closest fit to systems of points in space Philosophical Magazine Series 6, 2(11):559–572, 1901 doi: 10.1080/14786440109462720 URL http://dx.doi org/10.1080/14786440109462720 Kaare Brandt Petersen, Michael Syskind Pedersen, et al The matrix cookbook Technical University of Denmark, 7(15):510, 2008 Vikas C Raykar and Ramani Duraiswami Fast optimal bandwidth selection for kernel density estimation In SDM, pages 524–528 Murray Rosenblatt et al Remarks on some nonparametric estimates of a density function The Annals of Mathematical Statistics, 27(3):832–837, 1956 Robert E Schapire The strength of weak learnability Machine learning, 5(2):197–227, 1990 Steve Selvin, M',\n",
              " 'Rex Bryce, James A Hagans, Thomas C Chalmers, E Maxwell, and Gary N Letters to the editor The American Statistician, 29(1):67–71, 1975 ISSN 00031305 URL http://www.jstor.org/ stable/2683689 A mathematical theory of communication The Bell System Technical Journal, 27 (3):379–423, July 1948 ISSN 0005-8580 doi: 10.1002/j.1538-7305.1948.tb01338.x Sur la division des corp materiels en parties Sci, 1:801–804, 1956.384 References S On the theory of scales of measurement Science, 103(2684):677–680, 1946 ISSN 0036- 8075 doi: 10.1126/science.103.2684.677 URL http://science.sciencemag.org/content/103/ 2684/677 Gilbert W Stewart On the early history of the singular value decomposition SIAM review, 35(4): 551–566, 1993 Alexander Strehl and Joydeep Ghosh Cluster ensembles—a knowledge reuse framework for com\\ufffebining multiple partitions Journal of machine learning research, 3(Dec):583–617, 2002 Steinbach, and V Introduction to Data Mining Addison-Wesley, 2013 ISBN 9780133128901']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_segments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [],
      "source": [
        "text_segments_old = text_segments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [],
      "source": [
        "text_segments = [''.join(x) for x in zip(text_segments_old,text_sentences[1::2])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'.'"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_sentences[1::2][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "671"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(text_segments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1002"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max([len(seg) for seg in text_segments])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' Tue Herlau, Mikkel N Schmidt and Morten Mørup Introduction to Machine Learning and Data Mining Lecture notes, Spring 2022, version 1.0 Version for print This document may not be redistributed All rights belongs to the authors and DTU April 5, 2022 Technical University of DenmarkNotation cheat sheet Matlab var Type Size Description X Numeric N × M Data matrix: The rows correspond to N data objects, each of which contains M at\\ufffetributes attributeNames Cell array M × 1 Attribute names: Name (string) for each of the M attributes N Numeric Scalar Number of data objects M Numeric Scalar Number of attributes Regression y Numeric N × 1 Dependent variable (output): For each data object, y contains an output value that we wish to predict Classification y Numeric N × 1 Class index: For each data object, y con\\ufffetains a class index, yn ∈ {0, 1,  , C − 1}, where C is the total number of classes classNames Cell array C × 1 Class names: Name (string) for each of the C classes.'"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_segments[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Questions from round 1 saved!\n",
            "Questions from round 2 saved!\n",
            "Questions from round 3 saved!\n",
            "Questions from round 4 saved!\n",
            "Questions from round 5 saved!\n",
            "Questions from round 6 saved!\n",
            "Questions from round 7 saved!\n",
            "Questions from round 8 saved!\n",
            "Questions from round 9 saved!\n",
            "Questions from round 10 saved!\n",
            "Questions from round 11 saved!\n",
            "Questions from round 12 saved!\n",
            "Questions from round 13 saved!\n",
            "Questions from round 14 saved!\n",
            "Questions from round 15 saved!\n",
            "Questions from round 16 saved!\n",
            "Questions from round 17 saved!\n",
            "Questions from round 18 saved!\n",
            "Questions from round 19 saved!\n",
            "Questions from round 20 saved!\n",
            "Questions from round 21 saved!\n",
            "Questions from round 22 saved!\n",
            "Questions from round 23 saved!\n",
            "Questions from round 24 saved!\n",
            "Questions from round 25 saved!\n",
            "Questions from round 26 saved!\n",
            "OPENAI_ERROR: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 951017b3bcbae2a6a9590ee9b3df84b0 in your message.)\n",
            "Questions from round 28 saved!\n",
            "Questions from round 29 saved!\n",
            "Questions from round 30 saved!\n",
            "Questions from round 31 saved!\n",
            "Questions from round 32 saved!\n",
            "Questions from round 33 saved!\n",
            "Questions from round 34 saved!\n",
            "Questions from round 35 saved!\n",
            "Questions from round 36 saved!\n",
            "Questions from round 37 saved!\n",
            "Questions from round 38 saved!\n",
            "Questions from round 39 saved!\n",
            "Questions from round 40 saved!\n",
            "Questions from round 41 saved!\n",
            "Questions from round 42 saved!\n",
            "Questions from round 43 saved!\n",
            "Questions from round 44 saved!\n",
            "Questions from round 45 saved!\n",
            "Questions from round 46 saved!\n",
            "Questions from round 47 saved!\n",
            "Questions from round 48 saved!\n",
            "Questions from round 49 saved!\n",
            "Questions from round 50 saved!\n",
            "Questions from round 51 saved!\n",
            "Questions from round 52 saved!\n",
            "Questions from round 53 saved!\n",
            "Questions from round 54 saved!\n",
            "Questions from round 55 saved!\n",
            "Questions from round 56 saved!\n",
            "OPENAI_ERROR: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7c1c7722d3948bbf157f99598b87588d in your message.)\n",
            "Questions from round 58 saved!\n",
            "Questions from round 59 saved!\n",
            "Questions from round 60 saved!\n",
            "Questions from round 61 saved!\n",
            "Questions from round 62 saved!\n",
            "Questions from round 63 saved!\n",
            "Questions from round 64 saved!\n",
            "Questions from round 65 saved!\n",
            "Questions from round 66 saved!\n",
            "Questions from round 67 saved!\n",
            "Questions from round 68 saved!\n",
            "Questions from round 69 saved!\n",
            "Questions from round 70 saved!\n",
            "Questions from round 71 saved!\n",
            "Questions from round 72 saved!\n",
            "Questions from round 73 saved!\n",
            "Questions from round 74 saved!\n",
            "Questions from round 75 saved!\n",
            "Questions from round 76 saved!\n",
            "Questions from round 77 saved!\n",
            "Questions from round 78 saved!\n",
            "Questions from round 79 saved!\n",
            "Questions from round 80 saved!\n",
            "Questions from round 81 saved!\n",
            "Questions from round 82 saved!\n",
            "Questions from round 83 saved!\n",
            "Questions from round 84 saved!\n",
            "Questions from round 85 saved!\n",
            "Questions from round 86 saved!\n",
            "Questions from round 87 saved!\n",
            "Questions from round 88 saved!\n",
            "Questions from round 89 saved!\n",
            "Questions from round 90 saved!\n",
            "Questions from round 91 saved!\n",
            "Questions from round 92 saved!\n",
            "Questions from round 93 saved!\n",
            "Questions from round 94 saved!\n",
            "Questions from round 95 saved!\n",
            "Questions from round 96 saved!\n",
            "Questions from round 97 saved!\n",
            "Questions from round 98 saved!\n",
            "Questions from round 99 saved!\n",
            "Questions from round 100 saved!\n",
            "Questions from round 101 saved!\n",
            "Questions from round 102 saved!\n",
            "Questions from round 103 saved!\n",
            "Questions from round 104 saved!\n",
            "Questions from round 105 saved!\n",
            "Questions from round 106 saved!\n",
            "Questions from round 107 saved!\n",
            "Questions from round 108 saved!\n",
            "Questions from round 109 saved!\n",
            "Questions from round 110 saved!\n",
            "Questions from round 111 saved!\n",
            "Questions from round 112 saved!\n",
            "Questions from round 113 saved!\n",
            "Questions from round 114 saved!\n",
            "Questions from round 115 saved!\n",
            "Questions from round 116 saved!\n",
            "Questions from round 117 saved!\n",
            "Questions from round 118 saved!\n",
            "Questions from round 119 saved!\n",
            "Questions from round 120 saved!\n",
            "Questions from round 121 saved!\n",
            "Questions from round 122 saved!\n",
            "Questions from round 123 saved!\n",
            "Questions from round 124 saved!\n",
            "Questions from round 125 saved!\n",
            "Questions from round 126 saved!\n",
            "Questions from round 127 saved!\n",
            "Questions from round 128 saved!\n",
            "Questions from round 129 saved!\n",
            "Questions from round 130 saved!\n",
            "Questions from round 131 saved!\n",
            "Questions from round 132 saved!\n",
            "Questions from round 133 saved!\n",
            "Questions from round 134 saved!\n",
            "Questions from round 135 saved!\n",
            "Questions from round 136 saved!\n",
            "OPENAI_ERROR: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID be193e44cc921c5b8b525db863a52a16 in your message.)\n",
            "Questions from round 138 saved!\n",
            "Questions from round 139 saved!\n",
            "Questions from round 140 saved!\n",
            "Questions from round 141 saved!\n",
            "Questions from round 142 saved!\n",
            "Questions from round 143 saved!\n",
            "Questions from round 144 saved!\n",
            "Questions from round 145 saved!\n",
            "Questions from round 146 saved!\n",
            "Questions from round 147 saved!\n",
            "Questions from round 148 saved!\n",
            "Questions from round 149 saved!\n",
            "Questions from round 150 saved!\n",
            "Questions from round 151 saved!\n",
            "Questions from round 152 saved!\n",
            "Questions from round 153 saved!\n",
            "OPENAI_ERROR: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 687e3fb46f2f593f5d213e4e79afdf4a in your message.)\n",
            "Questions from round 155 saved!\n",
            "Questions from round 156 saved!\n",
            "Questions from round 157 saved!\n",
            "Questions from round 158 saved!\n",
            "Questions from round 159 saved!\n",
            "Questions from round 160 saved!\n",
            "Questions from round 161 saved!\n",
            "Questions from round 162 saved!\n",
            "Questions from round 163 saved!\n",
            "OPENAI_ERROR: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1f366f1c31bc795fef784e0266750ab3 in your message.)\n",
            "Questions from round 165 saved!\n",
            "Questions from round 166 saved!\n",
            "Questions from round 167 saved!\n",
            "Questions from round 168 saved!\n",
            "Questions from round 169 saved!\n",
            "Questions from round 170 saved!\n",
            "Questions from round 171 saved!\n",
            "Questions from round 172 saved!\n",
            "Questions from round 173 saved!\n",
            "Questions from round 174 saved!\n",
            "Questions from round 175 saved!\n",
            "Questions from round 176 saved!\n",
            "Questions from round 177 saved!\n",
            "Questions from round 178 saved!\n",
            "Questions from round 179 saved!\n",
            "Questions from round 180 saved!\n",
            "Questions from round 181 saved!\n",
            "Questions from round 182 saved!\n",
            "Questions from round 183 saved!\n",
            "Questions from round 184 saved!\n",
            "Questions from round 185 saved!\n",
            "Questions from round 186 saved!\n",
            "Questions from round 187 saved!\n",
            "Questions from round 188 saved!\n",
            "Questions from round 189 saved!\n",
            "Questions from round 190 saved!\n",
            "Questions from round 191 saved!\n",
            "Questions from round 192 saved!\n",
            "Questions from round 193 saved!\n",
            "Questions from round 194 saved!\n",
            "Questions from round 195 saved!\n",
            "Questions from round 196 saved!\n",
            "Questions from round 197 saved!\n",
            "Questions from round 198 saved!\n",
            "Questions from round 199 saved!\n",
            "OPENAI_ERROR: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5d14d485d3af0a2eaeebf7708a688ec3 in your message.)\n",
            "Questions from round 201 saved!\n",
            "Questions from round 202 saved!\n",
            "Questions from round 203 saved!\n",
            "Questions from round 204 saved!\n",
            "Questions from round 205 saved!\n",
            "OPENAI_ERROR: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2f43bc87f36f8fef0baedf4717b82540 in your message.)\n",
            "Questions from round 207 saved!\n",
            "Questions from round 208 saved!\n",
            "Questions from round 209 saved!\n",
            "Questions from round 210 saved!\n",
            "Questions from round 211 saved!\n",
            "Questions from round 212 saved!\n",
            "Questions from round 213 saved!\n",
            "Questions from round 214 saved!\n",
            "Questions from round 215 saved!\n",
            "Questions from round 216 saved!\n",
            "Questions from round 217 saved!\n",
            "Questions from round 218 saved!\n",
            "Questions from round 219 saved!\n",
            "Questions from round 220 saved!\n",
            "Questions from round 221 saved!\n",
            "Questions from round 222 saved!\n",
            "Questions from round 223 saved!\n",
            "Questions from round 224 saved!\n",
            "Questions from round 225 saved!\n",
            "Questions from round 226 saved!\n",
            "Questions from round 227 saved!\n",
            "Questions from round 228 saved!\n",
            "Questions from round 229 saved!\n",
            "Questions from round 230 saved!\n",
            "Questions from round 231 saved!\n",
            "Questions from round 232 saved!\n",
            "Questions from round 233 saved!\n",
            "Questions from round 234 saved!\n",
            "Questions from round 235 saved!\n",
            "Questions from round 236 saved!\n",
            "Questions from round 237 saved!\n",
            "Questions from round 238 saved!\n",
            "Questions from round 239 saved!\n",
            "Questions from round 240 saved!\n",
            "Questions from round 241 saved!\n",
            "Questions from round 242 saved!\n",
            "Questions from round 243 saved!\n",
            "Questions from round 244 saved!\n",
            "Questions from round 245 saved!\n",
            "Questions from round 246 saved!\n",
            "Questions from round 247 saved!\n",
            "Questions from round 248 saved!\n",
            "Questions from round 249 saved!\n",
            "Questions from round 250 saved!\n",
            "Questions from round 251 saved!\n",
            "Questions from round 252 saved!\n",
            "Questions from round 253 saved!\n",
            "Questions from round 254 saved!\n",
            "Questions from round 255 saved!\n",
            "Questions from round 256 saved!\n",
            "Questions from round 257 saved!\n",
            "Questions from round 258 saved!\n",
            "Questions from round 259 saved!\n",
            "Questions from round 260 saved!\n",
            "Questions from round 261 saved!\n",
            "Questions from round 262 saved!\n",
            "Questions from round 263 saved!\n",
            "Questions from round 264 saved!\n",
            "Questions from round 265 saved!\n",
            "Questions from round 266 saved!\n",
            "Questions from round 267 saved!\n",
            "Questions from round 268 saved!\n",
            "Questions from round 269 saved!\n",
            "Questions from round 270 saved!\n",
            "Questions from round 271 saved!\n",
            "Questions from round 272 saved!\n",
            "Questions from round 273 saved!\n",
            "Questions from round 274 saved!\n",
            "Questions from round 275 saved!\n",
            "Questions from round 276 saved!\n",
            "Questions from round 277 saved!\n",
            "Questions from round 278 saved!\n",
            "Questions from round 279 saved!\n",
            "Questions from round 280 saved!\n",
            "Questions from round 281 saved!\n",
            "Questions from round 282 saved!\n",
            "Questions from round 283 saved!\n",
            "Questions from round 284 saved!\n",
            "Questions from round 285 saved!\n",
            "Questions from round 286 saved!\n",
            "Questions from round 287 saved!\n",
            "Questions from round 288 saved!\n",
            "Questions from round 289 saved!\n",
            "Questions from round 290 saved!\n",
            "Questions from round 291 saved!\n",
            "Questions from round 292 saved!\n",
            "Questions from round 293 saved!\n",
            "Questions from round 294 saved!\n",
            "Questions from round 295 saved!\n",
            "Questions from round 296 saved!\n",
            "Questions from round 297 saved!\n",
            "Questions from round 298 saved!\n",
            "Questions from round 299 saved!\n",
            "Questions from round 300 saved!\n",
            "Questions from round 301 saved!\n",
            "Questions from round 302 saved!\n",
            "Questions from round 303 saved!\n",
            "Questions from round 304 saved!\n",
            "Questions from round 305 saved!\n",
            "Questions from round 306 saved!\n",
            "Questions from round 307 saved!\n",
            "Questions from round 308 saved!\n",
            "Questions from round 309 saved!\n",
            "Questions from round 310 saved!\n",
            "Questions from round 311 saved!\n",
            "Questions from round 312 saved!\n",
            "Questions from round 313 saved!\n",
            "Questions from round 314 saved!\n",
            "Questions from round 315 saved!\n",
            "Questions from round 316 saved!\n",
            "Questions from round 317 saved!\n",
            "Questions from round 318 saved!\n",
            "Questions from round 319 saved!\n",
            "Questions from round 320 saved!\n",
            "OPENAI_ERROR: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID aeb12a93b87fee06df6e48b53ebda333 in your message.)\n",
            "Questions from round 322 saved!\n",
            "Questions from round 323 saved!\n",
            "Questions from round 324 saved!\n",
            "Questions from round 325 saved!\n",
            "Questions from round 326 saved!\n",
            "Questions from round 327 saved!\n",
            "Questions from round 328 saved!\n",
            "Questions from round 329 saved!\n",
            "Questions from round 330 saved!\n",
            "Questions from round 331 saved!\n",
            "Questions from round 332 saved!\n",
            "Questions from round 333 saved!\n",
            "Questions from round 334 saved!\n",
            "Questions from round 335 saved!\n",
            "Questions from round 336 saved!\n",
            "Questions from round 337 saved!\n",
            "OPENAI_ERROR: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b8515328801b7abca97a9384bf096698 in your message.)\n",
            "Questions from round 339 saved!\n",
            "Questions from round 340 saved!\n",
            "Questions from round 341 saved!\n",
            "Questions from round 342 saved!\n",
            "Questions from round 343 saved!\n",
            "Questions from round 344 saved!\n",
            "Questions from round 345 saved!\n",
            "Questions from round 346 saved!\n",
            "Questions from round 347 saved!\n",
            "Questions from round 348 saved!\n",
            "Questions from round 349 saved!\n",
            "Questions from round 350 saved!\n",
            "Questions from round 351 saved!\n",
            "Questions from round 352 saved!\n",
            "Questions from round 353 saved!\n",
            "Questions from round 354 saved!\n",
            "Questions from round 355 saved!\n",
            "Questions from round 356 saved!\n",
            "Questions from round 357 saved!\n",
            "Questions from round 358 saved!\n",
            "[Error] questions not generated for 358\n",
            "Questions from round 360 saved!\n",
            "Questions from round 361 saved!\n",
            "Questions from round 362 saved!\n",
            "Questions from round 363 saved!\n",
            "Questions from round 364 saved!\n",
            "Questions from round 365 saved!\n",
            "Questions from round 366 saved!\n",
            "Questions from round 367 saved!\n",
            "Questions from round 368 saved!\n",
            "Questions from round 369 saved!\n",
            "Questions from round 370 saved!\n",
            "Questions from round 371 saved!\n",
            "Questions from round 372 saved!\n",
            "Questions from round 373 saved!\n",
            "Questions from round 374 saved!\n",
            "Questions from round 375 saved!\n",
            "Questions from round 376 saved!\n",
            "Questions from round 377 saved!\n",
            "Questions from round 378 saved!\n",
            "Questions from round 379 saved!\n",
            "Questions from round 380 saved!\n",
            "Questions from round 381 saved!\n",
            "Questions from round 382 saved!\n",
            "Questions from round 383 saved!\n",
            "Questions from round 384 saved!\n",
            "Questions from round 385 saved!\n",
            "Questions from round 386 saved!\n",
            "Questions from round 387 saved!\n",
            "Questions from round 388 saved!\n",
            "Questions from round 389 saved!\n",
            "Questions from round 390 saved!\n",
            "Questions from round 391 saved!\n",
            "Questions from round 392 saved!\n",
            "Questions from round 393 saved!\n",
            "Questions from round 394 saved!\n",
            "Questions from round 395 saved!\n",
            "OPENAI_ERROR: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b459743ba0ad02b695c165f2d3701cda in your message.)\n",
            "Questions from round 397 saved!\n",
            "Questions from round 398 saved!\n",
            "Questions from round 399 saved!\n",
            "Questions from round 400 saved!\n",
            "Questions from round 401 saved!\n",
            "Questions from round 402 saved!\n",
            "Questions from round 403 saved!\n",
            "Questions from round 404 saved!\n",
            "Questions from round 405 saved!\n",
            "Questions from round 406 saved!\n",
            "Questions from round 407 saved!\n",
            "Questions from round 408 saved!\n",
            "Questions from round 409 saved!\n",
            "Questions from round 410 saved!\n",
            "Questions from round 411 saved!\n",
            "Questions from round 412 saved!\n",
            "Questions from round 413 saved!\n",
            "Questions from round 414 saved!\n",
            "Questions from round 415 saved!\n",
            "Questions from round 416 saved!\n",
            "Questions from round 417 saved!\n",
            "Questions from round 418 saved!\n",
            "Questions from round 419 saved!\n",
            "Questions from round 420 saved!\n",
            "Questions from round 421 saved!\n",
            "Questions from round 422 saved!\n",
            "Questions from round 423 saved!\n",
            "Questions from round 424 saved!\n",
            "OPENAI_ERROR: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ff213df92be841b421be5bbd7980cc78 in your message.)\n",
            "Questions from round 426 saved!\n",
            "Questions from round 427 saved!\n",
            "Questions from round 428 saved!\n",
            "Questions from round 429 saved!\n",
            "Questions from round 430 saved!\n",
            "Questions from round 431 saved!\n",
            "Questions from round 432 saved!\n",
            "OPENAI_ERROR: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9f8f591e342ab2e62ae2bf562d7cc050 in your message.)\n",
            "Questions from round 434 saved!\n",
            "Questions from round 435 saved!\n",
            "Questions from round 436 saved!\n",
            "Questions from round 437 saved!\n",
            "Questions from round 438 saved!\n",
            "Questions from round 439 saved!\n",
            "Questions from round 440 saved!\n",
            "Questions from round 441 saved!\n",
            "Questions from round 442 saved!\n",
            "Questions from round 443 saved!\n",
            "Questions from round 444 saved!\n",
            "Questions from round 445 saved!\n",
            "Questions from round 446 saved!\n",
            "Questions from round 447 saved!\n",
            "Questions from round 448 saved!\n",
            "Questions from round 449 saved!\n",
            "Questions from round 450 saved!\n",
            "Questions from round 451 saved!\n",
            "Questions from round 452 saved!\n",
            "Questions from round 453 saved!\n",
            "Questions from round 454 saved!\n",
            "Questions from round 455 saved!\n",
            "Questions from round 456 saved!\n",
            "Questions from round 457 saved!\n",
            "Questions from round 458 saved!\n",
            "Questions from round 459 saved!\n",
            "Questions from round 460 saved!\n",
            "Questions from round 461 saved!\n",
            "Questions from round 462 saved!\n",
            "Questions from round 463 saved!\n",
            "OPENAI_ERROR: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e3f00b62eb6b0038b8699faf732909c3 in your message.)\n",
            "Questions from round 465 saved!\n",
            "Questions from round 466 saved!\n",
            "Questions from round 467 saved!\n",
            "Questions from round 468 saved!\n",
            "Questions from round 469 saved!\n",
            "Questions from round 470 saved!\n",
            "Questions from round 471 saved!\n",
            "Questions from round 472 saved!\n",
            "Questions from round 473 saved!\n",
            "Questions from round 474 saved!\n",
            "Questions from round 475 saved!\n",
            "Questions from round 476 saved!\n",
            "Questions from round 477 saved!\n",
            "Questions from round 478 saved!\n",
            "Questions from round 479 saved!\n",
            "Questions from round 480 saved!\n",
            "Questions from round 481 saved!\n",
            "Questions from round 482 saved!\n",
            "Questions from round 483 saved!\n",
            "Questions from round 484 saved!\n",
            "Questions from round 485 saved!\n",
            "Questions from round 486 saved!\n",
            "Questions from round 487 saved!\n",
            "Questions from round 488 saved!\n",
            "Questions from round 489 saved!\n",
            "Questions from round 490 saved!\n",
            "Questions from round 491 saved!\n",
            "Questions from round 492 saved!\n",
            "Questions from round 493 saved!\n",
            "Questions from round 494 saved!\n",
            "Questions from round 495 saved!\n",
            "Questions from round 496 saved!\n",
            "Questions from round 497 saved!\n",
            "Questions from round 498 saved!\n",
            "Questions from round 499 saved!\n",
            "Questions from round 500 saved!\n",
            "Questions from round 501 saved!\n",
            "Questions from round 502 saved!\n",
            "Questions from round 503 saved!\n",
            "Questions from round 504 saved!\n",
            "Questions from round 505 saved!\n",
            "Questions from round 506 saved!\n",
            "Questions from round 507 saved!\n",
            "Questions from round 508 saved!\n",
            "Questions from round 509 saved!\n",
            "Questions from round 510 saved!\n",
            "Questions from round 511 saved!\n",
            "Questions from round 512 saved!\n",
            "Questions from round 513 saved!\n",
            "Questions from round 514 saved!\n",
            "Questions from round 515 saved!\n",
            "Questions from round 516 saved!\n",
            "Questions from round 517 saved!\n",
            "Questions from round 518 saved!\n",
            "Questions from round 519 saved!\n",
            "Questions from round 520 saved!\n",
            "Questions from round 521 saved!\n",
            "Questions from round 522 saved!\n",
            "Questions from round 523 saved!\n",
            "Questions from round 524 saved!\n",
            "Questions from round 525 saved!\n",
            "Questions from round 526 saved!\n",
            "Questions from round 527 saved!\n",
            "Questions from round 528 saved!\n",
            "Questions from round 529 saved!\n",
            "Questions from round 530 saved!\n",
            "Questions from round 531 saved!\n",
            "Questions from round 532 saved!\n",
            "Questions from round 533 saved!\n",
            "Questions from round 534 saved!\n",
            "Questions from round 535 saved!\n",
            "Questions from round 536 saved!\n",
            "Questions from round 537 saved!\n",
            "Questions from round 538 saved!\n",
            "Questions from round 539 saved!\n",
            "Questions from round 540 saved!\n",
            "Questions from round 541 saved!\n",
            "Questions from round 542 saved!\n",
            "Questions from round 543 saved!\n",
            "Questions from round 544 saved!\n",
            "Questions from round 545 saved!\n",
            "Questions from round 546 saved!\n",
            "Questions from round 547 saved!\n",
            "Questions from round 548 saved!\n",
            "Questions from round 549 saved!\n",
            "Questions from round 550 saved!\n",
            "Questions from round 551 saved!\n",
            "Questions from round 552 saved!\n",
            "Questions from round 553 saved!\n",
            "Questions from round 554 saved!\n",
            "Questions from round 555 saved!\n",
            "Questions from round 556 saved!\n",
            "Questions from round 557 saved!\n",
            "Questions from round 558 saved!\n",
            "Questions from round 559 saved!\n",
            "Questions from round 560 saved!\n",
            "Questions from round 561 saved!\n",
            "Questions from round 562 saved!\n",
            "Questions from round 563 saved!\n",
            "Questions from round 564 saved!\n",
            "Questions from round 565 saved!\n",
            "Questions from round 566 saved!\n",
            "Questions from round 567 saved!\n",
            "Questions from round 568 saved!\n",
            "OPENAI_ERROR: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 64dc70cc5ead61a272e576c54bd6a540 in your message.)\n",
            "Questions from round 570 saved!\n",
            "Questions from round 571 saved!\n",
            "Questions from round 572 saved!\n",
            "Questions from round 573 saved!\n",
            "Questions from round 574 saved!\n",
            "Questions from round 575 saved!\n",
            "Questions from round 576 saved!\n",
            "Questions from round 577 saved!\n",
            "Questions from round 578 saved!\n",
            "Questions from round 579 saved!\n",
            "Questions from round 580 saved!\n",
            "Questions from round 581 saved!\n",
            "Questions from round 582 saved!\n",
            "Questions from round 583 saved!\n",
            "Questions from round 584 saved!\n",
            "Questions from round 585 saved!\n",
            "Questions from round 586 saved!\n",
            "Questions from round 587 saved!\n",
            "Questions from round 588 saved!\n",
            "Questions from round 589 saved!\n",
            "Questions from round 590 saved!\n",
            "Questions from round 591 saved!\n",
            "Questions from round 592 saved!\n",
            "Questions from round 593 saved!\n",
            "Questions from round 594 saved!\n",
            "Questions from round 595 saved!\n",
            "Questions from round 596 saved!\n",
            "Questions from round 597 saved!\n",
            "Questions from round 598 saved!\n",
            "Questions from round 599 saved!\n",
            "OPENAI_ERROR: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7e6663ff9e7c5fd6bd3a9827fecb4233 in your message.)\n",
            "Questions from round 601 saved!\n",
            "Questions from round 602 saved!\n",
            "Questions from round 603 saved!\n",
            "Questions from round 604 saved!\n",
            "Questions from round 605 saved!\n",
            "Questions from round 606 saved!\n",
            "Questions from round 607 saved!\n",
            "Questions from round 608 saved!\n",
            "Questions from round 609 saved!\n",
            "Questions from round 610 saved!\n",
            "Questions from round 611 saved!\n",
            "Questions from round 612 saved!\n",
            "Questions from round 613 saved!\n",
            "Questions from round 614 saved!\n",
            "Questions from round 615 saved!\n",
            "Questions from round 616 saved!\n",
            "Questions from round 617 saved!\n",
            "Questions from round 618 saved!\n",
            "Questions from round 619 saved!\n",
            "Questions from round 620 saved!\n",
            "Questions from round 621 saved!\n",
            "Questions from round 622 saved!\n",
            "Questions from round 623 saved!\n",
            "Questions from round 624 saved!\n",
            "Questions from round 625 saved!\n",
            "Questions from round 626 saved!\n",
            "OPENAI_ERROR: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 533510f2cdefdab219855d96dd02d2f5 in your message.)\n",
            "Questions from round 628 saved!\n",
            "Questions from round 629 saved!\n",
            "Questions from round 630 saved!\n",
            "Questions from round 631 saved!\n",
            "Questions from round 632 saved!\n",
            "Questions from round 633 saved!\n",
            "Questions from round 634 saved!\n",
            "Questions from round 635 saved!\n",
            "Questions from round 636 saved!\n",
            "Questions from round 637 saved!\n",
            "Questions from round 638 saved!\n",
            "Questions from round 639 saved!\n",
            "Questions from round 640 saved!\n",
            "Questions from round 641 saved!\n",
            "Questions from round 642 saved!\n",
            "Questions from round 643 saved!\n",
            "Questions from round 644 saved!\n",
            "Questions from round 645 saved!\n",
            "Questions from round 646 saved!\n",
            "Questions from round 647 saved!\n",
            "Questions from round 648 saved!\n",
            "Questions from round 649 saved!\n",
            "Questions from round 650 saved!\n",
            "OPENAI_ERROR: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5f5e64083765ba9f84f84ac4b2682d65 in your message.)\n",
            "Questions from round 652 saved!\n",
            "Questions from round 653 saved!\n",
            "Questions from round 654 saved!\n",
            "Questions from round 655 saved!\n",
            "Questions from round 656 saved!\n",
            "Questions from round 657 saved!\n",
            "Questions from round 658 saved!\n",
            "Questions from round 659 saved!\n",
            "Questions from round 660 saved!\n",
            "Questions from round 661 saved!\n",
            "Questions from round 662 saved!\n",
            "Questions from round 663 saved!\n",
            "Questions from round 664 saved!\n",
            "Questions from round 665 saved!\n",
            "Questions from round 666 saved!\n",
            "Questions from round 667 saved!\n",
            "Questions from round 668 saved!\n",
            "Questions from round 669 saved!\n",
            "OPENAI_ERROR: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 17a1e7b26b7740083bbdea0f74cb4e74 in your message.)\n",
            "Questions from round 671 saved!\n"
          ]
        }
      ],
      "source": [
        "# Ask ChatGPT to make questions to sections\n",
        "combinations = []\n",
        "\n",
        "req_per_min = 0\n",
        "max_req_per_min = 3\n",
        "last_time_stamp = time.time()\n",
        "# For each pair of questions\n",
        "for i in range(0, len(text_segments)):\n",
        "    context = text_segments[i]\n",
        "    \n",
        "    # Check rate limit\n",
        "    req_per_min += 1\n",
        "    while req_per_min>=max_req_per_min:\n",
        "        time_stamp = time.time()\n",
        "        if int(time.time()-last_time_stamp) > 60:\n",
        "            last_time_stamp = time_stamp\n",
        "            req_per_min = 0\n",
        "        else:\n",
        "            time.sleep(10)\n",
        "        \n",
        "    # Ask the oracle for label for the context and two questions\n",
        "    try:\n",
        "        completion = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            temperature=0,\n",
        "            messages=[\n",
        "            {\"role\":\"system\", \"content\":\"You are a system designed to generate questions that can be answered using ANY part of a provided text, and which are specific to it.\"},\n",
        "            {\"role\": \"user\", \"content\": f'Please Generate 5 questions CONTEXT: ```{context}```'}\n",
        "            ]\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(\"OPENAI_ERROR:\",str(e))\n",
        "        continue\n",
        "\n",
        "    # Parse the response to get labels\n",
        "    res = completion.choices[0].message.content\n",
        "\n",
        "    # Split and remove index\n",
        "    split = res.splitlines()\n",
        "    questions = [re.sub(r'^\\d+\\.\\s', '', q) for q in split]\n",
        "    #print(questions)\n",
        "    \n",
        "    # If 5 questions are not found, assume something went wrong and skip this iteration\n",
        "    if len(questions) != 5:\n",
        "        print(f'[Error] questions not generated for {i}')\n",
        "        continue\n",
        "    \n",
        "    # Save data into a dataframe\n",
        "    combinations += [{'context': context, 'question': question} for question in questions]\n",
        "    print(f\"Questions from round {i+1} saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Questions from round 358 saved!\n"
          ]
        }
      ],
      "source": [
        "# Ask ChatGPT to make questions to failed sections in 02450\n",
        "#fails = [26, 56, 136, 153, 163, 199, 205, 320, 337, 358, 395, 424, 432, 463, 568, 599, 626, 650, 669]\n",
        "#fails = [358, 395]\n",
        "fails = [358]\n",
        "\n",
        "req_per_min = 0\n",
        "max_req_per_min = 2\n",
        "last_time_stamp = time.time()\n",
        "# For each pair of questions\n",
        "for f in fails:\n",
        "    context = text_segments[f]\n",
        "    \n",
        "    # Check rate limit\n",
        "    req_per_min += 1\n",
        "    while req_per_min>=max_req_per_min:\n",
        "        time_stamp = time.time()\n",
        "        if int(time.time()-last_time_stamp) > 59:\n",
        "            last_time_stamp = time_stamp\n",
        "            req_per_min = 0\n",
        "        else:\n",
        "            time.sleep(15)\n",
        "        \n",
        "    # Ask the oracle for label for the context and two questions\n",
        "    try:\n",
        "        completion = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            temperature=0,\n",
        "            messages=[\n",
        "            {\"role\":\"system\", \"content\":\"You are a system designed to generate questions that can be answered using ANY part of a provided text, and which are specific to it.\"},\n",
        "            {\"role\": \"user\", \"content\": f'Please Generate 5 questions CONTEXT: ```{context}```'}\n",
        "            ]\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(\"OPENAI_ERROR:\",str(e))\n",
        "        continue\n",
        "\n",
        "    # Parse the response to get labels\n",
        "    res = completion.choices[0].message.content\n",
        "\n",
        "    # Split and remove index\n",
        "    split = res.splitlines()\n",
        "    questions = [re.sub(r'^\\d+\\.\\s', '', q) for q in split]\n",
        "    #print(questions)\n",
        "    \n",
        "    # If 5 questions are not found, assume something went wrong and skip this iteration\n",
        "    if len(questions) != 5:\n",
        "        print(f'[Error] questions not generated for {f}')\n",
        "        print(questions)\n",
        "        continue\n",
        "    \n",
        "    # Save data into a dataframe\n",
        "    fail_combinations += [{'context': context, 'question': question} for question in questions]\n",
        "    print(f\"Questions from round {f} saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {},
      "outputs": [],
      "source": [
        "#df = pd.DataFrame(columns=['context', 'question'], data = combinations)\n",
        "\n",
        "with open('./data/final_2450.pkl', 'wb') as fp:\n",
        "    pickle.dump(df, fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_fail = pd.DataFrame(columns=['context', 'question'], data = fail_combinations)\n",
        "\n",
        "with open('./data/fails3_2450.pkl', 'wb') as fp:\n",
        "    pickle.dump(df_fail, fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('./data/fails3_2450.pkl', 'rb') as f:\n",
        "    df_fail = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' Root mean square error (rmse) for the train\\ufffeing and test set when using an artificial neural network with three hidden units to predict the Area of an island based only on the four attributes x1, x2, x5 and x6 using the hold-out method with 40 % of the observations hold-out for testing Attribute description Abbrev x1 Number of plant species Plants x2 Number of endemic plant species E-Plants x3 Area of island (in km2 ) Area x4 Max elevation above sea-level (in m) Elev x5 Distance to nearest island (in km) DistNI x6 Distance to Santa Cruz Island (in km) StCruz x7 Area of adjacent island (in km2 ) AreaNI Table 10.7 The seven attributes of the data on a selection of 29 of the Gal´apagos islands A Neither forward nor backward selection will identify the optimal feature combination for this problem B Forward selection will result in a better model being selected than using backward selection C Backward selection will terminate at the model that includes the features x1, x2, and x6'"
            ]
          },
          "execution_count": 157,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 26, 56, 136, 153, 163, 199, 205, 320, 337, 424, 432, 463, 568, 599, 626, 650, 669, 395, 358\n",
        "text_segments[359]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' D For least squares linear regression the test error will always decrease as we include more attributes in the model E Don’t know Question 4: We would like to fit an artificial neural network (ANN) model to the Galagapos dataset shown in Table 10.7 To reduce the computational cost of fitting the models it was decided to not include Elev, i.e x4, and AreaNI, i.e x7 in the ANN models We there\\ufffefore only consider x1, x2, x5 and x6 in order to predict Area, i.e x3 An artificial neural network with three hid\\ufffeden units is applied to the data with these four attributes and trained using different combinations of the four at\\ufffetributes x1, x2, x5 and x6 Table 10.6 gives the training and test performance in terms of root mean squared error (rmse) of the ANN for different combinations of the con\\ufffesidered attributes Which one of the following statements is correct'"
            ]
          },
          "execution_count": 152,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_fail.loc[90,'context']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' Root mean square error (rmse) for the train\\ufffeing and test set when using an artificial neural network with three hidden units to predict the Area of an island based only on the four attributes x1, x2, x5 and x6 using the hold-out method with 40 % of the observations hold-out for testing Attribute description Abbrev x1 Number of plant species Plants x2 Number of endemic plant species E-Plants x3 Area of island (in km2 ) Area x4 Max elevation above sea-level (in m) Elev x5 Distance to nearest island (in km) DistNI x6 Distance to Santa Cruz Island (in km) StCruz x7 Area of adjacent island (in km2 ) AreaNI Table 10.7 The seven attributes of the data on a selection of 29 of the Gal´apagos islands A Neither forward nor backward selection will identify the optimal feature combination for this problem B Forward selection will result in a better model being selected than using backward selection C Backward selection will terminate at the model that includes the features x1, x2, and x6'"
            ]
          },
          "execution_count": 156,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.loc[1745,'context']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>Tue Herlau, Mikkel N Schmidt and Morten Mørup...</td>\n",
              "      <td>What is the purpose of the Introduction to Mac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>Tue Herlau, Mikkel N Schmidt and Morten Mørup...</td>\n",
              "      <td>What is the size of the data matrix X?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.0</th>\n",
              "      <td>Tue Herlau, Mikkel N Schmidt and Morten Mørup...</td>\n",
              "      <td>What is the difference between the dependent v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3.0</th>\n",
              "      <td>Tue Herlau, Mikkel N Schmidt and Morten Mørup...</td>\n",
              "      <td>What is the range of values that the class ind...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4.0</th>\n",
              "      <td>Tue Herlau, Mikkel N Schmidt and Morten Mørup...</td>\n",
              "      <td>What is the purpose of the attributeNames cell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1744.1</th>\n",
              "      <td>D For least squares linear regression the tes...</td>\n",
              "      <td>What is the purpose of fitting an artificial n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1744.3</th>\n",
              "      <td>D For least squares linear regression the tes...</td>\n",
              "      <td>Which attributes were excluded from the ANN mo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1744.5</th>\n",
              "      <td>D For least squares linear regression the tes...</td>\n",
              "      <td>Which attributes were considered in the ANN mo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1744.7</th>\n",
              "      <td>D For least squares linear regression the tes...</td>\n",
              "      <td>How many hidden units were used in the ANN model?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1744.9</th>\n",
              "      <td>D For least squares linear regression the tes...</td>\n",
              "      <td>What is the performance metric used to evaluat...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3355 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  context  \\\n",
              "0.0      Tue Herlau, Mikkel N Schmidt and Morten Mørup...   \n",
              "1.0      Tue Herlau, Mikkel N Schmidt and Morten Mørup...   \n",
              "2.0      Tue Herlau, Mikkel N Schmidt and Morten Mørup...   \n",
              "3.0      Tue Herlau, Mikkel N Schmidt and Morten Mørup...   \n",
              "4.0      Tue Herlau, Mikkel N Schmidt and Morten Mørup...   \n",
              "...                                                   ...   \n",
              "1744.1   D For least squares linear regression the tes...   \n",
              "1744.3   D For least squares linear regression the tes...   \n",
              "1744.5   D For least squares linear regression the tes...   \n",
              "1744.7   D For least squares linear regression the tes...   \n",
              "1744.9   D For least squares linear regression the tes...   \n",
              "\n",
              "                                                 question  \n",
              "0.0     What is the purpose of the Introduction to Mac...  \n",
              "1.0                What is the size of the data matrix X?  \n",
              "2.0     What is the difference between the dependent v...  \n",
              "3.0     What is the range of values that the class ind...  \n",
              "4.0     What is the purpose of the attributeNames cell...  \n",
              "...                                                   ...  \n",
              "1744.1  What is the purpose of fitting an artificial n...  \n",
              "1744.3  Which attributes were excluded from the ANN mo...  \n",
              "1744.5  Which attributes were considered in the ANN mo...  \n",
              "1744.7  How many hidden units were used in the ANN model?  \n",
              "1744.9  What is the performance metric used to evaluat...  \n",
              "\n",
              "[3355 rows x 2 columns]"
            ]
          },
          "execution_count": 158,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for i in range(5):\n",
        "    n = round(1744.1+i*0.2,1)\n",
        "    c = i+90\n",
        "    df.loc[n] = df_fail.loc[c, 'context'], df_fail.loc[c, 'question']\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.sort_index().reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Tue Herlau, Mikkel N Schmidt and Morten Mørup...</td>\n",
              "      <td>What is the purpose of the Introduction to Mac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tue Herlau, Mikkel N Schmidt and Morten Mørup...</td>\n",
              "      <td>What is the size of the data matrix X?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tue Herlau, Mikkel N Schmidt and Morten Mørup...</td>\n",
              "      <td>What is the difference between the dependent v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tue Herlau, Mikkel N Schmidt and Morten Mørup...</td>\n",
              "      <td>What is the range of values that the class ind...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tue Herlau, Mikkel N Schmidt and Morten Mørup...</td>\n",
              "      <td>What is the purpose of the attributeNames cell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350</th>\n",
              "      <td>Rex Bryce, James A Hagans, Thomas C Chalmers,...</td>\n",
              "      <td>What is the title of the article published in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3351</th>\n",
              "      <td>Rex Bryce, James A Hagans, Thomas C Chalmers,...</td>\n",
              "      <td>In which year was the article \"On the theory o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3352</th>\n",
              "      <td>Rex Bryce, James A Hagans, Thomas C Chalmers,...</td>\n",
              "      <td>Who are the authors of the article \"Cluster en...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3353</th>\n",
              "      <td>Rex Bryce, James A Hagans, Thomas C Chalmers,...</td>\n",
              "      <td>What is the name of the book published by Addi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3354</th>\n",
              "      <td>Rex Bryce, James A Hagans, Thomas C Chalmers,...</td>\n",
              "      <td>Who wrote the article \"On the early history of...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3355 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                context  \\\n",
              "0      Tue Herlau, Mikkel N Schmidt and Morten Mørup...   \n",
              "1      Tue Herlau, Mikkel N Schmidt and Morten Mørup...   \n",
              "2      Tue Herlau, Mikkel N Schmidt and Morten Mørup...   \n",
              "3      Tue Herlau, Mikkel N Schmidt and Morten Mørup...   \n",
              "4      Tue Herlau, Mikkel N Schmidt and Morten Mørup...   \n",
              "...                                                 ...   \n",
              "3350   Rex Bryce, James A Hagans, Thomas C Chalmers,...   \n",
              "3351   Rex Bryce, James A Hagans, Thomas C Chalmers,...   \n",
              "3352   Rex Bryce, James A Hagans, Thomas C Chalmers,...   \n",
              "3353   Rex Bryce, James A Hagans, Thomas C Chalmers,...   \n",
              "3354   Rex Bryce, James A Hagans, Thomas C Chalmers,...   \n",
              "\n",
              "                                               question  \n",
              "0     What is the purpose of the Introduction to Mac...  \n",
              "1                What is the size of the data matrix X?  \n",
              "2     What is the difference between the dependent v...  \n",
              "3     What is the range of values that the class ind...  \n",
              "4     What is the purpose of the attributeNames cell...  \n",
              "...                                                 ...  \n",
              "3350  What is the title of the article published in ...  \n",
              "3351  In which year was the article \"On the theory o...  \n",
              "3352  Who are the authors of the article \"Cluster en...  \n",
              "3353  What is the name of the book published by Addi...  \n",
              "3354  Who wrote the article \"On the early history of...  \n",
              "\n",
              "[3355 rows x 2 columns]"
            ]
          },
          "execution_count": 160,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Genarate answers for A/B context length test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pickle\n",
        "import openai\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "openai.api_key = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('../../web/chatta/ab_test/context_length/df_data_original.pkl','rb') as f:\n",
        "    df_ab = pickle.loads(f.read())\n",
        "\n",
        "df_ab['answer_short'] = np.nan\n",
        "df_ab['answer_medium'] = np.nan\n",
        "df_ab['answer_long'] = np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Questions from round 0 saved! Index: 1663\n",
            "Questions from round 1 saved! Index: 1744\n",
            "Questions from round 2 saved! Index: 2174\n",
            "Questions from round 3 saved! Index: 1101\n",
            "Questions from round 4 saved! Index: 2126\n",
            "Questions from round 5 saved! Index: 68\n",
            "Questions from round 6 saved! Index: 537\n",
            "Questions from round 7 saved! Index: 3078\n",
            "Questions from round 8 saved! Index: 1194\n",
            "Questions from round 9 saved! Index: 2334\n",
            "Questions from round 10 saved! Index: 1480\n",
            "Questions from round 11 saved! Index: 2892\n",
            "Questions from round 12 saved! Index: 2036\n",
            "Questions from round 13 saved! Index: 2110\n",
            "Questions from round 14 saved! Index: 2796\n",
            "Questions from round 15 saved! Index: 3008\n",
            "Questions from round 16 saved! Index: 2151\n",
            "Questions from round 17 saved! Index: 2920\n",
            "Questions from round 18 saved! Index: 1470\n",
            "Questions from round 19 saved! Index: 1096\n",
            "Questions from round 20 saved! Index: 2145\n",
            "Questions from round 21 saved! Index: 553\n",
            "Questions from round 22 saved! Index: 2923\n",
            "Questions from round 23 saved! Index: 2362\n",
            "Questions from round 24 saved! Index: 1293\n",
            "Questions from round 25 saved! Index: 2922\n",
            "Questions from round 26 saved! Index: 758\n",
            "Questions from round 27 saved! Index: 140\n",
            "Questions from round 28 saved! Index: 1611\n",
            "OPENAI_ERROR: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 75e17e16431de8573aee203b70cdcfa7 in your message.)\n",
            "Questions from round 29 saved! Index: 833\n",
            "Questions from round 30 saved! Index: 43\n",
            "Questions from round 31 saved! Index: 2578\n",
            "Questions from round 32 saved! Index: 2368\n",
            "Questions from round 33 saved! Index: 1679\n",
            "OPENAI_ERROR: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 25b0115ff1ae99b2fc0a08c3f756be9a in your message.)\n",
            "Questions from round 34 saved! Index: 2739\n",
            "Questions from round 35 saved! Index: 2251\n",
            "Questions from round 36 saved! Index: 584\n",
            "Questions from round 37 saved! Index: 2171\n",
            "Questions from round 38 saved! Index: 1158\n",
            "Questions from round 39 saved! Index: 2252\n",
            "Questions from round 40 saved! Index: 2556\n",
            "Questions from round 41 saved! Index: 2972\n",
            "Questions from round 42 saved! Index: 2761\n",
            "Questions from round 43 saved! Index: 2241\n",
            "Questions from round 44 saved! Index: 504\n",
            "Questions from round 45 saved! Index: 2478\n",
            "Questions from round 46 saved! Index: 624\n",
            "Questions from round 47 saved! Index: 2046\n",
            "Questions from round 48 saved! Index: 661\n",
            "Questions from round 49 saved! Index: 2235\n",
            "Questions from round 50 saved! Index: 318\n",
            "Questions from round 51 saved! Index: 1160\n",
            "Questions from round 52 saved! Index: 754\n",
            "Questions from round 53 saved! Index: 1270\n",
            "Questions from round 54 saved! Index: 1942\n",
            "Questions from round 55 saved! Index: 2506\n",
            "Questions from round 56 saved! Index: 489\n",
            "Questions from round 57 saved! Index: 3294\n",
            "Questions from round 58 saved! Index: 1899\n",
            "Questions from round 59 saved! Index: 3226\n",
            "OPENAI_ERROR: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0f4718a84acd53df9bfa61d231b0d37e in your message.)\n",
            "Questions from round 60 saved! Index: 2983\n",
            "Questions from round 61 saved! Index: 1697\n",
            "Questions from round 62 saved! Index: 1009\n",
            "Questions from round 63 saved! Index: 3220\n",
            "Questions from round 64 saved! Index: 1485\n",
            "Questions from round 65 saved! Index: 655\n",
            "Questions from round 66 saved! Index: 3289\n",
            "Questions from round 67 saved! Index: 907\n",
            "Questions from round 68 saved! Index: 2164\n",
            "Questions from round 69 saved! Index: 2091\n",
            "OPENAI_ERROR: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3290432bd9c13a867c2d7706e3ecdb35 in your message.)\n",
            "Questions from round 70 saved! Index: 100\n",
            "Questions from round 71 saved! Index: 2341\n",
            "Questions from round 72 saved! Index: 1815\n",
            "Questions from round 73 saved! Index: 2084\n",
            "Questions from round 74 saved! Index: 2201\n",
            "OPENAI_ERROR: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 86e9d13fdc001a31b39cc000149c600f in your message.)\n",
            "Questions from round 75 saved! Index: 2264\n",
            "Questions from round 76 saved! Index: 1547\n",
            "Questions from round 77 saved! Index: 2507\n",
            "Questions from round 78 saved! Index: 1803\n",
            "Questions from round 79 saved! Index: 1018\n",
            "Questions from round 80 saved! Index: 1475\n",
            "Questions from round 81 saved! Index: 2528\n",
            "Questions from round 82 saved! Index: 1946\n",
            "Questions from round 83 saved! Index: 3081\n",
            "Questions from round 84 saved! Index: 2391\n",
            "Questions from round 85 saved! Index: 330\n",
            "Questions from round 86 saved! Index: 990\n",
            "Questions from round 87 saved! Index: 2748\n",
            "Questions from round 88 saved! Index: 2998\n",
            "Questions from round 89 saved! Index: 2289\n",
            "Questions from round 90 saved! Index: 412\n",
            "Questions from round 91 saved! Index: 666\n",
            "Questions from round 92 saved! Index: 227\n"
          ]
        }
      ],
      "source": [
        "# Ask ChatGPT to make answers to 3 lengths of contexs\n",
        "\n",
        "req_per_min = 0\n",
        "max_req_per_min = 3\n",
        "last_time_stamp = time.time()\n",
        "# For each pair of questions\n",
        "i = 0\n",
        "for idx,row in df_ab[df_ab['answer_short'].isna()].sample(n=98).iterrows():\n",
        "    question = row['question']\n",
        "    context_short = row['short']\n",
        "    context_medium = row['medium']\n",
        "    context_long = row['long']\n",
        "    \n",
        "    # Check rate limit\n",
        "    req_per_min += 3\n",
        "    while req_per_min>=max_req_per_min:\n",
        "        time_stamp = time.time()\n",
        "        if int(time.time()-last_time_stamp) > 60:\n",
        "            last_time_stamp = time_stamp\n",
        "            req_per_min = 0\n",
        "        else:\n",
        "            time.sleep(5)\n",
        "        \n",
        "    # Ask the oracle for label for the context and two questions\n",
        "    try:\n",
        "        completion = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            temperature=0,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": f'Act as a teacher. A student asks the following question: {question}. Use the following context to answer the question: {context_short}'}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        answer_short = completion.choices[0].message.content\n",
        "\n",
        "        df_ab.loc[idx,'answer_short'] = answer_short\n",
        "\n",
        "        completion = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            temperature=0,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": f'Act as a teacher. A student asks the following question: {question}. Use the following context to answer the question: {context_medium}'}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        answer_medium = completion.choices[0].message.content\n",
        "\n",
        "        df_ab.loc[idx,'answer_medium'] = answer_medium\n",
        "\n",
        "        completion = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            temperature=0,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": f'Act as a teacher. A student asks the following question: {question}. Use the following context to answer the question: {context_long}'}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        answer_long = completion.choices[0].message.content\n",
        "\n",
        "        df_ab.loc[idx,'answer_long'] = answer_long\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"OPENAI_ERROR:\",str(e))\n",
        "        continue\n",
        "    print(f\"Questions from round {i} saved! Index: {idx}\")\n",
        "    i+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "single positional indexer is out-of-bounds",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Lauritz\\Documents\\DTU\\4-semester\\fagprojekt\\Learning-with-ChatGPT\\dev\\Neural Search\\q_w_chat.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Lauritz/Documents/DTU/4-semester/fagprojekt/Learning-with-ChatGPT/dev/Neural%20Search/q_w_chat.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m q \u001b[39m=\u001b[39m df_ab[(\u001b[39m~\u001b[39;49mdf_ab[\u001b[39m'\u001b[39;49m\u001b[39manswer_short\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49misna()) \u001b[39m&\u001b[39;49m (df_ab[\u001b[39m'\u001b[39;49m\u001b[39manswer_long\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49misna())]\u001b[39m.\u001b[39;49miloc[\u001b[39m0\u001b[39;49m][\u001b[39m'\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lauritz/Documents/DTU/4-semester/fagprojekt/Learning-with-ChatGPT/dev/Neural%20Search/q_w_chat.ipynb#X44sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m ctx \u001b[39m=\u001b[39m df_ab[(\u001b[39m~\u001b[39mdf_ab[\u001b[39m'\u001b[39m\u001b[39manswer_short\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misna()) \u001b[39m&\u001b[39m (df_ab[\u001b[39m'\u001b[39m\u001b[39manswer_long\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misna())]\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mlong\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lauritz/Documents/DTU/4-semester/fagprojekt/Learning-with-ChatGPT/dev/Neural%20Search/q_w_chat.ipynb#X44sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df_ab[(\u001b[39m~\u001b[39mdf_ab[\u001b[39m'\u001b[39m\u001b[39manswer_short\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misna()) \u001b[39m&\u001b[39m (df_ab[\u001b[39m'\u001b[39m\u001b[39manswer_long\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misna())]\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\Lauritz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1073\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1070\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m   1072\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[1;32m-> 1073\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
            "File \u001b[1;32mc:\\Users\\Lauritz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1625\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1622\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index by location index with a non-integer key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1624\u001b[0m \u001b[39m# validate the location\u001b[39;00m\n\u001b[1;32m-> 1625\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_integer(key, axis)\n\u001b[0;32m   1627\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_ixs(key, axis\u001b[39m=\u001b[39maxis)\n",
            "File \u001b[1;32mc:\\Users\\Lauritz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1557\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1555\u001b[0m len_axis \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis))\n\u001b[0;32m   1556\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m len_axis \u001b[39mor\u001b[39;00m key \u001b[39m<\u001b[39m \u001b[39m-\u001b[39mlen_axis:\n\u001b[1;32m-> 1557\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msingle positional indexer is out-of-bounds\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
          ]
        }
      ],
      "source": [
        "q = df_ab[(~df_ab['answer_short'].isna()) & (df_ab['answer_long'].isna())].iloc[0]['question']\n",
        "ctx = df_ab[(~df_ab['answer_short'].isna()) & (df_ab['answer_long'].isna())].iloc[0]['long']\n",
        "df_ab[(~df_ab['answer_short'].isna()) & (df_ab['answer_long'].isna())].iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "completion = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            temperature=0,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": f'Act as a teacher. A student asks the following question: {q}. Use the following context to answer the question: {ctx}'}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "ans = completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_ab.loc[(~df_ab['answer_short'].isna()) & (df_ab['long'] == ctx), 'answer_long'] = ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('../../web/chatta/ab_test/context_length/df_ab_original.pkl','wb') as f:\n",
        "    f.write(pickle.dumps(df_ab[~df_ab['answer_short'].isna()]))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generate new questions for 2450 and ww2 A/B test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import openai\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "openai.api_key = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('./data/ww2_long_contexts.pkl','rb') as f:\n",
        "    contexts = pickle.loads(f.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_history_results_u = df_history_results.loc[df_history_results['question'].drop_duplicates().index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "41    answer_context\n",
              "49    answer_context\n",
              "Name: choice, dtype: object"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q = df_2450_results.loc[df_2450_results['question'].duplicated(keep=False),'question'].unique()[4]\n",
        "df_2450_results.loc[df_2450_results['question']==q,'choice']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.random.randint(0,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(43, 9)"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_history_results_u.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_2450_results_u.loc[df_2450_results_u['question']==q,'choice'] = 'answer_context'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_history_results_updated = pd.concat((df_history_results_u,df_history_extra))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50,)"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_history_results_updated['question'].unique().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>correct_context</th>\n",
              "      <th>answer</th>\n",
              "      <th>answer_correct_context</th>\n",
              "      <th>fetched</th>\n",
              "      <th>fetched_time</th>\n",
              "      <th>choice</th>\n",
              "      <th>answer_context</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>What is the main focus of the third chapter of...</td>\n",
              "      <td>The third chapter of the pamphlet examines t...</td>\n",
              "      <td>The main focus of the third chapter of the pam...</td>\n",
              "      <td>The main focus of the third chapter of the pam...</td>\n",
              "      <td>True</td>\n",
              "      <td>1686747591</td>\n",
              "      <td>answer</td>\n",
              "      <td>The main focus of the third chapter of the pam...</td>\n",
              "      <td>As we have already seen in the previous sect...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>What evidence suggests that Hitler was already...</td>\n",
              "      <td>At the same time, Overy has argued that, by t...</td>\n",
              "      <td>There is no concrete evidence that suggests Hi...</td>\n",
              "      <td>There is evidence to suggest that Hitler was a...</td>\n",
              "      <td>True</td>\n",
              "      <td>1686743885</td>\n",
              "      <td>answer_context</td>\n",
              "      <td>There is no direct evidence in the given conte...</td>\n",
              "      <td>In the course of 1940, as the German armies  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>What were some of the factors that led to risi...</td>\n",
              "      <td>The more the League of Nations tried to put p...</td>\n",
              "      <td>Sure, I can help you with that question. The r...</td>\n",
              "      <td>The rising nationalist protests in Japan and t...</td>\n",
              "      <td>True</td>\n",
              "      <td>1686773241</td>\n",
              "      <td>answer_context</td>\n",
              "      <td>The rising nationalist protests in Japan and t...</td>\n",
              "      <td>The more the League of Nations tried to put p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>What were the reasons behind the United States...</td>\n",
              "      <td>Some historians, such as Arnold Offner, in h...</td>\n",
              "      <td>The United States' policy of appeasement towar...</td>\n",
              "      <td>The reasons behind the United States' policy o...</td>\n",
              "      <td>True</td>\n",
              "      <td>1686747523</td>\n",
              "      <td>answer</td>\n",
              "      <td>The United States' policy of appeasement towar...</td>\n",
              "      <td>The onward march of fascism was underlined b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>What was Hitler's plan for expanding German te...</td>\n",
              "      <td>A racially strong and  expanding German popul...</td>\n",
              "      <td>:\\n\\nHitler's plan for expanding German territ...</td>\n",
              "      <td>Hitler's plan for expanding German territory w...</td>\n",
              "      <td>True</td>\n",
              "      <td>1686772009</td>\n",
              "      <td>answer</td>\n",
              "      <td>Hitler's plan for expanding German territory w...</td>\n",
              "      <td>The onward march of fascism was underlined b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>What was Hitler's ultimate goal in terms of fo...</td>\n",
              "      <td>However, there still  remained some areas of ...</td>\n",
              "      <td>Hitler's ultimate goal in terms of foreign pol...</td>\n",
              "      <td>Hitler's ultimate goal in terms of foreign pol...</td>\n",
              "      <td>True</td>\n",
              "      <td>1686747507</td>\n",
              "      <td>answer</td>\n",
              "      <td>According to historians, Hitler's ultimate goa...</td>\n",
              "      <td>But it is less clear that a pact with Russia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>What was the main argument presented by A.J.P....</td>\n",
              "      <td>Detailed studies began  to show that Hitler’s...</td>\n",
              "      <td>A.J.P. Taylor's main argument in his book Orig...</td>\n",
              "      <td>A.J.P. Taylor's main argument in his book Orig...</td>\n",
              "      <td>True</td>\n",
              "      <td>1686745816</td>\n",
              "      <td>answer</td>\n",
              "      <td>I appreciate your question about A.J.P. Taylor...</td>\n",
              "      <td>As we have already seen in the previous sect...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>What is the main focus of the third chapter of...</td>\n",
              "      <td>The third chapter of the pamphlet examines t...</td>\n",
              "      <td>The main focus of the third chapter of the pam...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The main focus of the third chapter of the pam...</td>\n",
              "      <td>Much of it has focused on the diplomatic even...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>What was Hitler's plan for expanding German te...</td>\n",
              "      <td>A racially strong and  expanding German popul...</td>\n",
              "      <td>:\\n\\nHitler's plan for expanding German territ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Hitler's plan for expanding German territory w...</td>\n",
              "      <td>As we shall see,  social tensions, economic w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>What were the reasons behind the United States...</td>\n",
              "      <td>Some historians, such as Arnold Offner, in h...</td>\n",
              "      <td>The United States' policy of appeasement towar...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The United States' policy of appeasement towar...</td>\n",
              "      <td>The third chapter of the pamphlet examines t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>What was Hitler's ultimate goal in terms of fo...</td>\n",
              "      <td>However, there still  remained some areas of ...</td>\n",
              "      <td>Hitler's ultimate goal in terms of foreign pol...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Hitler's ultimate goal in terms of foreign pol...</td>\n",
              "      <td>For, as Taylor pointed out, the  peace settle...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>What evidence suggests that Hitler was already...</td>\n",
              "      <td>At the same time, Overy has argued that, by t...</td>\n",
              "      <td>There is no concrete evidence that suggests Hi...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>There is no direct evidence that suggests Hitl...</td>\n",
              "      <td>Baldwin and Chamberlain were repeatedly warne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>What were some of the factors that led to risi...</td>\n",
              "      <td>The more the League of Nations tried to put p...</td>\n",
              "      <td>Sure, I can help you with that question. The r...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The rising nationalist protests in Japan and t...</td>\n",
              "      <td>For, as Taylor pointed out, the  peace settle...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>What was the main argument presented by A.J.P....</td>\n",
              "      <td>Detailed studies began  to show that Hitler’s...</td>\n",
              "      <td>A.J.P. Taylor's main argument in his book Orig...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A.J.P. Taylor's main argument in his book Orig...</td>\n",
              "      <td>As we shall see,  social tensions, economic w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question  \\\n",
              "11  What is the main focus of the third chapter of...   \n",
              "13  What evidence suggests that Hitler was already...   \n",
              "20  What were some of the factors that led to risi...   \n",
              "28  What were the reasons behind the United States...   \n",
              "29  What was Hitler's plan for expanding German te...   \n",
              "30  What was Hitler's ultimate goal in terms of fo...   \n",
              "33  What was the main argument presented by A.J.P....   \n",
              "36  What is the main focus of the third chapter of...   \n",
              "37  What was Hitler's plan for expanding German te...   \n",
              "38  What were the reasons behind the United States...   \n",
              "41  What was Hitler's ultimate goal in terms of fo...   \n",
              "42  What evidence suggests that Hitler was already...   \n",
              "45  What were some of the factors that led to risi...   \n",
              "46  What was the main argument presented by A.J.P....   \n",
              "\n",
              "                                      correct_context  \\\n",
              "11    The third chapter of the pamphlet examines t...   \n",
              "13   At the same time, Overy has argued that, by t...   \n",
              "20   The more the League of Nations tried to put p...   \n",
              "28    Some historians, such as Arnold Offner, in h...   \n",
              "29   A racially strong and  expanding German popul...   \n",
              "30   However, there still  remained some areas of ...   \n",
              "33   Detailed studies began  to show that Hitler’s...   \n",
              "36    The third chapter of the pamphlet examines t...   \n",
              "37   A racially strong and  expanding German popul...   \n",
              "38    Some historians, such as Arnold Offner, in h...   \n",
              "41   However, there still  remained some areas of ...   \n",
              "42   At the same time, Overy has argued that, by t...   \n",
              "45   The more the League of Nations tried to put p...   \n",
              "46   Detailed studies began  to show that Hitler’s...   \n",
              "\n",
              "                                               answer  \\\n",
              "11  The main focus of the third chapter of the pam...   \n",
              "13  There is no concrete evidence that suggests Hi...   \n",
              "20  Sure, I can help you with that question. The r...   \n",
              "28  The United States' policy of appeasement towar...   \n",
              "29  :\\n\\nHitler's plan for expanding German territ...   \n",
              "30  Hitler's ultimate goal in terms of foreign pol...   \n",
              "33  A.J.P. Taylor's main argument in his book Orig...   \n",
              "36  The main focus of the third chapter of the pam...   \n",
              "37  :\\n\\nHitler's plan for expanding German territ...   \n",
              "38  The United States' policy of appeasement towar...   \n",
              "41  Hitler's ultimate goal in terms of foreign pol...   \n",
              "42  There is no concrete evidence that suggests Hi...   \n",
              "45  Sure, I can help you with that question. The r...   \n",
              "46  A.J.P. Taylor's main argument in his book Orig...   \n",
              "\n",
              "                               answer_correct_context  fetched  fetched_time  \\\n",
              "11  The main focus of the third chapter of the pam...     True    1686747591   \n",
              "13  There is evidence to suggest that Hitler was a...     True    1686743885   \n",
              "20  The rising nationalist protests in Japan and t...     True    1686773241   \n",
              "28  The reasons behind the United States' policy o...     True    1686747523   \n",
              "29  Hitler's plan for expanding German territory w...     True    1686772009   \n",
              "30  Hitler's ultimate goal in terms of foreign pol...     True    1686747507   \n",
              "33  A.J.P. Taylor's main argument in his book Orig...     True    1686745816   \n",
              "36                                                NaN    False             0   \n",
              "37                                                NaN    False             0   \n",
              "38                                                NaN    False             0   \n",
              "41                                                NaN    False             0   \n",
              "42                                                NaN    False             0   \n",
              "45                                                NaN    False             0   \n",
              "46                                                NaN    False             0   \n",
              "\n",
              "            choice                                     answer_context  \\\n",
              "11          answer  The main focus of the third chapter of the pam...   \n",
              "13  answer_context  There is no direct evidence in the given conte...   \n",
              "20  answer_context  The rising nationalist protests in Japan and t...   \n",
              "28          answer  The United States' policy of appeasement towar...   \n",
              "29          answer  Hitler's plan for expanding German territory w...   \n",
              "30          answer  According to historians, Hitler's ultimate goa...   \n",
              "33          answer  I appreciate your question about A.J.P. Taylor...   \n",
              "36             NaN  The main focus of the third chapter of the pam...   \n",
              "37             NaN  Hitler's plan for expanding German territory w...   \n",
              "38             NaN  The United States' policy of appeasement towar...   \n",
              "41             NaN  Hitler's ultimate goal in terms of foreign pol...   \n",
              "42             NaN  There is no direct evidence that suggests Hitl...   \n",
              "45             NaN  The rising nationalist protests in Japan and t...   \n",
              "46             NaN  A.J.P. Taylor's main argument in his book Orig...   \n",
              "\n",
              "                                              context  \n",
              "11    As we have already seen in the previous sect...  \n",
              "13   In the course of 1940, as the German armies  ...  \n",
              "20   The more the League of Nations tried to put p...  \n",
              "28    The onward march of fascism was underlined b...  \n",
              "29    The onward march of fascism was underlined b...  \n",
              "30    But it is less clear that a pact with Russia...  \n",
              "33    As we have already seen in the previous sect...  \n",
              "36   Much of it has focused on the diplomatic even...  \n",
              "37   As we shall see,  social tensions, economic w...  \n",
              "38    The third chapter of the pamphlet examines t...  \n",
              "41   For, as Taylor pointed out, the  peace settle...  \n",
              "42   Baldwin and Chamberlain were repeatedly warne...  \n",
              "45   For, as Taylor pointed out, the  peace settle...  \n",
              "46   As we shall see,  social tensions, economic w...  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_history_results.loc[df_history_results['question'].duplicated(keep=False),:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(43,)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_history_results['question'].unique().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "context_sample = [c for c in contexts if c not in df_history_results['context'].unique()]\n",
        "context_sample = np.random.choice(contexts,4,replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Questions from round 0 saved!\n",
            "Questions from round 1 saved!\n",
            "Questions from round 2 saved!\n",
            "Questions from round 3 saved!\n"
          ]
        }
      ],
      "source": [
        "# Ask ChatGPT to make questions to sections\n",
        "data = []\n",
        "\n",
        "req_per_min = 0\n",
        "max_req_per_min = 3\n",
        "last_time_stamp = time.time()\n",
        "# For each pair of questions\n",
        "for i in range(len(context_sample)):\n",
        "    context = context_sample[i]\n",
        "    \n",
        "    # Check rate limit\n",
        "    req_per_min += 1\n",
        "    while req_per_min>=max_req_per_min:\n",
        "        time_stamp = time.time()\n",
        "        if int(time.time()-last_time_stamp) > 60:\n",
        "            last_time_stamp = time_stamp\n",
        "            req_per_min = 0\n",
        "        else:\n",
        "            time.sleep(10)\n",
        "        \n",
        "    # Ask the oracle for label for the context and two questions\n",
        "    try:\n",
        "        completion = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            temperature=0,\n",
        "            messages=[\n",
        "            {\"role\":\"system\", \"content\":\"You are a system designed to generate a question that can be answered well using a provided context. It should also be possible to answer the question without knowing the context.\"},\n",
        "            {\"role\": \"user\", \"content\": f'CONTEXT: ```{context}```'}\n",
        "            ]\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(\"OPENAI_ERROR:\",str(e))\n",
        "        continue\n",
        "\n",
        "    # Parse the response to get labels\n",
        "    res = completion.choices[0].message.content\n",
        "    \n",
        "    # Save data into a dataframe\n",
        "    data += [{'correct_context': context, 'question': res}]\n",
        "    print(f\"Questions from round {i} saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>correct_context</th>\n",
              "      <th>answer</th>\n",
              "      <th>answer_correct_context</th>\n",
              "      <th>fetched</th>\n",
              "      <th>fetched_time</th>\n",
              "      <th>choice</th>\n",
              "      <th>answer_context</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What were the key themes in Hitler's thinking ...</td>\n",
              "      <td>(For further discussion of this topic  see th...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the focus of the book \"The Origins of ...</td>\n",
              "      <td>The Origins of the Second World War  1933–194...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What were the fundamental beliefs of the Nazi ...</td>\n",
              "      <td>Other races, notably eastern ones, could carr...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What was the Sudeten German leader's tactic in...</td>\n",
              "      <td>Schuschnigg took the hint, and on his return...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What were the alternative policies towards Ger...</td>\n",
              "      <td>He  further points out that, by early 1939, t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  What were the key themes in Hitler's thinking ...   \n",
              "1  What is the focus of the book \"The Origins of ...   \n",
              "2  What were the fundamental beliefs of the Nazi ...   \n",
              "3  What was the Sudeten German leader's tactic in...   \n",
              "6  What were the alternative policies towards Ger...   \n",
              "\n",
              "                                     correct_context  answer  \\\n",
              "0   (For further discussion of this topic  see th...     NaN   \n",
              "1   The Origins of the Second World War  1933–194...     NaN   \n",
              "2   Other races, notably eastern ones, could carr...     NaN   \n",
              "3    Schuschnigg took the hint, and on his return...     NaN   \n",
              "6   He  further points out that, by early 1939, t...     NaN   \n",
              "\n",
              "   answer_correct_context  fetched  fetched_time  choice  answer_context  \\\n",
              "0                     NaN    False             0     NaN             NaN   \n",
              "1                     NaN    False             0     NaN             NaN   \n",
              "2                     NaN    False             0     NaN             NaN   \n",
              "3                     NaN    False             0     NaN             NaN   \n",
              "6                     NaN    False             0     NaN             NaN   \n",
              "\n",
              "   context  \n",
              "0      NaN  \n",
              "1      NaN  \n",
              "2      NaN  \n",
              "3      NaN  \n",
              "6      NaN  "
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_history_extra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>correct_context</th>\n",
              "      <th>answer</th>\n",
              "      <th>answer_correct_context</th>\n",
              "      <th>fetched</th>\n",
              "      <th>fetched_time</th>\n",
              "      <th>choice</th>\n",
              "      <th>answer_context</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What were the consequences of the Maginot line...</td>\n",
              "      <td>Further-more, Britain had only skeletal home...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What was the anti-comintern pact and how did i...</td>\n",
              "      <td>The onward march of fascism was underlined b...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  What were the consequences of the Maginot line...   \n",
              "1  What was the anti-comintern pact and how did i...   \n",
              "\n",
              "                                     correct_context  answer  \\\n",
              "0    Further-more, Britain had only skeletal home...     NaN   \n",
              "1    The onward march of fascism was underlined b...     NaN   \n",
              "\n",
              "   answer_correct_context  fetched  fetched_time  choice  answer_context  \\\n",
              "0                     NaN    False             0     NaN             NaN   \n",
              "1                     NaN    False             0     NaN             NaN   \n",
              "\n",
              "   context  \n",
              "0      NaN  \n",
              "1      NaN  "
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_history_extra = df_history_extra[~df_history_extra['question'].isin(df_history_results['question'].values)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_history_extra = pd.concat((df_history_extra,df_history_extra_e[~df_history_extra_e['question'].isin(df_history_results['question'].values)].iloc[0:2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_history_extra = pd.DataFrame(columns=df_history_results.columns, data=data)\n",
        "df_history_extra['fetched'] = False\n",
        "df_history_extra['fetched_time'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame(columns=['question','context'],data=data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('./data/history_long_contexts_questions.pkl','wb') as f:\n",
        "    f.write(pickle.dumps(df))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generate answers for A/B test w and w/o context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('./data/2450_long_contexts_questions.pkl','rb') as f:\n",
        "    df_ab = pickle.loads(f.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_ab['answer'] = np.nan\n",
        "df_ab['answer_context'] = np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Questions from round 0 saved! Index: 43\n",
            "Questions from round 1 saved! Index: 44\n",
            "Questions from round 2 saved! Index: 45\n",
            "Questions from round 3 saved! Index: 46\n",
            "Questions from round 4 saved! Index: 47\n",
            "Questions from round 5 saved! Index: 48\n",
            "Questions from round 6 saved! Index: 49\n"
          ]
        }
      ],
      "source": [
        "# Ask ChatGPT to make answers to 3 lengths of contexs\n",
        "\n",
        "\n",
        "req_per_min = 0\n",
        "max_req_per_min = 3\n",
        "last_time_stamp = time.time()\n",
        "# For each pair of questions\n",
        "i = 0\n",
        "for idx,row in df_ab.iloc[43:].iterrows():\n",
        "    question = row['question']\n",
        "    context = row['context']\n",
        "    \n",
        "    # Check rate limit\n",
        "    req_per_min += 1\n",
        "    while req_per_min>=max_req_per_min:\n",
        "        time_stamp = time.time()\n",
        "        if int(time.time()-last_time_stamp) > 60:\n",
        "            last_time_stamp = time_stamp\n",
        "            req_per_min = 0\n",
        "        else:\n",
        "            time.sleep(5)\n",
        "        \n",
        "    # Ask the oracle for label for the context and two questions\n",
        "    try:\n",
        "        completion = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            temperature=0,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": f'Act as a teacher. A student asks the following question: ```{question}```. Answer the question with help from the following context: ```{context}```'}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        answer = completion.choices[0].message.content\n",
        "\n",
        "        df_ab.loc[idx,'answer_context'] = answer\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"OPENAI_ERROR:\",str(e))\n",
        "        continue\n",
        "\n",
        "    # Check rate limit\n",
        "    req_per_min += 1\n",
        "    while req_per_min>=max_req_per_min:\n",
        "        time_stamp = time.time()\n",
        "        if int(time.time()-last_time_stamp) > 60:\n",
        "            last_time_stamp = time_stamp\n",
        "            req_per_min = 0\n",
        "        else:\n",
        "            time.sleep(5)\n",
        "        \n",
        "    # Ask the oracle for label for the context and two questions\n",
        "    try:\n",
        "        completion = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            temperature=0,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": f'Act as a teacher. A student asks the following question: ```{question}```. Answer the question'}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        answer = completion.choices[0].message.content\n",
        "\n",
        "        df_ab.loc[idx,'answer'] = answer\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"OPENAI_ERROR:\",str(e))\n",
        "        continue\n",
        "\n",
        "    \n",
        "\n",
        "    print(f\"Questions from round {i} saved! Index: {idx}\")\n",
        "    i+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_ab['fetched'] = False\n",
        "df_ab['fetched_time'] = 0\n",
        "df_ab['choice'] = np.nan\n",
        "with open('../../web/chatta/ab_test/context_history/saves/df_ab_original.pkl','wb') as f:\n",
        "    f.write(pickle.dumps(df_ab))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Find contexts with NN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import tensorflow as tf\n",
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import random\n",
        "\n",
        "# set randomn seed for reproducibility\n",
        "seed = 23\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras import metrics\n",
        "from keras.models import load_model\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "emb_model = SentenceTransformer('sentence-transformers/multi-qa-mpnet-base-dot-v1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3281"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(contexts[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = emb_model.encode(contexts[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b = emb_model.encode(contexts[10][0:-500])\n",
        "all(a == b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "471"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(contexts[10][0:-500].split(\" \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'ed his political elevation entirely to the  effects of the depression in Germany, though the evidence does appear to support this  interpretation Clearly the Nazis, under Hitler’s leadership, were sufficiently organized to  have exploited any internal crisis, though whether this would have resulted in such  widespread electoral support, or perhaps have involved a more forceful seizure of power,  we cannot know Would the Weimar system of coalition governments have survived  without the depression'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contexts[10][-500:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define NN\n",
        "neural_net = Sequential()\n",
        "neural_net.add(Dense(768, input_dim=768*2, activation='relu'))\n",
        "neural_net.add(Dense(384, activation='relu'))\n",
        "neural_net.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "neural_net.compile(loss='binary_crossentropy', optimizer='adam', metrics=[metrics.TruePositives(name='tp'),\n",
        "                metrics.FalsePositives(name='fp'),\n",
        "                metrics.TrueNegatives(name='tn'),\n",
        "                metrics.FalseNegatives(name='fn'),\n",
        "                metrics.BinaryAccuracy(name='accuracy'),\n",
        "                metrics.Precision(name='precision'),\n",
        "                metrics.Recall(name='recall'),\n",
        "                metrics.AUC(name='auc'),\n",
        "                metrics.AUC(name='prc', curve='PR')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x156f5b134c0>"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "neural_net.load_weights('./Results/NN/basic_all_ctx/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "# with open('../../web/chatta/ab_test/context_history/saves/df_ab_original_old.pkl','rb') as f:\n",
        "#     df_ab = pickle.loads(f.read())\n",
        "with open('./data/ww2_long_contexts.pkl','rb') as f:\n",
        "    contexts = pickle.loads(f.read())\n",
        "with open(f'./Embeddings/ww2_context_embeddings_4000.pkl', 'rb') as f:\n",
        "    context_embeddings = pickle.loads(f.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('../../web/chatta/ab_test/context_2450/saves/df_ab_original_old.pkl','rb') as f:\n",
        "    df_ab = pickle.loads(f.read())\n",
        "with open('./data/2450_long_contexts.pkl','rb') as f:\n",
        "    contexts = pickle.loads(f.read())\n",
        "with open(f'./Embeddings/2450_context_embeddings_4000.pkl', 'rb') as f:\n",
        "    context_embeddings = pickle.loads(f.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_ab = df_history_results_updated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "questions = df_ab['question'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "question_embeddings = {q:emb_model.encode(q) for q in questions}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "q_to_found_ctx = {}\n",
        "for q in questions:\n",
        "    q_emb = question_embeddings[q]\n",
        "    inp = np.array([\n",
        "    np.concatenate((context_embeddings[ctx],q_emb)) for ctx in contexts])\n",
        "    out = neural_net(inp)\n",
        "    #out = np.array([[np.dot(context_embeddings[ctx],q_emb)] for ctx in contexts])\n",
        "    found_ctx = contexts[np.argmax(out)]\n",
        "    q_to_found_ctx[q] = found_ctx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_ab.rename(columns={'context':'correct_context'},inplace=True)\n",
        "df_ab.rename(columns={'answer_context':'answer_correct_context'},inplace=True)\n",
        "df_ab['answer_context'] = np.nan\n",
        "df_ab['context'] = np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "for idx,row in df_ab.iloc[43:].iterrows():\n",
        "    df_ab.loc[idx,'context'] = q_to_found_ctx[row['question']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('../../web/chatta/ab_test/context_history/saves/df_ab_fixed.pkl','wb') as f:\n",
        "    f.write(pickle.dumps(df_ab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('../../web/chatta/ab_test/context_history/saves/df_ab_fixed.pkl','rb') as f:\n",
        "    df_fixed = pickle.loads(f.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11      The third chapter of the pamphlet examines t...\n",
              "36      The third chapter of the pamphlet examines t...\n",
              "Name: correct_context, dtype: object"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_fixed.loc[df_fixed['question']=='What is the main focus of the third chapter of the pamphlet \"The Origins of the Second World War 1933-1941\"?','correct_context']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df_fixed' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Lauritz\\Documents\\DTU\\4-semester\\fagprojekt\\Learning-with-ChatGPT\\dev\\Neural Search\\q_w_chat.ipynb Cell 73\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Lauritz/Documents/DTU/4-semester/fagprojekt/Learning-with-ChatGPT/dev/Neural%20Search/q_w_chat.ipynb#Y132sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_fixed[\u001b[39m'\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique()\u001b[39m.\u001b[39mshape\n",
            "\u001b[1;31mNameError\u001b[0m: name 'df_fixed' is not defined"
          ]
        }
      ],
      "source": [
        "df_fixed['question'].unique().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('../ab_test_2450_final.pkl','rb') as f:\n",
        "    df_2450_results = pickle.loads(f.read())\n",
        "with open('../ab_test_history_final.pkl','rb') as f:\n",
        "    df_history_results = pickle.loads(f.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('../16_2450_final.pkl','rb') as f:\n",
        "    df_2450_results = pickle.loads(f.read())\n",
        "with open('../16_history_final.pkl','rb') as f:\n",
        "    df_history_results = pickle.loads(f.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "answer            28\n",
              "answer_context    22\n",
              "Name: choice, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_2450_results['choice'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "answer            30\n",
              "answer_context    20\n",
              "Name: choice, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_history_results['choice'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "answer            33\n",
              "answer_context    17\n",
              "Name: choice, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_history_results['choice'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(44,)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_2450_results['question'].unique().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "What is the definition of a symmetric matrix?                                                                                                                      3\n",
              "What is the impurity measure used in the decision tree in the given context?                                                                                       2\n",
              "What is the purpose of using a baseline in machine learning?                                                                                                       2\n",
              "What is the most common choice for the logistic function used to define the density of the Bernoulli distribution?                                                 2\n",
              "What is the horizon effect and how does pruning attempt to address it?                                                                                             2\n",
              "What is the main distinction in statistical testing between setup I and setup II?                                                                                  1\n",
              "What is the delta function and how is it used in computing the number of observations in a cluster?                                                                1\n",
              "What is the subject of Alan Turing's famous essay \"Computing machinery and intelligence\"?                                                                          1\n",
              "What is the focus of chapters 5 and 6 in the provided context?                                                                                                     1\n",
              "What is the expected value of a random variable x given its density function p(x), as shown in Figure 6.13? (Context needed to answer this question is missing)    1\n",
              "What is the purpose of applying logarithm to a feature column in machine learning?                                                                                 1\n",
              "What is leave-one-out cross-validation and how is it used in KNN regression?                                                                                       1\n",
              "What is the sum rule for mutually exclusive events?                                                                                                                1\n",
              "What is regularization and how is it used to control model complexity?                                                                                             1\n",
              "What is the advantage of using a histogram to visualize a single attribute of a dataset?                                                                           1\n",
              "What is the goal of building a machine learning system for the MNIST dataset?                                                                                      1\n",
              "What is the significance level commonly used to reject the null hypothesis in statistical testing?                                                                 1\n",
              "What is cross-validation and why is it important in evaluating model performance?                                                                                  1\n",
              "What is the definition of a basis of a subspace?                                                                                                                   1\n",
              "What is the title of the book that contains the article \"Data mining for imbalanced datasets: An overview\"?                                                        1\n",
              "What is the purpose of cross-validation in estimating the generalization error?                                                                                    1\n",
              "What is cross-validation and how is it used for model selection?                                                                                                   1\n",
              "What is the goal of principal component analysis?                                                                                                                  1\n",
              "What is the binomial distribution and how is it used to compute the probability of observing m positive outcomes in a sequence of N Bernoulli events?              1\n",
              "What is forward selection and how does it work in the context of model selection?                                                                                  1\n",
              "What is KNN regression and how is it different from KNN classification?                                                                                            1\n",
              "Using the data in Table 4.4, which of the following statements is correct?                                                                                         1\n",
              "What is the Apriori algorithm used for?                                                                                                                            1\n",
              "What is the purpose of the document \"Introduction to Machine Learning and Data Mining Lecture notes, Spring 2022\"?                                                 1\n",
              "What are two popular frameworks for automating the construction of neural network algorithms, and what are some benefits of using them?                            1\n",
              "What is KNN regression and how can it be extended?                                                                                                                 1\n",
              "What is the AdaBoost algorithm and how does it work?                                                                                                               1\n",
              "What is PCA and what are its applications?                                                                                                                         1\n",
              "What is the naive baseline level for a dataset with 100 classes, each with the same number of elements?                                                            1\n",
              "What is the purpose of the Introduction to Machine Learning and Data Mining Lecture notes?                                                                         1\n",
              "What is the standard data format used in the course and how is it represented?                                                                                     1\n",
              "What is the correct answer for problem 7.2 and how was it obtained?                                                                                                1\n",
              "What is the goal of K-means clustering?                                                                                                                            1\n",
              "What is the definition of the p'th percentile and how is it calculated using linear interpolation?                                                                 1\n",
              "What is the data set described in Table 2.3 about and how many observations and input attributes does it contain?                                                  1\n",
              "What is the formula for updating the location of cluster centers in the K-means algorithm?                                                                         1\n",
              "What is cross-validation and why is it used to estimate a model's generalization error?                                                                            1\n",
              "What is regularization in linear regression?                                                                                                                       1\n",
              "What is the aim of regularized least squares regression?                                                                                                           1\n",
              "Name: question, dtype: int64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_2450_results['question'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(35,)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_history_results['question'].unique().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "What was the significance of the German-Soviet non-aggression pact in the context of the events leading up to World War II?                                                                                3\n",
              "What were the three developments that split open the united front of Britain, France, and Italy against German rearmament in the mid-1930s?                                                                3\n",
              "What were the objectives of Japan's expansion in the Pacific region during World War II?                                                                                                                   3\n",
              "What was Hitler's plan for expanding German territory and how did he justify it?                                                                                                                           2\n",
              "What are some recommended sources for studying the strategic and economic problems facing Britain in the inter-war period, as well as specific crises that occurred between 1935 and 1941?                 2\n",
              "What were the challenges faced by Britain and the United States in containing Japanese expansion in East Asia before the outbreak of the Second World War?                                                 2\n",
              "What evidence suggests that Hitler was already looking ahead to a conflict against the United States for world domination?                                                                                 2\n",
              "What was the Hoare-Laval pact and why did it cause an uproar in Britain?                                                                                                                                   2\n",
              "What was Stalin's main concern during the mid- and late 1930s in terms of Soviet foreign policy, and how did this influence their actions towards Nazi Germany?                                            2\n",
              "What was the concern of Mussolini regarding German expansionist aims and how did he plan to establish Italy's own empire?                                                                                  2\n",
              "What was the British government's approach towards dealing with Hitler's grievances in the mid-1930s and why did they adopt this approach?                                                                 2\n",
              "What was Hitler's reaction to the Munich settlement and how did he plan to continue his expansionist ambitions?                                                                                            2\n",
              "What were the difficulties in forming an alliance between Britain, France, and Soviet Russia in the lead up to World War II?                                                                               1\n",
              "What was Chamberlain's approach to negotiating territorial change with Hitler and Mussolini, and how was it received by his contemporaries?                                                                1\n",
              "What was the main argument presented by A.J.P. Taylor in his book Origins of the Second World War and how did it shift the debate about Hitler's role in the outbreak of the war?                          1\n",
              "What were some of the challenges faced by Germany in implementing the Treaty of Versailles, and how did these challenges contribute to the rise of extreme nationalist groups in Germany?                  1\n",
              "What was the outcome of the conference at Munich in 1938, and what were the consequences of this outcome for Czechoslovakia?                                                                               1\n",
              "What was Hitler's ultimate goal in terms of foreign policy, according to historians?                                                                                                                       1\n",
              "What was Hitler's reaction to the Munich settlement and what actions did he take afterwards?                                                                                                               1\n",
              "What were the reasons behind the United States' policy of appeasement towards Hitler in the mid- to late 1930s, and how did it change by 1940?                                                             1\n",
              "What were the reasons for the failure of attempts to draw up a draft arms limitation convention agreeable to the major world powers and members of the League of Nations?                                  1\n",
              "What was the impact of the Wall Street crash of 1929 on Germany and other European countries?                                                                                                              1\n",
              "What were the main causes of the outbreak of war in Europe in 1939 and how did it escalate into a global conflict by 1941?                                                                                 1\n",
              "What was the Night of the Long Knives and how did it impact Hitler's power in Germany?                                                                                                                     1\n",
              "What was the secret protocol in the Nazi-Soviet pact and how did it affect Poland?                                                                                                                         1\n",
              "What were some of the factors that led to rising nationalist protests in Japan and the eventual withdrawal of Japan from the League of Nations in 1933?                                                    1\n",
              "What are some recommended books for studying the diplomacy and politics leading up to the Second World War, including American foreign policy towards Europe and Japanese foreign and imperial policy?     1\n",
              "What are some recommended books and essays for understanding the origins of the Second World War, Fascist and Nazi ideology, inter-war German history, and Soviet foreign policy during Stalin's reign?    1\n",
              "What was Mussolini's aim in the mid-1920s and how did he plan to achieve it?                                                                                                                               1\n",
              "What was the reason behind the French and British reluctance to impose oil sanctions and close the Suez Canal during the years 1933-41, and how did this impact the Italian war effort?                    1\n",
              "What were the major global challenges faced by the British and French governments in the inter-war period and how did these challenges shape their policies towards Hitler after 1933?                     1\n",
              "What was the controversy surrounding A.J.P. Taylor's interpretation of the origins of the Second World War, and how did it impact the study of Nazi foreign policy?                                        1\n",
              "What were the obstacles to Italy forming a political or military alliance with France and its eastern European allies in the 1930s?                                                                        1\n",
              "What is the main focus of the third chapter of the pamphlet \"The Origins of the Second World War 1933-1941\"?                                                                                               1\n",
              "What was the historical debate surrounding the extent to which Hitler shaped Nazi foreign policy?                                                                                                          1\n",
              "Name: question, dtype: int64"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_history_results['question'].value_counts()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
